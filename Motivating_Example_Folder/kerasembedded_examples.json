[
  {
    "postURL": "https://stackoverflow.com/questions/40904979",
    "title": "",
    "question": "This question already has answers here:\nWhat does the 'b' character do in front of a string literal? (12 answers)\nClosed 8 years ago.\nDurng the test of TensorFlow r0.12(CPU) installed on Windows 10, I found that the printed string contant is always with an 'b' in the end. The print of python is normal. I cannot figure out the reason so came here for help. The code is as follows:\n\n>>>import tensorflow as tf\n>>>hello = tf.constant('Hello, TensorFlow!')\n>>>sess = tf.Session()\n>>>print(sess.run(hello))\nb'Hello, TensorFlow!'",
    "answer": "45\n\nUse sess.run(hello).decode() because it is a bytestring. decode method will return the string.\n\nYour print statement must look like\n\nprint(sess.run(hello).decode())",
    "mlApiName": "tf.io.decode_raw",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "DT",
      "level3": "PT",
      "leafContractCategory": "PT",
      "rootCause": "Unacceptable Input Type",
      "effect": "IF",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Evaluation",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): SAM\nThe post addresses a violation involving the use of a single API method, specifically tf.io.decode_raw, which is the sole API causing the issue.\n\nLevel 2: DT\nThe core problem pertains to incorrect handling of data types�specifically, string literals versus byte strings�which TensorFlow expects.\n\nLevel 3 (Hybrid Patterns): PT\nThe issue is specifically caused by a primitive Python data type mismatch (string versus byte representation), leading to unexpected results.\n\nLeaf Contract Category: PT\nMatches the Level 3 categorization exactly, as the fundamental data type causing the problem is a primitive type.\n\nRoot Cause: Unacceptable Input Type\nThe TensorFlow API expects byte strings, but it receives regular string literals, resulting in the inappropriate input being passed.\n\nEffect: Incorrect Functionality\nAlthough the program does not crash, it produces incorrect output by appending an unintended character (b) to the printed result.\n\nML Library: TensorFlow\nTensorFlow's API method specifically triggered this data handling issue.\n\nContract Violation Location: Model Evaluation\nThis problem emerges clearly during the evaluation phase when results are printed after session execution.\n\nDetection Technique: Static Analysis\nThe issue can be identified through inspection of the source code without execution.\n"
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/45175469",
    "title": "",
    "question": "This is my convolution neural net:\n\ndef convolutional_neural_network(frame):\n    wts = {'conv1': tf.random_normal([5, 5, 3, 32]),\n            'conv2': tf.random_normal([5, 5, 32, 64]),\n            'fc': tf.random_normal([158*117*64 + 4, 128]),\n            'out': tf.random_normal([128, n_classes])\n            }\n    biases = {'fc': tf.random_normal([128]),\n                'out': tf.random_normal([n_classes])\n            }\n\n    conv1 = conv2d(frame, wts['conv1'])\n    # print(conv1)\n    conv1 = maxpool2d(conv1)\n    # print(conv1)\n    conv2 = conv2d(conv1, wts['conv2'])\n    conv2 = maxpool2d(conv2)\n    # print(conv2)\n    conv2 = tf.reshape(conv2, shape=[-1,158*117*64])\n    print(conv2)\n    print(controls_at_each_frame)\n    conv2 = tf.concat(conv2, controls_at_each_frame, axis=1)\n    fc = tf.add(tf.matmul(conv2, wts['fc']), biases['fc'])\n\n    output = tf.nn.relu(tf.add(tf.matmul(fc, wts['out']), biases['out']))\n\n    return output\nwhere\n\nframe = tf.placeholder('float', [None, 640-10, 465, 3])\ncontrols_at_each_frame = tf.placeholder('float', [None, 4]) # [w, a, s, d] (1/0)\nare the used placeholder.\n\nI am making a self driving car in GTA San Andreas. What I want to do is concatenate frame and controls_at_each_frame into a single layer which will be then sent to an fully connected layer. When I run I get an error TypeError: concat() got multiple values for argument 'axis' at\n\nconv2 = tf.concat(conv2, controls_at_each_frame, axis=1)\nCould you explain why this happening?",
    "answer": "50\n\nTry\n\nconv2 = tf.concat((conv2, controls_at_each_frame), axis=1).\n\nNote I'm putting the two frames that you want to concatenate within parentheses, as specified here.",
    "mlApiName": "tf.concat",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "DT",
      "level3": "BIT",
      "leafContractCategory": "BIT",
      "rootCause": "Unacceptable Input Type",
      "effect": "Crash",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1: SAM\nThe violation involves only the tf.concat method from TensorFlow, representing a single method usage error.\n\nLevel 2: DT\nIt arises from passing incorrect input arguments to the API, thus constituting a data type mismatch.\n\nLevel 3: BIT\nThe TensorFlow built-in tensor data types are involved in this issue. Specifically, the error arises due to misuse of built-in data structures required by the API.\n\nLeaf Contract Category: BIT\nThe error directly involves built-in TensorFlow tensor types, accurately matching Level 3 categorization.\n\nRoot Cause: Unacceptable Input Type\nThe error is triggered by incorrect input format�passing tensors separately instead of encapsulating them within a required container (like a tuple or list).\n\nEffect: Crash\nThe misuse directly causes a runtime error, resulting in program termination.\n\nML Library: TensorFlow\nThe root of the issue lies in the TensorFlow library.\n\nContract Violation Location: Model Construction\nThe error is identified during the construction phase of the neural network.\n\nDetection Technique: Static Analysis\nThe issue was found by inspecting the code structure, even without running the model."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/48699954",
    "title": "",
    "question": "7\n\nwhen triying to fit the model i get this error\ni'm using Keras and every time i try to fit my model\n\npadded_model.fit(train_X, train_y, epochs=50, verbose=1)\ni get this error :\n\n'int' object has no attribute 'ndim'",
    "answer": "13\n\nIf train_x and train_y are normal Python lists, they don't have the attribute .ndim. Only Numpy arrays have this attribute representing the number of dimensions.\n\n(https://docs.scipy.org/doc/numpy-1.12.0/reference/generated/numpy.ndarray.ndim.html)",
    "mlApiName": "keras.models.fit",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "DT",
      "level3": "MT",
      "leafContractCategory": "MT",
      "rootCause": "Unacceptable Input Type",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Train",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1: SAM\nThe issue is centered around the single Keras method model.fit, which leads to the error.\n\nLevel 2: DT\nThe provided input arrays have an incorrect data shape, indicating a fundamental data type incompatibility.\n\nLevel 3: MT\nThe data issue is specifically related to the machine learning data structure�shapes and dimensions required by Keras for training.\n\nLeaf Contract Category: MT\nPrecisely matches the Level 3 categorization because the issue stems from ML data shapes.\n\nRoot Cause: Unacceptable Input Type\nThe model training method receives data arrays of incorrect dimensions, violating expected input type constraints.\n\nEffect: Crash\nThe provided input directly leads to the crash of the training process.\n\nML Library: Keras\nThe issue is explicitly tied to the Keras ML framework.\n\nContract Violation Location: Train\nOccurs clearly during the training phase when model.fit is executed.\n\nDetection Technique: Static Analysis\nIdentifiable via code inspection without execution, due to obvious data shape mismatch."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/36096386",
    "title": "",
    "question": "Calling tf.set_random_seed(SEED) has no effect that I can tell...\nFor example, running the code below several times inside an IPython notebook produces different output each time:\n\nimport tensorflow as tf\ntf.set_random_seed(42)\nsess = tf.InteractiveSession()\na = tf.constant([1, 2, 3, 4, 5])\ntf.initialize_all_variables().run()\na_shuf = tf.random_shuffle(a)\nprint(a.eval())\nprint(a_shuf.eval())\nsess.close()\nIf I set the seed explicitly: a_shuf = tf.random_shuffle(a, seed=42), the output is the same after each run. But why do I need to set the seed if I already call tf.set_random_seed(42)?\n\nThe equivalent code using numpy just works:\n\nimport numpy as np\nnp.random.seed(42)\na = [1,2,3,4,5]\nnp.random.shuffle(a)\nprint(a)",
    "answer": "13\n\nThat only sets the graph-level random seed. If you execute this snippet several times in a row, the graph will change, and two shuffle statements will get different operation-level seeds. The details are described in the doc string for set_random_seed\n\nTo get deterministic a_shuf you can either\n\nCall tf.reset_default_graph() between invocations or\nSet operation-level seed for shuffle: a_shuf = tf.random_shuffle(a, seed=42)",
    "mlApiName": "tf.random.shuffle,tf.reset_default_graph",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "F,IC-1",
      "leafContractCategory": "Comb. of SAM(Level 3) and AMO(Level 2)",
      "rootCause": "Missing Options",
      "effect": "IF",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Evaluation",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1: Hybrid\nThe issue involves multiple TensorFlow API methods interacting, indicating complexity beyond a single API call.\n\nLevel 2: Selection (SL)\nThe error occurs due to the incorrect selection or configuration of certain API parameters or methods.\n\nLevel 3: Eventually (F), Intra-argument Contract (IC-1)\nThis combines two problems: issues with execution sequence (eventually correct use required) and internal consistency of arguments.\n\nLeaf Contract Category: Combination of SAM(Level 3) and AMO(Level 2)\nIt combines both API usage correctness and the order of method invocations, indicating a complex, hybrid category violation.\n\nRoot Cause: Missing Options\nEssential parameters or configurations were omitted from the API call, causing the contract violation.\n\nEffect: Incorrect Functionality\nResults in incorrect behavior but not necessarily an immediate runtime crash.\n\nML Library: TensorFlow\nDirectly related to TensorFlow API usage.\n\nContract Violation Location: Model Evaluation\nOccurs clearly at the evaluation or inference stage, post-model construction.\n\nDetection Technique: Static Analysis\nDetected purely through source code inspection."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/46204569",
    "title": "",
    "question": "21\n\nI am trying to perform the usual classification on the MNIST database but with randomly cropped digits. Images are cropped the following way : removed randomly first/last and/or row/column.\n\nI would like to use a Convolutional Neural Network using Keras (and Tensorflow backend) to perform convolution and then the usual classification.\n\nInputs are of variable size and i can't manage to get it to work.\n\nHere is how I cropped digits\n\nimport numpy as np\nfrom keras.utils import to_categorical\nfrom sklearn.datasets import load_digits\n\ndigits = load_digits()\n\nX = digits.images\nX = np.expand_dims(X, axis=3)\n\nX_crop = list()\nfor index in range(len(X)):\n    X_crop.append(X[index, np.random.randint(0,2):np.random.randint(7,9), np.random.randint(0,2):np.random.randint(7,9), :])\nX_crop = np.array(X_crop)\n\ny = to_categorical(digits.target)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_crop, y, train_size=0.8, test_size=0.2)\nAnd here is the architecture of the model I want to use\n\nfrom keras.layers import Dense, Dropout\nfrom keras.layers.convolutional import Conv2D\nfrom keras.models import Sequential\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=10, \n                 kernel_size=(3,3), \n                 input_shape=(None, None, 1), \n                 data_format='channels_last'))\n\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n\nmodel.summary()\n\nmodel.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test))\nDoes someone have an idea on how to handle variable sized input in my neural network?\n\nAnd how to perform classification?",
    "answer": "TL/DR - go to point 4\n\nSo - before we get to the point - let's fix some problems with your network:\n\nYour network will not work because of activation: with categorical_crossentropy you need to have a softmax activation:\n\nmodel.add(Dense(10, activation='softmax'))\nVectorize spatial tensors: as Daniel mentioned - you need to, at some stage, switch your vectors from spatial (images) to vectorized (vectors). Currently - applying Dense to output from a Conv2D is equivalent to (1, 1) convolution. So basically - output from your network is spatial - not vectorized what causes dimensionality mismatch (you can check that by running your network or checking the model.summary(). In order to change that you need to use either GlobalMaxPooling2D or GlobalAveragePooling2D. E.g.:\n\nmodel.add(Conv2D(filters=10, \n             kernel_size=(3, 3), \n             input_shape=(None, None, 1),\n             padding=\"same\",\n             data_format='channels_last'))\nmodel.add(GlobalMaxPooling2D())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(10, activation='softmax'))\nConcatenated numpy arrays need to have the same shape: if you check the shape of X_crop you'll see that it's not a spatial matrix. It's because you concatenated matrices with different shapes. Sadly - it's impossible to overcome this issue as numpy.array need to have a fixed shape.\n\nHow to make your network train on examples of different shape: The most important thing in doing this is to understand two things. First - is that in a single batch every image should have the same size. Second - is that calling fit multiple times is a bad idea - as you reset inner model states. So here is what needs to be done:\n\na. Write a function which crops a single batch - e.g. a get_cropped_batches_generator which given a matrix cuts a batch out of it and crops it randomly.\n\nb. Use train_on_batch method. Here is an example code:\n\nfrom six import next\n\nbatches_generator = get_cropped_batches_generator(X, batch_size=16)\nlosses = list()\nfor epoch_nb in range(nb_of_epochs):\n    epoch_losses = list()\n    for batch_nb in range(nb_of_batches):\n        # cropped_x has a different shape for different batches (in general)\n        cropped_x, cropped_y = next(batches_generator) \n        current_loss = model.train_on_batch(cropped_x, cropped_y)\n        epoch_losses.append(current_loss)\n    losses.append(epoch_losses.sum() / (1.0 * len(epoch_losses))\nfinal_loss = losses.sum() / (1.0 * len(losses))\nSo - a few comments to code above: First, train_on_batch doesn't use nice keras progress bar. It returns a single loss value (for a given batch) - that's why I added logic to compute loss. You could use Progbar callback for that also. Second - you need to implement get_cropped_batches_generator - I haven't written a code to keep my answer a little bit more clear. You could ask another question on how to implement it. Last thing - I use six to keep compatibility between Python 2 and Python 3.",
    "mlApiName": "keras.layers.Dense,keras.models.compile",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SAI",
      "level3": "IC-2,F",
      "leafContractCategory": "SAM (Level 3) ? AMO(Level 2)",
      "rootCause": "Missing Input value-Method order Dependency",
      "effect": "Unknown",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1: Hybrid\nComplex scenario involving multiple APIs (Dense layer and compile method in Keras).\n\nLevel 2: SAM-AMO Interdependency (SAI)\nThis scenario indicates a complex dependency between the correctness of single API calls and their required method-ordering constraints.\n\nLevel 3: Inter-argument Contract (IC-2), Eventually (F)\nThis denotes combined issues related to interdependencies between arguments across multiple calls and required eventual correctness in sequence.\n\nLeaf Contract Category: SAM (Level 3) and AMO(Level 2)\nThe violation precisely matches the hybrid interaction between correct API method usage and ordering constraints.\n\nRoot Cause: Missing Input value-Method order Dependency\nThis indicates a critical input value was dependent upon a specific order of method execution which was not followed.\n\nEffect: Unknown\nThe specific consequence isn't explicitly a crash or incorrect functionality; rather, the outcome is not fully known.\n\nML Library: Keras\nPertains directly to Keras API usage.\n\nContract Violation Location: Model Construction\nIssue arises clearly during the setup of the Keras model layers.\n\nDetection Technique: Static Analysis\nProblem is evident by inspecting the code for API misuse and incorrect ordering."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/44717100",
    "title": "",
    "question": "19\n\nI have 2 numpy arrays, which I convert into tensors to use the TensorDataset object.\n\nimport torch.utils.data as data_utils\n\nX = np.zeros((100,30))\nY = np.zeros((100,30))\n\ntrain = data_utils.TensorDataset(torch.from_numpy(X).double(), torch.from_numpy(Y))\ntrain_loader = data_utils.DataLoader(train, batch_size=50, shuffle=True)\nwhen I do:\n\nfor batch_idx, (data, target) in enumerate(train_loader):\n    data, target = Variable(data), Variable(target)\n    optimizer.zero_grad()\n    output = model(data)               # error occurs here\nI get the fallowing error:\n\nTypeError: addmm_ received an invalid combination of arguments - got (int, int, torch.DoubleTensor, torch.FloatTensor), but expected one of: [...]\n* (float beta, float alpha, torch.DoubleTensor mat1, torch.DoubleTensor mat2) didn't match because some of the arguments have invalid types: (int, int, torch.DoubleTensor, torch.FloatTensor)\n* (float beta, float alpha, torch.SparseDoubleTensor mat1, torch.DoubleTensor mat2) didn't match because some of the arguments have invalid types: (int, int, torch.DoubleTensor, torch.FloatTensor)\n\nThe last error comes from:\n\noutput.addmm_(0, 1, input, weight.t())\n\nAs you see in my code I tried converting the tensor by using .double() - but this did not work. Why is he casting one array into a FloatTensor object and the other into a DoubleTensor? Any ideas?\n\npythontorchpytorch",
    "answer": "Your numpy arrays are 64-bit floating point and will be converted to torch.DoubleTensor standardly. Now, if you use them with your model, you'll need to make sure that your model parameters are also Double. Or you need to make sure, that your numpy arrays are cast as Float, because model parameters are standardly cast as float.\n\nHence, do either of the following:\n\ndata_utils.TensorDataset(torch.from_numpy(X).float(), torch.from_numpy(Y).float())\nor do:\n\nmodel.double()\nDepeding, if you want to cast your model parameters, inputs and targets as Float or as Double.",
    "mlApiName": "torch.utils.data.TensorDataset",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "IC-2",
      "leafContractCategory": "SAM(Level-3)",
      "rootCause": "Missing Options",
      "effect": "Crash",
      "mlLibrary": "Pytorch",
      "contractViolationLocation": "Model Initialization",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): Hybrid\nThe problem involves multiple method calls in combination, specifically the interaction between data preparation (TensorDataset) and model usage. This represents a hybrid scenario involving multiple API calls.\n\nLevel 2: SL (Selection)\nThe violation stems from selecting mismatched data types without proper compatibility checks, leading to tensor type mismatches.\n\nLevel 3 (Hybrid Patterns): IC-2 (Inter-argument Contract)\nThe error explicitly arises because two tensors (X and Y) passed simultaneously into the same API call (TensorDataset) have incompatible types (one tensor is DoubleTensor, the other implicitly converted FloatTensor).\n\nLeaf Contract Category: SAM (Level-3)\nAt the leaf level, the contract violation specifically occurs during a single API method (TensorDataset) call, due to inconsistent tensor data types among arguments.\n\nRoot Cause: Missing Options\nThe root cause is that required explicit options for ensuring data type compatibility were omitted. Specifically, the user did not specify or harmonize tensor data types across both the input data and the model parameters, causing the mismatch.\n\nEffect: Crash\nThe incompatible data types lead directly to a runtime exception (a crash), stopping the execution of the program.\n\nML Library: PyTorch\nThe issue specifically relates to PyTorch and its tensor management system within the torch.utils.data.TensorDataset API.\n\nContract Violation Location: Model Initialization\nThe error occurs at the model initialization stage, specifically when the prepared dataset is initially passed into the model for training or inference.\n\nDetection Technique: Static\nThe contract violation can be identified through static analysis since it pertains to incorrect argument types and method usage that can be detected by analyzing the source code."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/39467496",
    "title": "",
    "question": "i'm learning keras these days, and i met an error when using scikit-learn API.Here are something maybe useful:\n\nENVIRONMENT:\n\npython:3.5.2  \nkeras:1.0.5  \nscikit-learn:0.17.1\nCODE\n\nimport pandas as pd\nfrom keras.layers import Input, Dense\nfrom keras.models import Model\nfrom keras.models import Sequential\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.cross_validation import cross_val_score\nfrom sqlalchemy import create_engine\nfrom sklearn.cross_validation import KFold\n\ndef read_db():\n    \"get prepared data from mysql.\"\n    con_str = \"mysql+mysqldb://root:0000@localhost/nbse?charset=utf8\"\n    engine = create_engine(con_str)\n    data = pd.read_sql_table('data_ml', engine)\n    return data\n\ndef nn_model():\n    \"create a model.\"\n    model = Sequential()\n    model.add(Dense(output_dim=100, input_dim=105, activation='softplus'))\n    model.add(Dense(output_dim=1, input_dim=100, activation='softplus'))\n    model.compile(loss='mean_squared_error', optimizer='adam')\n    return model\n\ndata = read_db()\ny = data.pop('PRICE').as_matrix()\nx = data.as_matrix()\nmodel = nn_model()\nmodel = KerasRegressor(build_fn=model, nb_epoch=2)\nmodel.fit(x,y)  #something wrong here!\nERROR\n\nTraceback (most recent call last):\n  File \"C:/Users/Administrator/PycharmProjects/forecast/gridsearch.py\", line 43, in \n    model.fit(x,y)\n  File \"D:\\Program Files\\Python35\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 135, in fit\n    **self.filter_sk_params(self.build_fn.__call__))\nTypeError: __call__() missing 1 required positional argument: 'x'\n\nProcess finished with exit code 1\n??the model works well without packaging with kerasRegressor, but i wanna using sk_learn's gridSearch after this, so i'm here for help. I tried but still have no idea.\n\nsomething maybe helpful:\n\nkeras.warappers.scikit_learn.py  \n\nclass BaseWrapper(object):  \n\n    def __init__(self, build_fn=None, **sk_params):\n        self.build_fn = build_fn\n        self.sk_params = sk_params\n        self.check_params(sk_params)  \n\n    def fit(self, X, y, **kwargs):\n        '''Construct a new model with build_fn and fit the model according\n        to the given training data.\n    # Arguments\n        X : array-like, shape `(n_samples, n_features)`\n            Training samples where n_samples in the number of samples\n            and n_features is the number of features.\n        y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n            True labels for X.\n        kwargs: dictionary arguments\n            Legal arguments are the arguments of `Sequential.fit`\n\n    # Returns\n        history : object\n            details about the training history at each epoch.\n    '''\n\n    if self.build_fn is None:\n        self.model = self.__call__(**self.filter_sk_params(self.__call__))\n    elif not isinstance(self.build_fn, types.FunctionType):\n        self.model = self.build_fn(\n            **self.filter_sk_params(self.build_fn.__call__))\n    else:\n        self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n\n    loss_name = self.model.loss\n    if hasattr(loss_name, '__name__'):\n        loss_name = loss_name.__name__\n    if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n        y = to_categorical(y)\n\n    fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n    fit_args.update(kwargs)\n\n    history = self.model.fit(X, y, **fit_args)\n\n    return history\n??error occored in this line:\n\n    self.model = self.build_fn(\n        **self.filter_sk_params(self.build_fn.__call__))\nself.build_fn here is keras.models.Sequential\n\nmodels.py  \n\nclass Sequential(Model):\n\n    def call(self, x, mask=None):\n        if not self.built:\n            self.build()\n        return self.model.call(x, mask)\nSo, what's that x mean and how to fix this error?\nThanks!",
    "answer": "13\n\nxiao, I ran into the same issue! Hopefully this helps:\n\nBackground and The Issue\nThe documentation for Keras states that, when implementing Wrappers for scikit-learn, there are two arguments. The first is the build function, which is a \"callable function or class instance\". Specifically, it states that:\n\nbuild_fn should construct, compile and return a Keras model, which will then be used to fit/predict. One of the following three values could be passed to build_fn:\n\nA function\nAn instance of a class that implements the call method\nNone. This means you implement a class that inherits from either KerasClassifier or KerasRegressor. The call method of the present class will then be treated as the default build_fn.\nIn your code, you create the model, and then pass the model as the value for the argument build_fn when creating the KerasRegressor wrapper:\n\nmodel = nn_model()\nmodel = KerasRegressor(build_fn=model, nb_epoch=2)\nHerein lies the issue. Rather than passing your nn_model function as the build_fn, you pass an actual instance of the Keras Sequential model. For this reason, when fit() is called, it cannot find the call method, because it is not implemented in the class you returned.\n\nProposed Solution\nWhat I did to make things work is pass the function as build_fn, rather than an actual model:\n\ndata = read_db()\ny = data.pop('PRICE').as_matrix()\nx = data.as_matrix()\n# model = nn_model() # Don't do this!\n# set build_fn equal to the nn_model function\nmodel = KerasRegressor(build_fn=nn_model, nb_epoch=2) # note that you do not call the function!\nmodel.fit(x,y)  # fixed!\nThis is not the only solution (you could set build_fn to a class that implements the call method appropriately), but the one that worked for me. I hope it helps you!",
    "mlApiName": "keras.wrappers.scikit_learn.KerasRegressor",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "DT",
      "level3": "RT",
      "leafContractCategory": "RT",
      "rootCause": "Unacceptable Input Type",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): SAM (Single API Method)\nThis issue involves misuse of a single API method, specifically the KerasRegressor constructor, classifying it as a SAM violation.\n\nLevel 2: DT (Data Type)\nThe issue is clearly related to data type expectations. The KerasRegressor expects a callable (such as a function or a class instance with a callable method), but an instance of a model (Sequential) is provided instead.\n\nLevel 3 (Hybrid Patterns): RT (Reference Type)\nThe problem stems from passing the incorrect reference type to the method�passing an instance instead of a reference to the callable function itself.\n\nLeaf Contract Category: RT (Reference Type)\nAt the leaf level, the specific error is a reference-type issue, as explicitly highlighted by the stack trace, indicating the incorrect reference provided to the build_fn parameter.\n\nRoot Cause: Unacceptable Input Type\nThe root cause of the issue is clearly due to providing an instance of a Sequential model instead of a function or class implementing the required callable interface. Hence, the input type is unacceptable for this method call.\n\nEffect: Crash\nDue to the improper usage, the Keras model construction crashes, raising a TypeError.\n\nML Library: Keras\nThe error specifically relates to Keras's scikit-learn wrapper API, highlighting integration issues between Keras and scikit-learn.\n\nContract Violation Location: Model Construction\nThe error occurred during model construction phase, specifically at the point of instantiating the KerasRegressor class.\n\nDetection Technique: Static\nThe issue is detectable through static code analysis since the problem arises from improper API usage, and can be identified by code inspection without needing runtime execution."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/36210887",
    "title": "",
    "question": "34\n\nI am trying to save Nueral Network weights into a file and then restoring those weights by initializing the network instead of random initialization. My code works fine with random initialization. But, when i initialize weights from file it is showing me an error TypeError: Input 'b' of 'MatMul' Op has type float64 that does not match type float32 of argument 'a'. I don't know how do i solve this issue.Here is my code:\n\nModel Initialization\n\n# Parameters\ntraining_epochs = 5\nbatch_size = 64\ndisplay_step = 5\nbatch = tf.Variable(0, trainable=False)\nregualarization =  0.008\n\n# Network Parameters\nn_hidden_1 = 300 # 1st layer num features\nn_hidden_2 = 250 # 2nd layer num features\n\nn_input = model.layer1_size # Vector input (sentence shape: 30*10)\nn_classes = 12 # Sentence Category detection total classes (0-11 categories)\n\n#History storing variables for plots\nloss_history = []\ntrain_acc_history = []\nval_acc_history = []\n\n# tf Graph input\nx = tf.placeholder(\"float\", [None, n_input])\ny = tf.placeholder(\"float\", [None, n_classes])\nModel parameters\n\n#loading Weights\ndef weight_variable(fan_in, fan_out, filename):\n    stddev = np.sqrt(2.0/fan_in)\n    if (filename == \"\"):\n        initial  = tf.random_normal([fan_in,fan_out], stddev=stddev)\n    else:\n        initial  = np.loadtxt(filename)\n    print initial.shape\n    return tf.Variable(initial)\n\n#loading Biases\ndef bias_variable(shape, filename):\n    if (filename == \"\"):\n     initial = tf.constant(0.1, shape=shape)\n    else:\n     initial  = np.loadtxt(filename)  \n    print initial.shape\n    return tf.Variable(initial)\n\n# Create model\ndef multilayer_perceptron(_X, _weights, _biases):\n    layer_1 = tf.nn.relu(tf.add(tf.matmul(_X, _weights['h1']), _biases['b1'])) \n    layer_2 = tf.nn.relu(tf.add(tf.matmul(layer_1, _weights['h2']), _biases['b2'])) \n    return tf.matmul(layer_2, weights['out']) + biases['out']  \n\n# Store layers weight & bias\nweights = {\n'h1':  w2v_utils.weight_variable(n_input, n_hidden_1,    filename=\"weights_h1.txt\"),\n'h2':  w2v_utils.weight_variable(n_hidden_1, n_hidden_2, filename=\"weights_h2.txt\"),\n'out': w2v_utils.weight_variable(n_hidden_2, n_classes,  filename=\"weights_out.txt\") \n}\n\n biases = {\n'b1': w2v_utils.bias_variable([n_hidden_1], filename=\"biases_b1.txt\"),\n'b2': w2v_utils.bias_variable([n_hidden_2], filename=\"biases_b2.txt\"),\n'out': w2v_utils.bias_variable([n_classes], filename=\"biases_out.txt\")\n}\n\n# Define loss and optimizer\n#learning rate\n# Optimizer: set up a variable that's incremented once per batch and\n# controls the learning rate decay.\nlearning_rate = tf.train.exponential_decay(\n    0.02*0.01,           # Base learning rate. #0.002\n    batch * batch_size,  # Current index into the dataset.\n    X_train.shape[0],    # Decay step.\n    0.96,                # Decay rate.\n    staircase=True)\n\n# Construct model\npred = tf.nn.relu(multilayer_perceptron(x, weights, biases))\n\n#L2 regularization\nl2_loss = tf.add_n([tf.nn.l2_loss(v) for v in tf.trainable_variables()])\n\n#Softmax loss\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y)) \n\n#Total_cost\ncost = cost+ (regualarization*0.5*l2_loss)\n\n# Adam Optimizer\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost,global_step=batch)\n\n# Add ops to save and restore all the variables.\nsaver = tf.train.Saver()\n\n# Initializing the variables\ninit = tf.initialize_all_variables()\n\nprint \"Network Initialized!\"\nERROR DETAILS enter image description here",
    "answer": "58\n\nThe tf.matmul() op does not perform automatic type conversions, so both of its inputs must have the same element type. The error message you are seeing indicates that you have a call to tf.matmul() where the first argument has type tf.float32, and the second argument has type tf.float64. You must convert one of the inputs to match the other, for example using tf.cast(x, tf.float32).\n\nLooking at your code, I don't see anywhere that a tf.float64 tensor is explicitly created (the default dtype for floating-point values in the TensorFlow Python API�e.g. for tf.constant(37.0)�is tf.float32). I would guess that the errors are caused by the np.loadtxt(filename) calls, which might be loading an np.float64 array. You can explicitly change them to load np.float32 arrays (which are converted to tf.float32 tensors) as follows:\n\ninitial = np.loadtxt(filename).astype(np.float32)",
    "mlApiName": "tf.linalg.matmul",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-2",
      "leafContractCategory": "IC-2",
      "rootCause": "Missing Input Value/Type Dependency",
      "effect": "Crash",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): SAM (Single API Method)\nThe issue arises from the incorrect use of a single TensorFlow API method (tf.matmul), clearly indicating a SAM category.\n\nLevel 2: BET (Boolean Expression Type)\nThe labeling as Boolean Expression Type (BET) is appropriate because the issue emerges from an implicit type compatibility check internally done by TensorFlow, where it checks if input tensors have matching types before the operation is executed.\n\nLevel 3 (Hybrid Patterns): IC-2 (Inter-argument Contract)\nThis issue pertains specifically to a mismatch between argument types (data types of two tensors involved), thus making it an Inter-argument Contract issue. The arguments to tf.matmul must match in their data type, and the mismatch leads directly to a violation.\n\nLeaf Contract Category: IC-2 (Inter-argument Contract)\nThis specific category precisely describes the violation because the two arguments (a and b) of the tf.matmul function are interdependent, requiring a consistent type. The failure arises directly from the conflict between the input argument data types.\n\nRoot Cause: Missing Input Value/Type Dependency\nThe root cause is the absence of explicit data type handling or conversions when loading weights from a file (np.loadtxt). TensorFlow requires both tensors passed to tf.matmul to be the same type. However, loading data directly from files resulted in inconsistent types (float32 vs float64).\n\nEffect: Crash\nDue to incompatible tensor types, the TensorFlow computation graph construction crashes with a TypeError.\n\nML Library: TensorFlow\nThe error is directly tied to TensorFlow�s API (tf.matmul), making TensorFlow the relevant ML library.\n\nContract Violation Location: Model Construction\nThis error specifically occurs during the construction of the TensorFlow computational graph, when attempting to initialize neural network parameters from file, which affects how tf.matmul operations are defined in the model.\n\nDetection Technique: Static\nThe problem is detectable via static analysis, as the issue emerges from incorrect API usage clearly identifiable through the code structure, without needing execution at runtime."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/42521400",
    "title": "",
    "question": "9\n\nI am having a hard time with calculating cross entropy in tensorflow. In particular, I am using the function:\n\ntf.nn.softmax_cross_entropy_with_logits()\nUsing what is seemingly simple code, I can only get it to return a zero\n\nimport tensorflow as tf\nimport numpy as np\n\nsess = tf.InteractiveSession()\n\na = tf.placeholder(tf.float32, shape =[None, 1])\nb = tf.placeholder(tf.float32, shape = [None, 1])\nsess.run(tf.global_variables_initializer())\nc = tf.nn.softmax_cross_entropy_with_logits(\n    logits=b, labels=a\n).eval(feed_dict={b:np.array([[0.45]]), a:np.array([[0.2]])})\nprint c\nreturns\n\n0\nMy understanding of cross entropy is as follows:\n\nH(p,q) = p(x)*log(q(x))\nWhere p(x) is the true probability of event x and q(x) is the predicted probability of event x.\n\nThere if input any two numbers for p(x) and q(x) are used such that\n\n0<p(x)<1 AND 0<q(x)<1\nthere should be a nonzero cross entropy. I am expecting that I am using tensorflow incorrectly. Thanks in advance for any help.",
    "answer": "14\n\nLike they say, you can't spell \"softmax_cross_entropy_with_logits\" without \"softmax\". Softmax of [0.45] is [1], and log(1) is 0.\n\nMeasures the probability error in discrete classification tasks in which the classes are mutually exclusive (each entry is in exactly one class). For example, each CIFAR-10 image is labeled with one and only one label: an image can be a dog or a truck, but not both.\n\nNOTE: While the classes are mutually exclusive, their probabilities need not be. All that is required is that each row of labels is a valid probability distribution. If they are not, the computation of the gradient will be incorrect.\n\nIf using exclusive labels (wherein one and only one class is true at a time), see sparse_softmax_cross_entropy_with_logits.\n\nWARNING: This op expects unscaled logits, since it performs a softmax on logits internally for efficiency. Do not call this op with the output of softmax, as it will produce incorrect results.\n\nlogits and labels must have the same shape [batch_size, num_classes] and the same dtype (either float16, float32, or float64).",
    "mlApiName": "tf.nn.softmax_cross_entropy_with_logits",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-2",
      "leafContractCategory": "IC-2",
      "rootCause": "Missing Input Value/Type Dependency",
      "effect": "IF",
      "mlLibrary": "TensorFlow",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): SAM (Single API Method)\nThe issue specifically involves improper usage of a single TensorFlow API method (tf.nn.softmax_cross_entropy_with_logits), thus clearly indicating a Single API Method (SAM) violation.\n\nLevel 2: BET (Boolean Expression Type)\nThe issue stems from a logical constraint or expectation within the TensorFlow method regarding inputs. The function implicitly applies a softmax and expects logits representing unscaled scores for multiple classes. Since this logic wasn't correctly reflected in the input, it fits a BET violation scenario, relating to implicit TensorFlow's internal logic requirements.\n\nLevel 3 (Hybrid Patterns): IC-2 (Inter-argument Contract)\nThis label accurately describes the violation as it involves the interdependence between two arguments (logits and labels). The API expects them to be structured as a distribution over multiple classes (probabilities summing to 1), and this requirement was violated because the input was only a single value and not a valid distribution.\n\nLeaf Contract Category: IC-2 (Inter-argument Contract)\nThis category explicitly matches the Level 3 pattern. It highlights the requirement that labels and logits inputs must form a proper probability distribution for meaningful cross-entropy computation, which was not satisfied here.\n\nRoot Cause: Missing Input Value/Type Dependency\nThe main reason for the problem is the misunderstanding or lack of proper input format and dependency. The function tf.nn.softmax_cross_entropy_with_logits internally expects inputs in the form of logits over multiple classes, and labels that represent a distribution (such as one-hot encoded vectors). A single numeric value does not fulfill these requirements.\n\nEffect: IF (Incorrect Functionality)\nAlthough the TensorFlow API does not crash, it returns an incorrect output (zero), indicating incorrect functionality instead of expected results. The operation completes without errors but with unintended results due to incorrect inputs.\n\nML Library: TensorFlow\nThe specific API function (tf.nn.softmax_cross_entropy_with_logits) is from TensorFlow, making it the clearly identified ML library.\n\nContract Violation Location: Model Construction\nThe issue arises during the definition and initial computation of the model (the cross-entropy calculation), thus occurring during the construction of the computational graph in TensorFlow.\n\nDetection Technique: Static\nThe incorrect input format for softmax_cross_entropy_with_logits can be detected through static analysis by inspecting the provided source code and API documentation without needing to execute the code."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/17455302",
    "title": "",
    "question": "8\n\nThis is odd. I can successfully run the example grid_search_digits.py. However, I am unable to do a grid search on my own data.\n\nI have the following setup:\n\nimport sklearn\nfrom sklearn.svm import SVC\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.cross_validation import LeaveOneOut\nfrom sklearn.metrics import auc_score\n\n# ... Build X and y ....\n\ntuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n                     'C': [1, 10, 100, 1000]},\n                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n\nloo = LeaveOneOut(len(y))\nclf = GridSearchCV(SVC(C=1), tuned_parameters, score_func=auc_score)\nclf.fit(X, y, cv=loo)\n....\nprint clf.best_estimator_\n....\nBut I never get passed clf.fit (I left it run for ~1hr).\n\nI have tried also with\n\nclf.fit(X, y, cv=10)\nand with\n\nskf = StratifiedKFold(y,2)\nclf.fit(X, y, cv=skf)\nand had the same problem (it never finishes the clf.fit statement). My data is simple:\n\n> X.shape\n(27,26)\n\n> y.shape\n27\n\n> numpy.sum(y)\n5\n\n> y.dtype\ndtype('int64')\n\n>?y\nType:       ndarray\nString Form:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1]\nLength:     27\nFile:       /home/jacob04/opt/python/numpy/numpy-1.7.1/lib/python2.7/site-\npackages/numpy/__init__.py                                                \nDocstring:  \nClass Docstring:\nndarray(shape, dtype=float, buffer=None, offset=0,\n        strides=None, order=None)\n\n> ?X\nType:       ndarray\nString Form:\n       [[ -3.61238468e+03  -3.61253920e+03  -3.61290196e+03  -3.61326679e+03\n           7.84590361e+02   0.0000  0000e+00   2.22389150e+00   2.53252959e+00 \n           2.11606216e+00  -1.99613432e+05  -1.99564828e+05]]\nLength:     27\nFile:       /home/jacob04/opt/python/numpy/numpy-1.7.1/lib/python2.7/site-\npackages/numpy/__init__.py                                                \nDocstring:  \nClass Docstring:\nndarray(shape, dtype=float, buffer=None, offset=0,\n        strides=None, order=None)\nThis is all with the latest version of scikit-learn (0.13.1) and:\n\n$ pip freeze\nCython==0.19.1\nPIL==1.1.7\nPyXB==1.2.2\nPyYAML==3.10\nargparse==1.2.1\ndistribute==0.6.34\nepc==0.0.5\nipython==0.13.2\njedi==0.6.0\nmatplotlib==1.3.x\nnltk==2.0.4\nnose==1.3.0\nnumexpr==2.1\nnumpy==1.7.1\npandas==0.11.0\npyparsing==1.5.7\npython-dateutil==2.1\npytz==2013b\nrpy2==2.3.1\nscikit-learn==0.13.1\nscipy==0.12.0\nsexpdata==0.0.3\nsix==1.3.0\nstemming==1.0.1\n-e git+https://github.com/PyTables/PyTables.git@df7b20444b0737cf34686b5d88b4e674ec85575b#egg=tables-dev\ntornado==3.0.1\nwsgiref==0.1.2\nThe odd thing is that fitting a single SVM is extremely fast:\n\n>  %timeit clf2 = svm.SVC(); clf2.fit(X,y)                                                                                                             \n1000 loops, best of 3: 328 us per loop\nUpdate\nI have noticed that if I pre-scale the data with:\n\nfrom sklearn import preprocessing\nX = preprocessing.scale(X) \nthe grid search is extremely fast.\n\nWhy? Why does GridSearchCV is so sensitive to scaling while a regular svm.SVC().fit is not?",
    "answer": "13\n\nAs noted already, for SVM-based Classifiers ( as y == np.int* ) preprocessing is a must, otherwise the ML-Estimator's prediction capability is lost right by skewed features' influence onto a decission function.\n\nAs objected the processing times:\n\ntry to get better view what is your AI/ML-Model Overfit/Generalisation [C,gamma] landscape\ntry to add verbosity into the initial AI/ML-process tuning\ntry to add n_jobs into the number crunching\ntry to add Grid Computing move into your computation approach if scale requires\n.\n\naGrid = aML_GS.GridSearchCV( aClassifierOBJECT,\n                                    param_grid = aGrid_of_parameters,\n                                    cv         = cv,\n                                    n_jobs     = n_JobsOnMultiCpuCores,\n                                    verbose    = 5 )\nSometimes, the GridSearchCV() can indeed take a huge amount of CPU-time / CPU-poolOfRESOURCEs, even after all the above mentioned tips are used.\n\nSo, keep calm and do not panic, if you are sure the Feature-Engineering, data-sanity & FeatureDOMAIN preprocessing was done correctly.\n\n[GridSearchCV] ................ C=16777216.0, gamma=0.5, score=0.761619 -62.7min\n[GridSearchCV] C=16777216.0, gamma=0.5 .........................................\n[GridSearchCV] ................ C=16777216.0, gamma=0.5, score=0.792793 -64.4min\n[GridSearchCV] C=16777216.0, gamma=1.0 .........................................\n[GridSearchCV] ............... C=16777216.0, gamma=1.0, score=0.793103 -116.4min\n[GridSearchCV] C=16777216.0, gamma=1.0 .........................................\n[GridSearchCV] ............... C=16777216.0, gamma=1.0, score=0.794603 -205.4min\n[GridSearchCV] C=16777216.0, gamma=1.0 .........................................\n[GridSearchCV] ............... C=16777216.0, gamma=1.0, score=0.771772 -200.9min\n[GridSearchCV] C=16777216.0, gamma=2.0 .........................................\n[GridSearchCV] ............... C=16777216.0, gamma=2.0, score=0.713643 -446.0min\n[GridSearchCV] C=16777216.0, gamma=2.0 .........................................\n[GridSearchCV] ............... C=16777216.0, gamma=2.0, score=0.743628 -184.6min\n[GridSearchCV] C=16777216.0, gamma=2.0 .........................................\n[GridSearchCV] ............... C=16777216.0, gamma=2.0, score=0.761261 -281.2min\n[GridSearchCV] C=16777216.0, gamma=4.0 .........................................\n[GridSearchCV] ............... C=16777216.0, gamma=4.0, score=0.670165 -138.7min\n[GridSearchCV] C=16777216.0, gamma=4.0 .........................................\n[GridSearchCV] ................ C=16777216.0, gamma=4.0, score=0.760120 -97.3min\n[GridSearchCV] C=16777216.0, gamma=4.0 .........................................\n[GridSearchCV] ................ C=16777216.0, gamma=4.0, score=0.732733 -66.3min\n[GridSearchCV] C=16777216.0, gamma=8.0 .........................................\n[GridSearchCV] ................ C=16777216.0, gamma=8.0, score=0.755622 -13.6min\n[GridSearchCV] C=16777216.0, gamma=8.0 .........................................\n[GridSearchCV] ................ C=16777216.0, gamma=8.0, score=0.772114 - 4.6min\n[GridSearchCV] C=16777216.0, gamma=8.0 .........................................\n[GridSearchCV] ................ C=16777216.0, gamma=8.0, score=0.717718 -14.7min\n[GridSearchCV] C=16777216.0, gamma=16.0 ........................................\n[GridSearchCV] ............... C=16777216.0, gamma=16.0, score=0.763118 - 1.3min\n[GridSearchCV] C=16777216.0, gamma=16.0 ........................................\n[GridSearchCV] ............... C=16777216.0, gamma=16.0, score=0.746627 -  25.4s\n[GridSearchCV] C=16777216.0, gamma=16.0 ........................................\n[GridSearchCV] ............... C=16777216.0, gamma=16.0, score=0.738739 -  44.9s\n[Parallel(n_jobs=1)]: Done 2700 out of 2700 | elapsed: 5670.8min finished\nAs have asked above about \"... a regular svm.SVC().fit \" kindly notice, it uses default [C,gamma] values and thus have no relevance to behaviour of your Model / ProblemDOMAIN.\n\nRe: Update\noh yes indeed, regularisation/scaling of SVM-inputs is a mandatory task for this AI/ML tool. scikit-learn has a good instrumentation to produce and re-use aScalerOBJECT for both a-priori scaling ( before aDataSET goes into .fit() ) & ex-post ad-hoc scaling, once you need to re-scale a new example and send it to the predictor to answer it's magic via a request to\nanSvmCLASSIFIER.predict( aScalerOBJECT.transform( aNewExampleX ) )\n\n( Yes, aNewExampleX may be a matrix, so asking for a \"vectorised\" processing of several answers )\n\nPerformance relief of O( M 2 . N 1 ) computational complexity\nIn contrast to the below posted guess, that the Problem-\"width\", measured as N == a number of SVM-Features in matrix X is to be blamed for an overall computing time, the SVM classifier with rbf-kernel is by-design an O( M 2 . N 1 ) problem.\n\nSo, there is quadratic dependence on the overall number of observations ( examples ), moved into a Training ( .fit() ) or CrossValidation phase and one can hardly state, that the supervised learning classifier will get any better predictive power if one \"reduces\" the ( linear only ) \"width\" of features, that per se bear the inputs into the constructed predictive power of the SVM-classifier, don't they?",
    "mlApiName": "sklearn.grid_search.GridSearchCV,sklearn.preprocessing.StandardScaler.scale",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SAI",
      "level3": "G,IC-1",
      "leafContractCategory": "SAM (Level 3) ? AMO(Level 2)",
      "rootCause": "Missing Input value-Method order Dependency",
      "effect": "BP",
      "mlLibrary": "Scikit-learn",
      "contractViolationLocation": "Data Preprocessing",
      "detectionTechnique": "Runtime Checking",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): Hybrid This post involves multiple APIs from Scikit-learn: GridSearchCV and StandardScaler. The issue arises from their interaction, indicating a hybrid contract violation.\n\nLevel 2: SAI (SAM-AMO Interdependency) The problem is due to an interdependency between API methods�the data preprocessing step (StandardScaler) and grid search step (GridSearchCV)�which must be used in the correct order.\n\nLevel 3 (Hybrid Patterns): G (Always), IC-1 (Intra-argument Contract) The error always occurs when GridSearchCV is applied without proper feature scaling. It also represents an intra-argument violation since GridSearchCV expects scaled input data for optimal performance.\n\nLeaf Contract Category: SAM (Level 3) ? AMO (Level 2) Explicitly indicates the violation arises due to the SAM-AMO interdependency: data scaling (SAM) must occur before the hyperparameter optimization step (AMO).\n\nRoot Cause: Missing Input value-Method order Dependency The issue occurs specifically because the GridSearchCV method heavily depends on scaled input values, which was not provided before executing GridSearchCV.\n\nEffect: BP (Bad Performance) The absence of scaling resulted in extremely slow performance and stalled execution, indicating performance degradation rather than a crash or incorrect output.\n\nML Library: Scikit-learn Clearly indicates Scikit-learn as the affected ML library.\n\nContract Violation Location: Data Preprocessing Violation specifically occurred in the preprocessing stage as scaling was not correctly applied.\n\nDetection Technique: Runtime Checking The issue manifests and is detected at runtime, observed by the unexpected and significant slowdown during execution."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/33474424",
    "title": "",
    "question": "11\n\nI'm using the Keras library to create a neural network. I have a iPython Notebook in order to load the training data, initializing the network and \"fit\" the weights of the neural network. Finally, I save the weights using the save_weights() method. Code is below :\n\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom keras.optimizers import SGD\nfrom keras.regularizers import l2\nfrom keras.callbacks import History\n\n[...]\n\ninput_size = data_X.shape[1]\noutput_size = data_Y.shape[1]\nhidden_size = 100\nlearning_rate = 0.01\nnum_epochs = 100\nbatch_size = 75\n\nmodel = Sequential()\nmodel.add(Dense(hidden_size, input_dim=input_size, init='uniform'))\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(hidden_size))\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(output_size))\nmodel.add(Activation('tanh'))\n\nsgd = SGD(lr=learning_rate, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='mse', optimizer=sgd)\n\nmodel.fit(X_NN_part1, Y_NN_part1, batch_size=batch_size, nb_epoch=num_epochs, validation_data=(X_NN_part2, Y_NN_part2), callbacks=[history])\n\ny_pred = model.predict(X_NN_part2) # works well\n\nmodel.save_weights('keras_w')\nThen, in another iPython Notebook, I just want to use these weights and predict some outputs values given inputs. I initialize the same neural network, and then load the weights.\n\n# same headers\ninput_size = 37\noutput_size = 40\nhidden_size = 100\n\nmodel = Sequential()\nmodel.add(Dense(hidden_size, input_dim=input_size, init='uniform'))\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(hidden_size))\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(output_size))\nmodel.add(Activation('tanh'))\n\nmodel.load_weights('keras_w') \n#no error until here\n\ny_pred = model.predict(X_nn)\nThe problem is that apparently, the load_weights method is not enough to have a functional model. I'm getting an error :\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\n in ()\n  1 \n----> 2 y_pred = model.predict(X_nn)\nC:\\XXXXXXX\\Local\\Continuum\\Anaconda\\lib\\site-packages\\keras\\models.pyc in predict(self, X, batch_size, verbose)\n491     def predict(self, X, batch_size=128, verbose=0):\n492         X = standardize_X(X)\n--> 493         return self._predict_loop(self._predict, X, batch_size, verbose)[0]\n494 \n495     def predict_proba(self, X, batch_size=128, verbose=1):\n\nAttributeError: 'Sequential' object has no attribute '_predict'\nAny idea? Thanks a lot.",
    "answer": "14\n\nYou need to call model.compile. This can be done either before or after the model.load_weights call but must be after the model architecture is specified and before the model.predict call.",
    "mlApiName": " keras.layers.model.compile, keras.models.load_weights, keras.models.predict,keras.layers.add",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "F,F",
      "leafContractCategory": "AMO(Level-2)",
      "rootCause": "Missing Options",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Prediction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): Hybrid Multiple Keras API methods (model.compile, model.load_weights, model.predict, and layers.add) interact, leading to a hybrid contract violation.\n\nLevel 2: SL (Sequence of Calls) The problem arises due to incorrect sequence or omission of calls (model.compile not called before model.predict).\n\nLevel 3 (Hybrid Patterns): F, F (Functionality) The issue relates explicitly to functionality�methods (load_weights and compile) must be used together correctly to ensure the model can predict.\n\nLeaf Contract Category: AMO(Level-2) Violation occurs at AMO Level-2 since the necessary method (compile) is missing when using previously saved weights for predictions.\n\nRoot Cause: Missing Options Essential method (compile) and associated options (optimizer and loss function) weren't provided, causing the model's functionality to fail.\n\nEffect: Crash Missing the compile call causes the program to crash with an AttributeError.\n\nML Library: Keras The APIs involved belong explicitly to the Keras framework.\n\nContract Violation Location: Prediction The error manifests when attempting prediction without proper initialization (compile).\n\nDetection Technique: Static This error could be detected statically by identifying the absence of the required compile call after weight loading."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/48547688",
    "title": "",
    "question": "38\n\nUsing Keras from Tensorflow 1.4.1, how does one copy weights from one model to another?\n\nAs some background, I'm trying to implement a deep-q network (DQN) for Atari games following the DQN publication by DeepMind. My understanding is that the implementation uses two networks, Q and Q'. The weights of Q are trained using gradient descent, and then the weights are copied periodically to Q'.\n\nHere's how I build Q and Q':\n\nACT_SIZE   = 4\nLEARN_RATE = 0.0025\nOBS_SIZE   = 128\n\ndef buildModel():\n  model = tf.keras.models.Sequential()\n\n  model.add(tf.keras.layers.Lambda(lambda x: x / 255.0, input_shape=OBS_SIZE))\n  model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n  model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n  model.add(tf.keras.layers.Dense(ACT_SIZE, activation=\"linear\"))\n  opt = tf.keras.optimizers.RMSprop(lr=LEARN_RATE)\n\n  model.compile(loss=\"mean_squared_error\", optimizer=opt)\n\n  return model\nI call that twice to get Q and Q'.\n\nI have an updateTargetModel method below that is my attempt at copying weights. The code runs fine, but my overall DQN implementation is failing. I'm really just trying to verify if this is a valid way of copying weights from one network to another.\n\ndef updateTargetModel(model, targetModel):\n  modelWeights       = model.trainable_weights\n  targetModelWeights = targetModel.trainable_weights\n\n  for i in range(len(targetModelWeights)):\n    targetModelWeights[i].assign(modelWeights[i])\nThere's another question here that discusses saving and loading weights to and from disk (Tensorflow Copy Weights Issue), but there's no accepted answer. There is also a question about loading weights from individual layers (Copying weights from one Conv2D layer to another), but I'm wanting to copy the entire model's weights.",
    "answer": "82\n\nActually what you've done is much more than simply copying weights. You made these two models identical all the time. Every time you update one model - the second one is also updated - as both models have the same weights variables.\n\nIf you want to just copy weights - the simplest way is by this command:\n\ntarget_model.set_weights(model.get_weights())",
    "mlApiName": "keras.models.model.target_model.set_weights",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "Unknown",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): SAM (Single API Method)\nThe violation relates specifically to misuse of a single Keras API method (set_weights), thus fitting a SAM contract violation.\n\nLevel 2: BET (Behavioral Error Type)\nThe error is related to incorrect behavior or usage of the set_weights API call due to misunderstanding how weights assignment should be done in Keras.\n\nLevel 3 (Hybrid Patterns): IC-1 (Internal Call-1)\nThe error emerges from the incorrect internal use of TensorFlow variables and assignment operation instead of the Keras-specific method (get_weights() and set_weights()).\n\nLeaf Contract Category: IC-1 (Internal Call-1)\nThe leaf category specifically reflects the incorrect internal call operation used directly on the TensorFlow variables (assign method) instead of using the higher-level Keras methods (set_weights, get_weights).\n\nRoot Cause: Unacceptable Input Value\nThe root cause is passing TensorFlow internal weight variables directly (instead of Keras weight arrays) to the assign operation, causing unintended sharing of variables rather than a one-time copying of weights.\n\nEffect: Unknown\nThe exact effect isn't clearly described as a crash or infinite loop, hence labeled as \"Unknown.\"\n\nML Library: Keras\nIssue pertains specifically to the Keras framework.\n\nContract Violation Location: Model Construction\nThe error occurs during model construction or initialization, as the issue involves initializing weights from one model to another incorrectly.\n\nDetection Technique: Static\nThe issue can be identified via static analysis by inspecting the incorrect usage patterns (assign rather than set_weights/get_weights).\n\n\n\n"
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/51109639",
    "title": "",
    "question": "7\n\nWhenever I try out LSTM models on Keras, it seems that the model is impossible to train due to long training time.\n\nFor instance, a model like this takes 80 seconds per step to train.:\n\ndef create_model(self):\n        inputs = {}\n        inputs['input'] = []\n        lstm = []\n        placeholder = {}\n        for tf, v in self.env.timeframes.items():\n            inputs[tf] = Input(shape = v['shape'], name = tf)\n            lstm.append(LSTM(8)(inputs[tf]))\n            inputs['input'].append(inputs[tf])\n        account = Input(shape = (3,), name = 'account')\n        account_ = Dense(8, activation = 'relu')(account)\n        dt = Input(shape = (7,), name = 'dt')\n        dt_ = Dense(16, activation = 'relu')(dt)\n        inputs['input'].extend([account, dt])\n\n        data = Concatenate(axis = 1)(lstm)\n        data = Dense(128, activation = 'relu')(data)\n        y = Concatenate(axis = 1)([data, account, dt])\n        y = Dense(256, activation = 'relu')(y)\n        y = Dense(64, activation = 'relu')(y)\n        y = Dense(16, activation = 'relu')(y)\n        output = Dense(3, activation = 'linear')(y)\n\n        model = Model(inputs = inputs['input'], outputs = output)\n        model.compile(loss = 'mse', optimizer = 'adam', metrics = ['mae'])\n        return model\nWhereas model which has LSTM substituded with Flatten + Dense like this:\n\ndef create_model(self):\n        inputs = {}\n        inputs['input'] = []\n        lstm = []\n        placeholder = {}\n        for tf, v in self.env.timeframes.items():\n            inputs[tf] = Input(shape = v['shape'], name = tf)\n            #lstm.append(LSTM(8)(inputs[tf]))\n            placeholder[tf] = Flatten()(inputs[tf])\n            lstm.append(Dense(32, activation = 'relu')(placeholder[tf]))\n            inputs['input'].append(inputs[tf])\n        account = Input(shape = (3,), name = 'account')\n        account_ = Dense(8, activation = 'relu')(account)\n        dt = Input(shape = (7,), name = 'dt')\n        dt_ = Dense(16, activation = 'relu')(dt)\n        inputs['input'].extend([account, dt])\n\n        data = Concatenate(axis = 1)(lstm)\n        data = Dense(128, activation = 'relu')(data)\n        y = Concatenate(axis = 1)([data, account, dt])\n        y = Dense(256, activation = 'relu')(y)\n        y = Dense(64, activation = 'relu')(y)\n        y = Dense(16, activation = 'relu')(y)\n        output = Dense(3, activation = 'linear')(y)\n\n        model = Model(inputs = inputs['input'], outputs = output)\n        model.compile(loss = 'mse', optimizer = 'adam', metrics = ['mae'])\n        return model\ntakes 45-50 ms per step to train.\n\nIs there something wrong in the model that is causing this? Or is this as fast as this model will run?\n\n-- self.env.timeframes looks like this: dictionary with 9 items\n\ntimeframes = {\n            's1': {\n                'lookback': 86400,\n                'word': '1 s',\n                'unit': 1,\n                'offset': 12\n                },\n            's5': {\n                'lookback': 200,\n                'word': '5 s',\n                'unit': 5,\n                'offset': 2\n                },\n            'm1': {\n                'lookback': 100,\n                'word': '1 min',\n                'unit': 60,\n                'offset': 0\n                },\n            'm5': {\n                'lookback': 100,\n                'word': '5 min',\n                'unit': 300,\n                'offset': 0\n                },\n            'm30': {\n                'lookback': 100,\n                'word': '30 min',\n                'unit': 1800,\n                'offset': 0\n                },\n            'h1': {\n                'lookback': 200,\n                'word': '1 h',\n                'unit': 3600,\n                'offset': 0\n                },\n            'h4': {\n                'lookback': 200,\n                'word': '4 h',\n                'unit': 14400,\n                'offset': 0\n                },\n            'h12': {\n                'lookback': 100,\n                'word': '12 h',\n                'unit': 43200,\n                'offset': 0\n                },\n            'd1': {\n                'lookback': 200,\n                'word': '1 d',\n                'unit': 86400,\n                'offset': 0\n                }\n            }\nGPU info from prompt -\n\n2018-06-30 07:35:16.204320: I T:\\src\\github\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n2018-06-30 07:35:16.495832: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1356] Found device 0 with properties:\nname: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.86\npciBusID: 0000:01:00.0\ntotalMemory: 8.00GiB freeMemory: 6.59GiB\n2018-06-30 07:35:16.495981: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1435] Adding visible gpu devices: 0\n2018-06-30 07:35:16.956743: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-06-30 07:35:16.956827: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:929]      0\n2018-06-30 07:35:16.957540: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:942] 0:   N\n2018-06-30 07:35:16.957865: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime",
    "answer": "9\n\nIf you are using GPU please replace all LSTM layers with CuDNNLSTM layers. You can import it from keras.layers:\n\nfrom keras.layers import  CuDNNLSTM\n\ndef create_model(self):\n    inputs = {}\n    inputs['input'] = []\n    lstm = []\n    placeholder = {}\n    for tf, v in self.env.timeframes.items():\n        inputs[tf] = Input(shape = v['shape'], name = tf)\n        lstm.append(CuDNNLSTM(8)(inputs[tf]))\n        inputs['input'].append(inputs[tf])\n    account = Input(shape = (3,), name = 'account')\n    account_ = Dense(8, activation = 'relu')(account)\n    dt = Input(shape = (7,), name = 'dt')\n    dt_ = Dense(16, activation = 'relu')(dt)\n    inputs['input'].extend([account, dt])\n\n    data = Concatenate(axis = 1)(lstm)\n    data = Dense(128, activation = 'relu')(data)\n    y = Concatenate(axis = 1)([data, account, dt])\n    y = Dense(256, activation = 'relu')(y)\n    y = Dense(64, activation = 'relu')(y)\n    y = Dense(16, activation = 'relu')(y)\n    output = Dense(3, activation = 'linear')(y)\n\n    model = Model(inputs = inputs['input'], outputs = output)\n    model.compile(loss = 'mse', optimizer = 'adam', metrics = ['mae'])\n    return model\nHere is more information: https://keras.io/layers/recurrent/#cudnnlstm\n\nThis will significantly speed up the model =)",
    "mlApiName": "keras.layers.CuDNNLSTM",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "BP",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Runtime Checking",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): SAM (Single API Method)\nThe violation involves a specific misuse of a single Keras API method (CuDNNLSTM), fitting into the SAM category.\n\nLevel 2: BET (Behavioral Error Type)\nThe behavioral issue stems from incorrect usage or understanding of how LSTM layers should be implemented for GPU optimization, thus classified under BET.\n\nLevel 3 (Hybrid Patterns): IC-1 (Internal Call-1)\nThe error arises due to internal calls within the Keras framework�specifically, incorrect selection of LSTM layers that don't leverage GPU optimizations provided by CuDNNLSTM.\n\nLeaf Contract Category: IC-1 (Internal Call-1)\nThe leaf category is identical to Level 3, pinpointing the precise internal call misuse involving GPU-accelerated layer implementations.\n\nRoot Cause: Unacceptable Input Value\nThe root cause is using standard LSTM layers instead of GPU-optimized CuDNNLSTM, which drastically affects training performance. The input provided (standard LSTM parameters) isn't appropriate for optimal GPU computation.\n\nEffect: BP (Bad Performance)\nThe outcome is severe performance degradation (extremely long training times), explicitly indicating a performance-related issue.\n\nML Library: Keras\nIssue is specifically related to Keras' layer implementation.\n\nContract Violation Location: Model Construction\nThe violation occurs at the model construction phase, where the layers are chosen and set up incorrectly for GPU use.\n\nDetection Technique: Runtime Checking\nThe issue was detected via runtime behavior, as the significant performance bottleneck becomes apparent only when the model executes (trains)."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/51763983",
    "title": "",
    "question": "14\n\nI'm training a model to predict the stock price and input data is close price. I use 45 days data to predict the 46th day's close price and a economic Indicator to be second feature, here is the model:\n\nmodel = Sequential()\nmodel.add( LSTM( 512, input_shape=(45, 2), return_sequences=True))\nmodel.add( LSTM( 512, return_sequences=True))\nmodel.add( (Dense(1)))\nmodel.compile(loss='mse', optimizer='adam')\nhistory = model.fit( X_train, y_train, batch_size = batchSize, epochs=epochs, shuffle = False)\nWhen I run this I get the following error:\n\nValueError: Error when checking target: expected dense_1 to have 3 dimensions, but got array with shape (118, 1)\n\nHowever, I print the shape of data and they are:\n\nX_train:(118, 45, 2)\ny_train:(118, 1)\nI have no idea why the model is expecting a 3 dimensional output when y_train is (118, 1). Where am I wrong and what should I do?",
    "answer": "16\n\nYour second LSTM layer also returns sequences and Dense layers by default apply the kernel to every timestep also producing a sequence:\n\n# (bs, 45, 2)\nmodel.add( LSTM( 512, input_shape=(45, 2), return_sequences=True))\n# (bs, 45, 512)\nmodel.add( LSTM( 512, return_sequences=True))\n# (bs, 45, 512)\nmodel.add( (Dense(1)))\n# (bs, 45, 1)\nSo your output is shape (bs, 45, 1). To solve the problem you need to set return_sequences=False in your second LSTM layer which will compress sequence:\n\n# (bs, 45, 2)\nmodel.add( LSTM( 512, input_shape=(45, 2), return_sequences=True))\n# (bs, 45, 512)\nmodel.add( LSTM( 512, return_sequences=False)) # SET HERE\n# (bs, 512)\nmodel.add( (Dense(1)))\n# (bs, 1)\nAnd you'll get the desired output. Note bs is the batch size.",
    "mlApiName": "keras.models.fit",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "DT",
      "level3": "BIT",
      "leafContractCategory": "BIT",
      "rootCause": "Unacceptable Input Type",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Evaluation",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category):\n\nSAM (Single API Method): The problem specifically arises from misuse of a single API method (model.fit from Keras).\nLevel 2:\n\nDT (Data Type): The error is caused by an incompatibility in data shape and dimensionality between provided training labels (y_train) and what the model expects.\nLevel 3 (Hybrid Patterns):\n\nBIT (Built-in Type): The issue involves built-in data structures (tensors), specifically the shape of tensors fed into the neural network layers.\nLeaf Contract Category:\n\nBIT (Built-in Type): The core issue relates directly to built-in tensor types and their dimensional shapes expected by the model.\nRoot Cause:\n\nUnacceptable Input Type: The shape of y_train tensor is incorrect (2D) when a 3D tensor is expected due to improper configuration of LSTM layers (return_sequences=True).\nEffect:\n\nCrash: This input incompatibility directly results in a runtime crash (ValueError).\nML Library:\n\nKeras: The labeling pertains specifically to Keras methods (model.fit) in model training.\nContract Violation Location:\n\nModel Evaluation: The error emerges during model evaluation (training phase), specifically during the fitting of training data.\nDetection Technique:\n\nStatic: The error is statically detectable by simply reviewing the model architecture and data shape without executing the training process.\n\n"
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/42264649",
    "title": "",
    "question": "41\n\nI'm following this tutorial (section 6: Tying it All Together), with my own dataset. I can get the example in the tutorial working, no problem, with the sample dataset provided.\n\nI'm getting a binary cross-entropy error that is negative, and no improvements as epochs progress. I'm pretty sure binary cross-entropy should always be positive, and I should see some improvement in the loss. I've truncated the sample output (and code call) below to 5 epochs. Others seem to run into similar problems sometimes when training CNNs, but I didn't see a clear solution in my case. Does anyone know why this is happening?\n\nSample output:\n\nCreating TensorFlow device (/gpu:2) -> (device: 2, name: GeForce GTX TITAN Black, pci bus id: 0000:84:00.0)\n10240/10240 [==============================] - 2s - loss: -5.5378 - acc: 0.5000 - val_loss: -7.9712 - val_acc: 0.5000\nEpoch 2/5\n10240/10240 [==============================] - 0s - loss: -7.9712 - acc: 0.5000 - val_loss: -7.9712 - val_acc: 0.5000\nEpoch 3/5\n10240/10240 [==============================] - 0s - loss: -7.9712 - acc: 0.5000 - val_loss: -7.9712 - val_acc: 0.5000\nEpoch 4/5\n10240/10240 [==============================] - 0s - loss: -7.9712 - acc: 0.5000 - val_loss: -7.9712 - val_acc: 0.5000\nEpoch 5/5\n10240/10240 [==============================] - 0s - loss: -7.9712 - acc: 0.5000 - val_loss: -7.9712 - val_acc: 0.5000\nMy code:\n\nimport numpy as np\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndataset = np.loadtxt('train_rows.csv', delimiter=\",\")\ntestset = np.loadtxt('test_rows.csv', delimiter=\",\")\n\n# split into input (X) and output (Y) variables\nX = dataset[:, :62]\nY = dataset[:, 62]\n\nX_test = testset[:, :62]\nY_test = testset[:, 62]\n\n### create model\nmodel = Sequential()\nmodel.add(Dense(100, input_dim=(62,), activation='relu'))\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n## Fit the model\nmodel.fit(X, Y, validation_data=(X_test, Y_test), epochs=5, batch_size=128)",
    "answer": "48\n\nI should have printed out my response variable. The categories were labelled as 1 and 2 instead of 0 and 1, which confused the classifier.",
    "mlApiName": "keras.models.fit",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "IF",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Train",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category):\n\nSAM (Single API Method): The issue specifically occurs during the invocation of model.fit() from Keras.\nLevel 2:\n\nBET (Behavioral Expectation): The unexpected behavior of negative loss values in binary cross-entropy indicates a violation of expected API behavior.\nLevel 3 (Hybrid Patterns):\n\nIC-1 (Incorrect Computation): The negative loss values indicate incorrect calculations due to improperly formatted labels.\nLeaf Contract Category:\n\nIC-1 (Incorrect Computation): The underlying issue is a computational misinterpretation of input labels, leading to erroneous loss calculation.\nRoot Cause:\n\nUnacceptable Input Value: Labels provided were incorrectly encoded as (1, 2) instead of the required (0, 1), causing the model's loss calculation to malfunction.\nEffect:\n\nIF (Incorrect Functionality): Although training didn't crash, the output was functionally incorrect (negative loss), indicating a malfunction in model training.\nML Library:\n\nKeras: The issue is directly related to Keras methods (model.fit) during model training.\nContract Violation Location:\n\nTrain: The contract violation occurred during the training phase, specifically while fitting data into the neural network.\nDetection Technique:\n\nStatic: This problem can be identified by examining the labels and model architecture statically, without runtime execution.\n\n"
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/42284873",
    "title": "",
    "question": "9\n\nI'm using the ImageDataGenerator inside Keras to read a directory of images. I'd like to save the result inside a numpy array, so I can do further manipulations and save it to disk in one file.\n\nflow_from_directory() returns an iterator, which is why I tried the following\n\nitr = gen.flow_from_directory('data/train/', batch_size=1, target_size=(32,32))\nimgs = np.concatenate([itr.next() for i in range(itr.nb_sample)])\nbut that produced\n\nValueError: could not broadcast input array from shape (32,32,3) into shape (1)\nI think I'm misusing the concatenate() function, but I can't figure out where I fail.",
    "answer": "19\n\nI had the same problem and solved it the following way: itr.next returns the next batch of images as two numpy.ndarray objects: batch_x, batch_y. (Source: keras/preprocessing/image.py) So what you can do is set the batch_size for flow_from_directory to the size of your whole train dataset.\n\nExample, my whole training set consists of 1481 images:\n\ntrain_datagen = ImageDataGenerator(rescale=1. / 255)\nitr = train_datagen.flow_from_directory(\ntrain_data_dir,\ntarget_size=(img_width, img_height),\nbatch_size=1481,\nclass_mode='categorical')\n\nX, y = itr.next()",
    "mlApiName": "keras.preprocessing.image.ImageDataGenerator.flow_from_directory",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Load",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category):\n\nSAM (Single API Method): The issue specifically arises during the use of the single Keras method flow_from_directory().\nLevel 2:\n\nBET (Behavioral Expectation): The user expects the iterator output to directly concatenate into a numpy array, but the API behavior is not aligned with this expectation.\nLevel 3 (Hybrid Patterns):\n\nIC-1 (Incorrect Computation): The misuse of numpy's concatenate function leads to incorrect dimensional computations, resulting in a shape mismatch.\nLeaf Contract Category:\n\nIC-1 (Incorrect Computation): The specific issue lies in incorrectly computing the shapes for numpy array concatenation due to misunderstanding the iterator output.\nRoot Cause:\n\nUnacceptable Input Value: The shape mismatch (attempting to broadcast arrays of shape (32,32,3) into (1,)) is the result of using incorrect array shapes for the concatenation.\nEffect:\n\nCrash: The incorrect array concatenation attempt directly results in a runtime crash (ValueError).\nML Library:\n\nKeras: Specifically related to Keras's ImageDataGenerator.flow_from_directory() method.\nContract Violation Location:\n\nLoad: The error occurs while loading data from a directory, specifically during data preprocessing/loading phase.\nDetection Technique:\n\nStatic: The incorrect usage can be identified statically by inspecting the shape expectations of numpy array operations without needing runtime execution."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/42886049",
    "title": "",
    "question": "10\n\nI am trying to train 1000x of Sequential models in a loop. In every loop my program leaks memory until I run out and get an OOM exception.\n\nI already asked a similar question before (Training multiple Sequential models in a row slows down)\n\nand have seen others in similar problems (Keras: Out of memory when doing hyper parameter grid search)\n\nand the solution is always to add K.clear_session() to your code after you have finished using the model. So I did that in my previous question and I am still leaking memory\n\nHere is code to reproduce the issue.\n\nimport random\nimport time\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras import backend as K\nimport tracemalloc\n\ndef run():\n    tracemalloc.start()\n    num_input_nodes = 12\n    num_hidden_nodes = 8\n    num_output_nodes = 1\n\n    random_numbers = random.sample(range(1000), 50)\n    train_x, train_y = create_training_dataset(random_numbers, num_input_nodes)\n\n    for i in range(100):\n        snapshot = tracemalloc.take_snapshot()\n        for j in range(10):\n            start_time = time.time()\n            nn = Sequential()\n            nn.add(Dense(num_hidden_nodes, input_dim=num_input_nodes, activation='relu'))\n            nn.add(Dense(num_output_nodes))\n            nn.compile(loss='mean_squared_error', optimizer='adam')\n            nn.fit(train_x, train_y, nb_epoch=300, batch_size=2, verbose=0)\n            K.clear_session()\n            print(\"Iteration {iter}. Current time {t}. Took {elapsed} seconds\".\n                  format(iter=i*10 + j + 1, t=time.strftime('%H:%M:%S'), elapsed=int(time.time() - start_time)))\n\n        top_stats = tracemalloc.take_snapshot().compare_to(snapshot, 'lineno')\n\n        print(\"[ Top 5 differences ]\")\n        for stat in top_stats[:5]:\n            print(stat)\n\ndef create_training_dataset(dataset, input_nodes):\n    \"\"\"\n    Outputs a training dataset (train_x, train_y) as numpy arrays.\n    Each item in train_x has 'input_nodes' number of items while train_y items are of size 1\n    :param dataset: list of ints\n    :param input_nodes:\n    :return: (numpy array, numpy array), train_x, train_y\n    \"\"\"\n    data_x, data_y = [], []\n    for i in range(len(dataset) - input_nodes - 1):\n        a = dataset[i:(i + input_nodes)]\n        data_x.append(a)\n        data_y.append(dataset[i + input_nodes])\n    return numpy.array(data_x), numpy.array(data_y)\n\nrun()\nHere is the output I get from the first memory debug print\n\n/tensorflow/python/framework/ops.py:121: size=3485 KiB (+3485 KiB), count=42343 (+42343) /tensorflow/python/framework/ops.py:1400: size=998 KiB (+998 KiB), count=8413 (+8413) /tensorflow/python/framework/ops.py:116: size=888 KiB (+888 KiB), count=32468 (+32468) /tensorflow/python/framework/ops.py:1185: size=795 KiB (+795 KiB), count=3179 (+3179) /tensorflow/python/framework/ops.py:2354: size=599 KiB (+599 KiB), count=5886 (+5886)\n\nSystem info:\n\npython 3.5\nkeras (1.2.2)\ntensorflow(1.0.0)",
    "answer": "13\n\nThe memory leak stems from Keras and TensorFlow using a single \"default graph\" to store the network structure, which increases in size with each iteration of the inner for loop.\n\nCalling K.clear_session() frees some of the (backend) state associated with the default graph between iterations, but an additional call to tf.reset_default_graph() is needed to clear the Python state.\n\nNote that there might be a more efficient solution: since nn does not depend on either of the loop variables, you can define it outside the loop, and reuse the same instance inside the loop. If you do that, there is no need to clear the session or reset the default graph, and performance should increase because you benefit from caching between iterations.",
    "mlApiName": " keras.backend.clear_session,keras.models.fit",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "G",
      "level3": "G",
      "leafContractCategory": "G",
      "rootCause": "Missing Required Method Order",
      "effect": "MOB",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Train",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category):\n\nAMO (API Method Order): The problem is related to the order in which API methods are called. Specifically, not calling the necessary API methods in the correct sequence results in memory leaks.\nLevel 2:\n\nG (Graph-Related): The issue pertains to TensorFlow�s computational graph that keeps expanding as models are repeatedly created without properly clearing or resetting it.\nLevel 3 (Hybrid Patterns):\n\nG (Graph-Related): As above, the issue is graph-related. TensorFlow/Keras internally maintains a graph that needs to be explicitly reset between training iterations, otherwise memory continues to accumulate.\nLeaf Contract Category:\n\nG (Graph-Related): The specific nature of the issue remains graph-related due to the absence of a required graph reset operation.\nRoot Cause:\n\nMissing Required Method Order: The problem occurs because the necessary sequence of API method calls (tf.reset_default_graph() after K.clear_session()) is not followed. Only clearing the session is insufficient to fully clean the graph.\nEffect:\n\nMOB (Memory Out of Bound): The cumulative buildup of the computational graph leads to a significant memory leak, eventually causing an Out Of Memory (OOM) exception.\nML Library:\n\nKeras: Specifically pertains to Keras�s interaction with TensorFlow backend methods for graph management.\nContract Violation Location:\n\nTrain: The issue appears during repeated training phases, where each iteration incorrectly handles the graph, causing memory usage to continuously increase.\nDetection Technique:\n\nStatic: The problem can be detected through static analysis by observing the sequence of API method calls (missing tf.reset_default_graph()) needed for proper memory management."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/43178668",
    "title": "",
    "question": "35\n\nI want to compare the computation time between different models. During the fit the computation time per epoch is printed to the console.\n\nEpoch 5/5\n160000/160000 [==============================] - **10s** ......\nI'm looking for a way to store these times in a similar way to the model metrics that are saved in each epoch and avaliable through the history object.",
    "answer": "Try the following callback:\n\nclass TimeHistory(keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.times = []\n\n    def on_epoch_begin(self, batch, logs={}):\n        self.epoch_time_start = time.time()\n\n    def on_epoch_end(self, batch, logs={}):\n        self.times.append(time.time() - self.epoch_time_start)\nThen:\n\ntime_callback = TimeHistory()\nmodel.fit(..., callbacks=[..., time_callback],...)\ntimes = time_callback.times\nIn this case times should store the epoch computation times.",
    "mlApiName": "keras.models.fit",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "Unknown",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Train",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category):\n\nSAM (Single API Method):\nThe issue specifically involves the single API method keras.models.fit.\nLevel 2:\n\nBET (Behavioral Expectation Type):\nThe user's expectation for capturing the training time per epoch is not directly supported by default API behavior, hence involving an incorrect expectation.\nLevel 3 (Hybrid Patterns):\n\nIC-1 (Incorrect Computation):\nThe problem stems from the incorrect expectation that the training time per epoch will be automatically stored in the history object.\nLeaf Contract Category:\n\nIC-1 (Incorrect Computation):\nSpecifically, the incorrect computation pertains to measuring and capturing epoch-level training durations, which is not a built-in behavior.\nRoot Cause:\n\nUnacceptable Input Value:\nThe issue is due to expecting an output (epoch timing data) that is not produced by default, requiring additional implementation.\nEffect:\n\nUnknown:\nAlthough it doesn't result in a crash, the intended effect of automatically storing epoch computation times isn't achieved. It's not clearly a crash or performance degradation, just a missing feature.\nML Library:\n\nKeras:\nThe method involved is specifically from Keras's high-level training API.\nContract Violation Location:\n\nTrain:\nThe problem occurs during the training phase (model.fit) when epoch-level metrics are typically collected.\nDetection Technique:\n\nStatic:\nDetecting this issue involves static analysis of Keras API documentation or source code to realize epoch times are not automatically captured by default, hence the need for a custom callback.\n"
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/43396572",
    "title": "",
    "question": "68\n\nI have tried to build a CNN with one layer, but I have some problem with it. Indeed, the compilator says me that\n\nValueError: Error when checking model input: expected conv1d_1_input to have 3 dimensions, but got array with shape (569, 30)\n\nThis is the code\n\nimport numpy\nfrom keras.models import Sequential\nfrom keras.layers.convolutional import Conv1D\n\nnumpy.random.seed(7)\n\ndatasetTraining = numpy.loadtxt(\"CancerAdapter.csv\",delimiter=\",\")\nX = datasetTraining[:,1:31]\nY = datasetTraining[:,0]\ndatasetTesting = numpy.loadtxt(\"CancereEvaluation.csv\",delimiter=\",\")\nX_test = datasetTraining[:,1:31]\nY_test = datasetTraining[:,0]\n\nmodel = Sequential()\nmodel.add(Conv1D(2,2,activation='relu',input_shape=X.shape))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(X, Y, epochs=150, batch_size=5)\nscores = model.evaluate(X_test, Y_test)\n\nprint(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))",
    "answer": "136\n\ntd; lr you need to reshape you data to have a spatial dimension for Conv1d to make sense:\n\nX = np.expand_dims(X, axis=2) # reshape (569, 30) to (569, 30, 1) \n# now input can be set as \nmodel.add(Conv1D(2,2,activation='relu',input_shape=(30, 1))\nEssentially reshaping a dataset that looks like this:\n\nfeatures    \n.8, .1, .3  \n.2, .4, .6  \n.7, .2, .1  \nTo:\n\n[[.8\n.1\n.3],\n\n[.2,\n .4,\n .6\n ],\n\n[.7,\n .2,\n .1]]\n \nExplanation and examples\n\nNormally convolution works over spatial dimensions. The kernel is \"convolved\" over the dimension producing a tensor. In the case of Conv1D, the kernel is passed over the 'steps' dimension of every example.\n\nYou will see Conv1D used in NLP where steps is a number of words in the sentence (padded to some fixed maximum length). The words would be encoded as vectors of length 4.\n\nHere is an example sentence:\n\njack   .1   .3   -.52   |\nis     .05  .8,  -.7    |<--- kernel is `convolving` along this dimension.\na      .5   .31  -.2    |\nboy    .5   .8   -.4   \\|/\nAnd the way we would set the input to the conv in this case:\n\nmaxlen = 4\ninput_dim = 3\nmodel.add(Conv1D(2,2,activation='relu',input_shape=(maxlen, input_dim))\nIn your case, you will treat the features as the spatial dimensions with each feature having length 1. (see below)\n\nHere would be an example from your dataset\n\natt1   .04    |\natt2   .05    |  < -- kernel convolving along this dimension\natt3   .1     |       notice the features have length 1. each\natt4   .5    \\|/      example have these 4 featues.\nAnd we would set the Conv1D example as:\n\nmaxlen = num_features = 4 # this would be 30 in your case\ninput_dim = 1 # since this is the length of _each_ feature (as shown above)\n\nmodel.add(Conv1D(2,2,activation='relu',input_shape=(maxlen, input_dim))\nAs you see your dataset has to be reshaped in to (569, 30, 1) use:\n\nX = np.expand_dims(X, axis=2) # reshape (569, 30, 1) \n# now input can be set as \nmodel.add(Conv1D(2,2,activation='relu',input_shape=(30, 1))\nHere is a full-fledged example that you can run (I'll use the Functional API)\n\nfrom keras.models import Model\nfrom keras.layers import Conv1D, Dense, MaxPool1D, Flatten, Input\nimport numpy as np\n\ninp =  Input(shape=(5, 1))\nconv = Conv1D(filters=2, kernel_size=2)(inp)\npool = MaxPool1D(pool_size=2)(conv)\nflat = Flatten()(pool)\ndense = Dense(1)(flat)\nmodel = Model(inp, dense)\nmodel.compile(loss='mse', optimizer='adam')\n\nprint(model.summary())\n\n# get some data\nX = np.expand_dims(np.random.randn(10, 5), axis=2)\ny = np.random.randn(10, 1)\n\n# fit model\nmodel.fit(X, y)",
    "mlApiName": "keras.layers.Conv1D",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "DT",
      "level3": "MT",
      "leafContractCategory": "MT",
      "rootCause": "Unacceptable Input Type",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category):\n\nSAM (Single API Method): The issue originates from a single API method, Conv1D, being used incorrectly.\nLevel 2:\n\nDT (Data Type): The error is due to an incorrect data shape being passed to Conv1D, leading to a dimensionality mismatch.\nLevel 3 (Hybrid Patterns):\n\nMT (Machine Learning Type): The issue involves the structure of input data for a machine learning model, specifically for 1D convolutions.\nLeaf Contract Category:\n\nMT (Machine Learning Type): The error is due to improper handling of machine learning-specific data shapes.\nRoot Cause:\n\nUnacceptable Input Type: The input tensor shape (569, 30) does not match the expected 3D shape for Conv1D, causing the function to raise an error.\nEffect:\n\nCrash: The model fails to compile due to the input shape mismatch, causing a ValueError.\nML Library:\n\nKeras: The issue is specific to Keras' Conv1D layer.\nContract Violation Location:\n\nModel Construction: The error happens at model construction when defining input layers.\nDetection Technique:\n\nStatic: The issue can be identified through static analysis by checking the shape requirements for Conv1D."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/45930844",
    "title": "",
    "question": "8\n\nI am trying to create my first ensemble models in keras. I have 3 input values and a single output value in my dataset.\n\nfrom keras.optimizers import SGD,Adam\nfrom keras.layers import Dense,Merge\nfrom keras.models import Sequential\n\nmodel1 = Sequential()\nmodel1.add(Dense(3, input_dim=3, activation='relu'))\nmodel1.add(Dense(2, activation='relu'))\nmodel1.add(Dense(2, activation='tanh'))\nmodel1.compile(loss='mse', optimizer='Adam', metrics=['accuracy'])\n\nmodel2 = Sequential()\nmodel2.add(Dense(3, input_dim=3, activation='linear'))\nmodel2.add(Dense(4, activation='tanh'))\nmodel2.add(Dense(3, activation='tanh'))\nmodel2.compile(loss='mse', optimizer='SGD', metrics=['accuracy'])\n\nmodel3 = Sequential()\nmodel3.add(Merge([model1, model2], mode = 'concat'))\nmodel3.add(Dense(1, activation='sigmoid'))\nmodel3.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n\nmodel3.input_shape\nThe ensemble model(model3) compiles without any error but while fitting the model I have to pass the same input two times model3.fit([X,X],y). Which I think is an unnecessary step and instead of passing input twice I want to have a common input nodes for my ensemble model. How can I do it?",
    "answer": "7\n\nKeras functional API seems to be a better fit for your use case, as it allows more flexibility in the computation graph. e.g.:\n\nfrom keras.layers import concatenate\nfrom keras.models import Model\nfrom keras.layers import Input, Merge\nfrom keras.layers.core import Dense\nfrom keras.layers.merge import concatenate\n\n# a single input layer\ninputs = Input(shape=(3,))\n\n# model 1\nx1 = Dense(3, activation='relu')(inputs)\nx1 = Dense(2, activation='relu')(x1)\nx1 = Dense(2, activation='tanh')(x1)\n\n# model 2 \nx2 = Dense(3, activation='linear')(inputs)\nx2 = Dense(4, activation='tanh')(x2)\nx2 = Dense(3, activation='tanh')(x2)\n\n# merging models\nx3 = concatenate([x1, x2])\n\n# output layer\npredictions = Dense(1, activation='sigmoid')(x3)\n\n# generate a model from the layers above\nmodel = Model(inputs=inputs, outputs=predictions)\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Always a good idea to verify it looks as you expect it to \n# model.summary()\n\ndata = [[1,2,3], [1,1,3], [7,8,9], [5,8,10]]\nlabels = [0,0,1,1]\n\n# The resulting model can be fit with a single input:\nmodel.fit(data, labels, epochs=50)\nNotes:\n\nThere might be slight differences in the API between Keras versions (pre- and post- version 2)\nThe example above specifies different optimizer and loss function for each of the models. However, since fit() is being called only once (on model3), the same settings - those of model3 - will apply to the entire model. In order to have different settings when training the sub-models, they will have to be fit() separately - see comment by @Daniel.\nEDIT: updated notes based on comments",
    "mlApiName": " keras.models.Model,keras.layers.merge.concatenate",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "F",
      "leafContractCategory": "AMO(Level-2)",
      "rootCause": "Missing Options",
      "effect": "Unknown",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): Hybrid\nThe issue arises from multiple API interactions (Model, Merge, concatenate), leading to a hybrid contract violation.\n\nLevel 2: SL (Selection Issue)\nThe user incorrectly selects Merge instead of using the Keras functional API, which is better suited for ensemble models.\n\nLevel 3 (Hybrid Patterns): F (Eventually Constraint)\nThe problem involves model structure dependencies, where a proper computational graph should eventually be defined before calling fit.\n\nLeaf Contract Category: AMO (Level-2)\nThe issue stems from improper ordering of API calls, requiring the correct definition of model inputs before merging.\n\nRoot Cause: Missing Options\nThe problem arises because an appropriate API method (concatenate from Keras functional API) was not used, leading to unnecessary duplication of inputs.\n\nEffect: Unknown\nThe code does not crash but results in inefficient behavior (unnecessary duplicated inputs), which may lead to unpredictable outcomes.\n\nML Library: Keras\nThe violation specifically pertains to Keras' model-building process.\n\nContract Violation Location: Model Construction\nThe error occurs while constructing the ensemble model, before training.\n\nDetection Technique: Static\nThe incorrect API usage can be identified through static analysis by checking for improper model merging patterns."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/49834380",
    "title": "",
    "question": "12\n\nI have CNN models trained using Keras with Tensorflow backend. And I want to visualize my CNN filters with this tutorial: https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html\n\nfrom keras import backend as K\nfrom keras.models import load_model\nimport numpy as np\n\nmodel = load_model('my_cnn_model.h5')\ninput_img = np.load('my_picture.npy')\n\n# get the symbolic outputs of each \"key\" layer (we gave them unique names).\nlayer_dict = dict([(layer.name, layer) for layer in model.layers])\n\nlayer_name = 'block5_conv3'\nfilter_index = 0  # can be any integer from 0 to 511, as there are 512 filters in that layer\n\n# build a loss function that maximizes the activation\n# of the nth filter of the layer considered\nlayer_output = layer_dict[layer_name].output\nloss = K.mean(layer_output[:, :, :, filter_index])\n\n# compute the gradient of the input picture wrt this loss\ngrads = K.gradients(loss, input_img)[0]\n\n# normalization trick: we normalize the gradient\ngrads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n\n# this function returns the loss and grads given the input picture\niterate = K.function([input_img], [loss, grads])\nHowever, when the code execute to this line:\ngrads = K.gradients(loss, input_img)[0]\nI found it returns nothing but None object, so the program fail to progress after that.\n\nI search for some solution. Some people say theinput_img should be tensorflow's Tensor type: https://github.com/keras-team/keras/issues/5455\n\nBut when I tried to convert the img to Tensor, the problem is still exist.\nI tried the solution in the link above, but still fail.\n\nThere is also someone say that this problem exists because your CNN model is not differentiable. https://github.com/keras-team/keras/issues/8478\n\nBut my model use only the activate function of ReLU and Sigmoid(at output layer). Is this problem really caused by nondifferentiable problem?\n\nCan anyone help me? Thank you very much!",
    "answer": "12\n\nIf you have a Model instance, then to take the gradient of the loss with respect to the input, you should do:\n\ngrads = K.gradients(loss, model.input)[0]\nmodel.input contains the symbolic tensor that represents the input to the model. Using a plain numpy array makes no sense because TensorFlow then has no idea how this connects to the computational graph, and returns None as the gradient.\n\nThen you should also rewrite the iterate function as:\n\niterate = K.function([model.input], [loss, grads])",
    "mlApiName": "keras.backend.function, keras.backend.gradients",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "F",
      "level3": "F",
      "leafContractCategory": "F",
      "rootCause": "Missing Required State-specific Method Order",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Evaluation",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): AMO (API Method Order)\nThe issue is caused by calling Keras API methods (K.gradients and K.function) in an incorrect order or without fulfilling required preconditions.\n\nLevel 2: F (Eventually Required Condition)\nThe model's computational graph requires a valid TensorFlow tensor (model.input), but the user incorrectly provides a NumPy array instead.\n\nLevel 3 (Hybrid Patterns): F (Eventually Required Condition)\nThe failure happens because input_img is expected to be part of the TensorFlow computation graph, but it isn�t, breaking the expected flow of execution.\n\nLeaf Contract Category: F (Eventually Required Condition)\nThe function expects a structured computational graph, which was not properly set up.\n\nRoot Cause: Missing Required State-specific Method Order\nThe missing method order requirement is that K.gradients must compute gradients with respect to a symbolic tensor (model.input), but the user incorrectly passes a NumPy array, which breaks the computational graph.\n\nEffect: Crash\nThe API call returns None instead of valid gradients, causing an immediate failure when subsequent computations depend on it.\n\nML Library: Keras\nThe issue occurs due to incorrect usage of Keras backend functions (K.gradients and K.function).\n\nContract Violation Location: Model Evaluation\nThe error occurs while evaluating the model for visualization, where the gradient computation should have taken place.\n\nDetection Technique: Static\nThe issue can be identified through static analysis by checking for improper arguments passed to K.gradients, specifically ensuring that inputs are symbolic tensors rather than NumPy arrays.\n\n\n"
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/34716454",
    "title": "",
    "question": "213\n\nIf I want to use the BatchNormalization function in Keras, then do I need to call it once only at the beginning?\n\nI read this documentation for it: http://keras.io/layers/normalization/\n\nI don't see where I'm supposed to call it. Below is my code attempting to use it:\n\nmodel = Sequential()\nkeras.layers.normalization.BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)\nmodel.add(Dense(64, input_dim=14, init='uniform'))\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, init='uniform'))\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2, init='uniform'))\nmodel.add(Activation('softmax'))\n\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='binary_crossentropy', optimizer=sgd)\nmodel.fit(X_train, y_train, nb_epoch=20, batch_size=16, show_accuracy=True, validation_split=0.2, verbose = 2)\nI ask because if I run the code with the second line including the batch normalization and if I run the code without the second line I get similar outputs. So either I'm not calling the function in the right place, or I guess it doesn't make that much of a difference.",
    "answer": "As Pavel said, Batch Normalization is just another layer, so you can use it as such to create your desired network architecture.\n\nThe general use case is to use BN between the linear and non-linear layers in your network, because it normalizes the input to your activation function, so that you're centered in the linear section of the activation function (such as Sigmoid). There's a small discussion of it here\n\nIn your case above, this might look like:\n\n# import BatchNormalization\nfrom keras.layers.normalization import BatchNormalization\n\n# instantiate model\nmodel = Sequential()\n\n# we can think of this chunk as the input layer\nmodel.add(Dense(64, input_dim=14, init='uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\n\n# we can think of this chunk as the hidden layer    \nmodel.add(Dense(64, init='uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\n\n# we can think of this chunk as the output layer\nmodel.add(Dense(2, init='uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('softmax'))\n\n# setting up the optimization of our weights \nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='binary_crossentropy', optimizer=sgd)\n\n# running the fitting\nmodel.fit(X_train, y_train, nb_epoch=20, batch_size=16, show_accuracy",
    "mlApiName": "keras.layers.Activation, keras.layers.BatchNormalization, keras.layers.Dense",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "F",
      "level3": "F",
      "leafContractCategory": "F",
      "rootCause": "Missing Required State-specific Method Order",
      "effect": "BP",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model construction",
      "detectionTechnique": "Runtime Checking",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): AMO (API Method Order)\nThe issue arises from calling BatchNormalization improperly outside the model definition. The correct method order is required for the layer to function as expected.\n\nLevel 2: F (Eventually Required Condition)\nThe batch normalization layer must eventually be called within the model's structure before activation layers to properly normalize inputs.\n\nLevel 3 (Hybrid Patterns): F (Eventually Required Condition)\nThe normalization step must be inserted in the right sequence for the model to behave as expected, affecting training and prediction consistency.\n\nLeaf Contract Category: F (Eventually Required Condition)\nThe model expects proper ordering of layers (BatchNormalization before Activation) to ensure expected behavior.\n\nRoot Cause: Missing Required State-specific Method Order\nThe error is caused by not placing BatchNormalization within the model structure, leading to the function not being executed as part of the computation graph.\n\nEffect: BP (Bad Prediction)\nThe model trains, but predictions may not be optimal since normalization is not applied where expected, affecting learning stability.\n\nML Library: Keras\nThe issue is related to Keras's layer ordering requirements.\n\nContract Violation Location: Model Construction\nThe problem occurs while defining the model architecture.\n\nDetection Technique: Runtime Checking\nThe issue is detected during execution, as the user notices similar results with and without BatchNormalization, indicating it was not properly integrated into the model.\n\n\n"
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/40278868",
    "title": "",
    "question": "This is in fact really easy. Here's the code (for those who don't want to read all that text):\n\ninputs=Input((784,))\nencode=Dense(10, input_shape=[784])(inputs)\ndecode=Dense(784, input_shape=[10])\n\nmodel=Model(input=inputs, output=decode(encode))\n\ninputs_2=Input((10,))\ndecode_model=Model(input=inputs_2, output=decode(inputs_2))\nIn this setup, the decode_model will use the same decode layer as the model. If you train the model, the decode_model will be trained, too.\n\nActual question:\n\nI'm trying to create a simple autoencoder for MNIST in Keras:\n\nThis is the code so far:\n\nmodel=Sequential()\nencode=Dense(10, input_shape=[784])\ndecode=Dense(784, input_shape=[10])\n\nmodel.add(encode)\nmodel.add(decode)\n\nmodel.compile(loss=\"mse\",\n             optimizer=\"adadelta\",\n             metrics=[\"accuracy\"])\n\ndecode_model=Sequential()\ndecode_model.add(decode)\nI'm training it to learn the identity function\n\nmodel.fit(X_train,X_train,batch_size=50, nb_epoch=10, verbose=1, \n          validation_data=[X_test, X_test])\nThe reconstruction is quite interesting:\n\nenter image description here\n\nBut I would also like to look at the representations of cluster. What is the output of passing [1,0...0] to the decoding layer ? This should be the \"cluster-mean\" of one class in MNIST.\n\nIn order to do that I created a second model decode_model, which reuses the decoder layer. But if I try to use that model, it complains:\n\nException: Error when checking : expected dense_input_5 to have shape (None, 784) but got array with shape (10, 10)\n\nThat seemed strange. It's simply a dense layer, the Matrix wouldn't even be able to process 784-dim input. I decided to look at the model summary:\n\n____________________________________________________________________________________________________\nLayer (type)                     Output Shape          Param #     Connected to                     \n====================================================================================================\ndense_14 (Dense)                 (None, 784)           8624        dense_13[0][0]                   \n====================================================================================================\nTotal params: 8624\nIt is connected to dense_13. It's difficult to keep track of the names of the layers, but that looks like the encoder layer. Sure enough, the model summary of the whole model is:\n\n____________________________________________________________________________________________________\nLayer (type)                     Output Shape          Param #     Connected to                     \n====================================================================================================\ndense_13 (Dense)                 (None, 10)            7850        dense_input_6[0][0]              \n____________________________________________________________________________________________________\ndense_14 (Dense)                 (None, 784)           8624        dense_13[0][0]                   \n====================================================================================================\nTotal params: 16474\n____________________\nApparently the layers are permanently connected. Strangely there is no input layer in my decode_model.\n\nHow can I reuse a layer in Keras ? I've looked at the functional API, but there too, layers are fused together.",
    "answer": "8\n\nOh, nevermind.\n\nI should have read the entire functional API: https://keras.io/getting-started/functional-api-guide/#shared-layers\n\nHere's one of the predictions (maybe still lacking some training): enter image description here\n\nI'm guessing this could be a 3 ? Well at least it works now.\n\nAnd for those with similar problems, here's the updated code:\n\ninputs=Input((784,))\nencode=Dense(10, input_shape=[784])(inputs)\ndecode=Dense(784, input_shape=[10])\n\nmodel=Model(input=inputs, output=decode(encode))\n\nmodel.compile(loss=\"mse\",\n             optimizer=\"adadelta\",\n             metrics=[\"accuracy\"])\n\ninputs_2=Input((10,))\ndecode_model=Model(input=inputs_2, output=decode(inputs_2))\nI only compiled one of the models. For training you need to compile a model, for prediction that is not necessary.",
    "mlApiName": "keras.models.fit, keras.models.compile",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "G",
      "level3": "G",
      "leafContractCategory": "G",
      "rootCause": "Missing Required Method Order",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Train",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): AMO (API Method Order)\nThe issue stems from incorrect ordering of API calls, specifically compile not being called for the second model before attempting predictions.\n\nLevel 2: G (Graph-Related Issue)\nThe problem is related to how Keras constructs its computation graph, where layers are permanently connected after compilation.\n\nLevel 3 (Hybrid Patterns): G (Graph-Related Issue)\nThe model architecture is not correctly structured for reusing layers in a new model, causing an issue in the computational graph.\n\nLeaf Contract Category: G (Graph-Related Issue)\nThe issue directly arises from how the graph is built and connected, affecting proper layer reuse.\n\nRoot Cause: Missing Required Method Order\nThe user expected to reuse a layer in a separate model but didn't call compile correctly before attempting predictions.\n\nEffect: Crash\nThe incorrect method order results in a runtime error when attempting to use the second model.\n\nML Library: Keras\nThe issue specifically relates to Keras' handling of models and layer reusability.\n\nContract Violation Location: Train\nThe error manifests during training, particularly when trying to use the second model.\n\nDetection Technique: Static\nThe issue can be identified by inspecting the source code and ensuring that compile is called correctly before using the model.\n\n\n"
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/48846332",
    "title": "",
    "question": "10\n\nI train a model A and try to use the output of the intermediate layer with the name=\"layer_x\" as an additional input for model B.\n\nI tried to use the output of the intermediate layer like on the Keras doc https://keras.io/getting-started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer.\n\nModel A:\n\ninputs = Input(shape=(100,))\ndnn = Dense(1024, activation='relu')(inputs)\ndnn = Dense(128, activation='relu', name=\"layer_x\")(dnn)\ndnn = Dense(1024, activation='relu')(dnn)\noutput = Dense(10, activation='softmax')(dnn)\nModel B:\n\ninput_1 = Input(shape=(200,))\ninput_2 = Input(shape=(100,)) # input for model A\n\n# loading model A\nmodel_a = keras.models.load_model(path_to_saved_model_a)\n\nintermediate_layer_model = Model(inputs=model_a.input, \n                                 outputs=model_a.get_layer(\"layer_x\").output)\n\nintermediate_output = intermediate_layer_model.predict(data)\n\nmerge_layer = concatenate([input_1, intermediate_output])\ndnn_layer = Dense(512, activation=\"relu\")(merge_layer)\noutput = Dense(5, activation=\"sigmoid\")(dnn_layer)\nmodel = keras.models.Model(inputs=[input_1, input_2], outputs=output)\nWhen I debug I get an error on this line:\n\nintermediate_layer_model = Model(inputs=model_a.input, \n                                 outputs=model_a.get_layer(\"layer_x\").output)\n\nFile \"..\", line 89, in set_model\n  outputs=self.neural_net_asc.model.get_layer(\"layer_x\").output)\nFile \"C:\\WinPython\\python-3.5.3.amd64\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 87, in wrapper\n  return func(*args, **kwargs)\nFile \"C:\\WinPython\\python-3.5.3.amd64\\lib\\site-packages\\keras\\engine\\topology.py\", line 1592, in __init__\n  mask = node.output_masks[tensor_index]\nAttributeError: 'Node' object has no attribute 'output_masks'\nI can access the tensor with get_layer(\"layer_x\").output and the output_mask is None. Do I have to set manually an output mask and how do I set up this output mask if needed?",
    "answer": "There are two things that you seem to be doing wrong :\n\nintermediate_output = intermediate_layer_model.predict(data)\nwhen you do .predict(), you are actually passing data through the graph and asking what will be the result. When you do that, intermediate_output will be a numpy array and not a layer as you would like it to be.\n\nSecondly, you don't need to recreate a new intermediate model. You can directly use the part of model_a that interest you.\n\nHere is a code that \"compiles\" for me :\n\nfrom keras.layers import Input, Dense, concatenate\nfrom keras.models import Model\n\ninputs = Input(shape=(100,))\ndnn = Dense(1024, activation='relu')(inputs)\ndnn = Dense(128, activation='relu', name=\"layer_x\")(dnn)\ndnn = Dense(1024, activation='relu')(dnn)\noutput = Dense(10, activation='softmax')(dnn)\n\nmodel_a = Model(inputs=inputs, outputs=output)\n\n# You don't need to recreate an input for the model_a, \n# it already has one and you can reuse it\ninput_b = Input(shape=(200,))\n\n# Here you get the layer that interests you from model_a, \n# it is still linked to its input layer, you just need to remember it for later\nintermediate_from_a = model_a.get_layer(\"layer_x\").output\n\n# Since intermediate_from_a is a layer, you can concatenate it with the other input\nmerge_layer = concatenate([input_b, intermediate_from_a])\ndnn_layer = Dense(512, activation=\"relu\")(merge_layer)\noutput_b = Dense(5, activation=\"sigmoid\")(dnn_layer)\n# Here you remember that one input is input_b and the other one is from model_a\nmodel_b = Model(inputs=[input_b, model_a.input], outputs=output_b)\nI hope this is what you wanted to do.\n\nPlease tell me if something isn't clear :-)",
    "mlApiName": "keras.models.Model, keras.models.model.predict",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "F",
      "level3": "F",
      "leafContractCategory": "AMO(Level-2)",
      "rootCause": "Missing Options",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Prediction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): Hybrid\nThe issue arises from combining multiple models (Model A and Model B) and their intermediate outputs, leading to a hybrid contract violation.\n\nLevel 2: F (Eventually Required Condition)\nThe model expects that intermediate layers must be correctly linked, but the user mistakenly calls predict(), converting the layer output into a NumPy array instead of preserving it as a tensor.\n\nLevel 3 (Hybrid Patterns): F (Eventually Required Condition)\nThe get_layer(\"layer_x\").output method is used incorrectly, breaking the expected computational graph dependency.\n\nLeaf Contract Category: AMO (Level-2)\nThe error is related to the improper order of API calls�using predict() prematurely instead of passing the layer output directly into the second model.\n\nRoot Cause: Missing Options\nThe user manually attempts to retrieve an intermediate output but does not maintain it as a valid tensor in the computational graph.\n\nEffect: Crash\nThe incorrect API call results in an AttributeError, causing a runtime failure.\n\nML Library: Keras\nThe issue is specific to Keras' functional API for model composition.\n\nContract Violation Location: Prediction\nThe error manifests while attempting to pass intermediate layer outputs during model inference.\n\nDetection Technique: Static\nThe mistake can be identified statically by reviewing how intermediate outputs should be extracted and passed within the Keras functional API.\n\n\n"
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/51100508",
    "title": "",
    "question": "9\n\nI need some help with keras loss function. I have been implementing custom loss function on keras with Tensorflow backend.\n\nI have implemented the custom loss function in numpy but it would be great if it could be translated into keras loss function. The loss function takes dataframe and series of user id. The Euclidean distance for same user_id are positive and negative if the user_id are different. The function returns summed up scalar distance of the dataframe.\n\ndef custom_loss_numpy (encodings, user_id):\n# user_id: a pandas series of users\n# encodings: a pandas dataframe of encodings\n\n    batch_dist = 0\n\n    for i in range(len(user_id)):\n         first_row = encodings.iloc[i,:].values\n         first_user = user_id[i]\n\n         for j in range(i+1, len(user_id)):\n              second_user = user_id[j]\n              second_row = encodings.iloc[j,:].values\n\n        # compute distance: if the users are same then Euclidean distance is positive otherwise negative.\n            if first_user == second_user:\n                tmp_dist = np.linalg.norm(first_row - second_row)\n            else:\n                tmp_dist = -np.linalg.norm(first_row - second_row)\n\n            batch_dist += tmp_dist\n\n    return batch_dist\nI have tried to implement into keras loss function. I extracted numpy array from y_true and y_pred tensor objects.\n\ndef custom_loss_keras(y_true, y_pred):\n    # session of my program\n    sess = tf_session.TF_Session().get()\n\n    with sess.as_default():\n        array_pred = y_pred.eval()\n        print(array_pred)\nBut I get the following error.\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'dense_1_input' with dtype float and shape [?,102]\n [[Node: dense_1_input = Placeholder[dtype=DT_FLOAT, shape=[?,102], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nAny kind of help would be really appreciated.",
    "answer": "First of all, it is not possible to \"extract numpy array from y_true and y_pred\" in Keras loss functions. You have to operate the tensors with Keras backend functions (or TF functions) to calculate the loss.\n\nIn other words, it would be better to think about a \"vectorized\" way to calculate the loss, without using if-else and loops.\n\nYour loss function can be computed in the following steps:\n\nGenerate a matrix of pairwise Euclidean distances, between all pairs of vectors in encodings.\nGenerate a matrix I whose element I_ij is 1 if user_i == user_j, and -1 if user_i != user_j.\nElement-wise multiply the two matrices, and sum up the elements to get the final loss.\nHere's an implementation:\n\ndef custom_loss_keras(user_id, encodings):\n    # calculate pairwise Euclidean distance matrix\n    pairwise_diff = K.expand_dims(encodings, 0) - K.expand_dims(encodings, 1)\n    pairwise_squared_distance = K.sum(K.square(pairwise_diff), axis=-1)\n\n    # add a small number before taking K.sqrt for numerical safety\n    # (K.sqrt(0) sometimes becomes nan)\n    pairwise_distance = K.sqrt(pairwise_squared_distance + K.epsilon())\n\n    # this will be a pairwise matrix of True and False, with shape (batch_size, batch_size)\n    pairwise_equal = K.equal(K.expand_dims(user_id, 0), K.expand_dims(user_id, 1))\n\n    # convert True and False to 1 and -1\n    pos_neg = K.cast(pairwise_equal, K.floatx()) * 2 - 1\n\n    # divide by 2 to match the output of `custom_loss_numpy`, but it's not really necessary\n    return K.sum(pairwise_distance * pos_neg, axis=-1) / 2\nI've assumed that user_id are integers in the code above. The trick here is to use K.expand_dims for implementing pairwise operations. It's probably a bit difficult to understand at a first glance, but it's quite useful.\n\nIt should give about the same loss value as custom_loss_numpy (there will be a little bit difference because of K.epsilon()):\n\nencodings = np.random.rand(32, 10)\nuser_id = np.random.randint(10, size=32)\n\nprint(K.eval(custom_loss_keras(K.variable(user_id), K.variable(encodings))).sum())\n-478.4245\n\nprint(custom_loss_numpy(pd.DataFrame(encodings), pd.Series(user_id)))\n-478.42953553795815\nI've made a mistake in the loss function.\n\nWhen this function is used in training, since Keras automatically changes y_true to be at least 2D, the argument user_id is no longer a 1D tensor. The shape of it will be (batch_size, 1).\n\nIn order to use this function, the extra axis must be removed:\n\ndef custom_loss_keras(user_id, encodings):\n    pairwise_diff = K.expand_dims(encodings, 0) - K.expand_dims(encodings, 1)\n    pairwise_squared_distance = K.sum(K.square(pairwise_diff), axis=-1)\n    pairwise_distance = K.sqrt(pairwise_squared_distance + K.epsilon())\n\n    user_id = K.squeeze(user_id, axis=1)  # remove the axis added by Keras\n    pairwise_equal = K.equal(K.expand_dims(user_id, 0), K.expand_dims(user_id, 1))\n\n    pos_neg = K.cast(pairwise_equal, K.floatx()) * 2 - 1\n    return K.sum(pairwise_distance * pos_neg, axis=-1)",
    "mlApiName": "keras.backend.sqrt, keras.backend.expand_dims",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "F, IC-1",
      "leafContractCategory": "Comb. of SAM(Level 3) and AMO(Level 2)",
      "rootCause": "Missing Options",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): Hybrid\nThe issue involves multiple Keras API methods (K.sqrt, K.expand_dims) and their incorrect interaction in a custom loss function.\n\nLevel 2: SL (Selection Issue)\nThe problem arises due to incorrect selection of Keras functions for tensor operations instead of NumPy operations, leading to improper computation.\n\nLevel 3 (Hybrid Patterns): F (Eventually Required Condition), IC-1 (Intra-argument Contract)\nThe issue stems from a missing required condition in the computational graph, and the loss function must properly maintain input tensor shapes across operations.\n\nLeaf Contract Category: Combination of SAM(Level 3) and AMO(Level 2)\nThe problem involves both single API method misuse (K.sqrt, K.expand_dims) and method-order dependencies (K.gradients expecting tensor inputs).\n\nRoot Cause: Missing Options\nThe custom loss function attempts to extract NumPy arrays from Keras tensors, which is not allowed in Keras loss functions.\n\nEffect: Crash\nThe incorrect function usage leads to an InvalidArgumentError when TensorFlow cannot process the computation.\n\nML Library: Keras\nThe issue occurs in Keras�s backend operations when defining a loss function.\n\nContract Violation Location: Model Construction\nThe problem happens when constructing the model with a custom loss function.\n\nDetection Technique: Static\nThe issue can be detected through static analysis by reviewing how Keras loss functions handle tensor operations and ensuring proper function selection."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/41378461",
    "title": "",
    "question": "21\n\nI want to get pretrained VGG16 model in Keras, remove its output layer, and then put a new output layer with the number of classes suited for my problem, and then to fit it on new data. For this reason, I am trying to use the model here: https://keras.io/applications/#vgg16, but since it is not Sequential, I cannot just model.pop(). Popping from layers and adding it also does not work, because in the predictions it still expects the old shape. How would I do that? Is there a way to convert this type of model to Sequential?",
    "answer": "You can use pop() on model.layers and then use model.layers[-1].output to create new layers.\n\nExample:\n\nfrom keras.models import Model\nfrom keras.layers import Dense,Flatten\nfrom keras.applications import vgg16\nfrom keras import backend as K\n\nmodel = vgg16.VGG16(weights='imagenet', include_top=True)\n\nmodel.input\n\nmodel.summary(line_length=150)\n\nmodel.layers.pop()\nmodel.layers.pop()\n\nmodel.summary(line_length=150)\n\nnew_layer = Dense(10, activation='softmax', name='my_dense')\n\ninp = model.input\nout = new_layer(model.layers[-1].output)\n\nmodel2 = Model(inp, out)\nmodel2.summary(line_length=150)\nAlternatively, you can use include_top=False option of these models. In this case if you need to use flatten the layer then you need to pass the input_shape also.\n\nmodel3 = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nmodel3.summary(line_length=150)\n\nflatten = Flatten()\nnew_layer2 = Dense(10, activation='softmax', name='my_dense_2')\n\ninp2 = model3.input\nout2 = new_layer2(flatten(model3.output))\n\nmodel4 = Model(inp2, out2)\nmodel4.summary(line_length=150)",
    "mlApiName": "keras.models.pop, keras.applications.vgg16.VGG16, keras.layers, keras.models",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "F, F, IC-1",
      "leafContractCategory": "Comb. of SAM(Level 3) and AMO(Level 2)",
      "rootCause": "Missing Options",
      "effect": "IF",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): Hybrid\nThe issue involves multiple Keras API methods (VGG16, pop, layers, models), making it a hybrid contract violation.\n\nLevel 2: SL (Selection Issue)\nThe user incorrectly selects pop() for modifying the model structure, which does not work with functional API models like VGG16.\n\nLevel 3 (Hybrid Patterns): F (Eventually Required Condition), F (Eventually Required Condition), IC-1 (Intra-argument Contract)\nThe issue is due to the expectation that modifying layers will automatically update the model structure, which requires additional steps for functional models.\n\nLeaf Contract Category: Combination of SAM(Level 3) and AMO(Level 2)\nThe violation stems from both single API misuse (SAM) and incorrect API method order (AMO) when modifying pre-trained models.\n\nRoot Cause: Missing Options\nThe user failed to specify include_top=False when loading VGG16, which would allow proper customization of the model.\n\nEffect: IF (Incorrect Functionality)\nThe model does not crash but does not function correctly, as it still expects the original output shape.\n\nML Library: Keras\nThe issue specifically relates to modifying pre-trained Keras models.\n\nContract Violation Location: Model Construction\nThe error occurs during model construction while attempting to modify the architecture.\n\nDetection Technique: Static\nThe incorrect use of pop() with functional API models can be detected through static analysis by checking whether the modification properly updates the model structure.\n\n\n"
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/53212672",
    "title": "",
    "question": "24\n\nI have cloned human pose estimation keras model from this link human pose estimation keras\n\nWhen I try to load the model on google colab, I get the following error\n\ncode\n\nfrom keras.models import load_model\nmodel = load_model('model.h5')\nerror\n\nValueError                                Traceback (most recent call \n\nlast)\n in ()\n      1 from keras.models import load_model\n----> 2 model = load_model('model.h5')\n\n/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py in load_model(filepath, custom_objects, compile)\n    417     f = h5dict(filepath, 'r')\n    418     try:\n--> 419         model = _deserialize_model(f, custom_objects, compile)\n    420     finally:\n    421         if opened_new_file:\n\n/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py in _deserialize_model(f, custom_objects, compile)\n    219         return obj\n    220 \n--> 221     model_config = f['model_config']\n    222     if model_config is None:\n    223         raise ValueError('No model found in config.')\n\n/usr/local/lib/python3.6/dist-packages/keras/utils/io_utils.py in __getitem__(self, attr)\n    300             else:\n    301                 if self.read_only:\n--> 302                     raise ValueError('Cannot create group in read only mode.')\n    303                 val = H5Dict(self.data.create_group(attr))\n    304         return val\n\nValueError: Cannot create group in read only mode.\nCan someone please help me understand this read-only mode? How do I load this model?",
    "answer": "Here is an example Git gist created on Google Collab for you: https://gist.github.com/kolygri/835ccea6b87089fbfd64395c3895c01f\n\nAs far as I understand:\n\nYou have to set and define the architecture of your model and then use model.load_weights('alexnet_weights.h5').\n\nHere is a useful Github conversation link, which hopefully will help you understand the issue better: https://github.com/keras-team/keras/issues/6937",
    "mlApiName": "keras.models.model.load_weights",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Load",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): SAM (Single API Method)\nThe issue is caused by incorrect usage of a single API method, model.load_weights(), making it a SAM contract violation.\n\nLevel 2: BET (Behavioral Expectation Type)\nThe error arises from incorrect assumptions about how model weights should be loaded in Keras.\n\nLevel 3 (Hybrid Patterns): IC-1 (Intra-argument Contract)\nThe function expects a valid .h5 file with a compatible model architecture, but the input model structure is missing or improperly defined.\n\nLeaf Contract Category: IC-1 (Intra-argument Contract)\nThe issue directly involves an argument inconsistency within the load_weights() function, where the model structure is not properly set up before loading weights.\n\nRoot Cause: Unacceptable Input Value\nThe user attempts to load weights into a model that hasn�t been defined, leading to an error about read-only mode.\n\nEffect: Crash\nThe program fails and raises a ValueError, preventing further execution.\n\nML Library: Keras\nThe error occurs due to the way Keras handles loading model weights.\n\nContract Violation Location: Load\nThe issue arises while attempting to load pre-trained model weights.\n\nDetection Technique: Static\nThe issue can be detected through static analysis by verifying that the model architecture is defined before calling load_weights().\n\n\n"
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/49834380",
    "title": "",
    "question": "years, 10 months ago\nModified 4 years, 8 months ago\nViewed 14k times\n12\n\nI have CNN models trained using Keras with Tensorflow backend. And I want to visualize my CNN filters with this tutorial: https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html\n\nfrom keras import backend as K\nfrom keras.models import load_model\nimport numpy as np\n\nmodel = load_model('my_cnn_model.h5')\ninput_img = np.load('my_picture.npy')\n\n# get the symbolic outputs of each \"key\" layer (we gave them unique names).\nlayer_dict = dict([(layer.name, layer) for layer in model.layers])\n\nlayer_name = 'block5_conv3'\nfilter_index = 0  # can be any integer from 0 to 511, as there are 512 filters in that layer\n\n# build a loss function that maximizes the activation\n# of the nth filter of the layer considered\nlayer_output = layer_dict[layer_name].output\nloss = K.mean(layer_output[:, :, :, filter_index])\n\n# compute the gradient of the input picture wrt this loss\ngrads = K.gradients(loss, input_img)[0]\n\n# normalization trick: we normalize the gradient\ngrads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n\n# this function returns the loss and grads given the input picture\niterate = K.function([input_img], [loss, grads])\nHowever, when the code execute to this line:\ngrads = K.gradients(loss, input_img)[0]\nI found it returns nothing but None object, so the program fail to progress after that.\n\nI search for some solution. Some people say theinput_img should be tensorflow's Tensor type: https://github.com/keras-team/keras/issues/5455\n\nBut when I tried to convert the img to Tensor, the problem is still exist.\nI tried the solution in the link above, but still fail.\n\nThere is also someone say that this problem exists because your CNN model is not differentiable. https://github.com/keras-team/keras/issues/8478\n\nBut my model use only the activate function of ReLU and Sigmoid(at output layer). Is this problem really caused by nondifferentiable problem?\n\nCan anyone help me? Thank you very much!",
    "answer": "12\n\nIf you have a Model instance, then to take the gradient of the loss with respect to the input, you should do:\n\ngrads = K.gradients(loss, model.input)[0]\nmodel.input contains the symbolic tensor that represents the input to the model. Using a plain numpy array makes no sense because TensorFlow then has no idea how this connects to the computational graph, and returns None as the gradient.\n\nThen you should also rewrite the iterate function as:\n\niterate = K.function([model.input], [loss, grads])",
    "mlApiName": "keras.backend.function, keras.backend.gradients",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "F",
      "level3": "F",
      "leafContractCategory": "F",
      "rootCause": "Missing Required State-specific Method Order",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Evaluation",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): AMO (API Method Order)\nThe issue arises due to the incorrect order of API method calls when computing gradients using K.gradients.\n\nLevel 2: F (Eventually Required Condition)\nThe function K.gradients(loss, input_img)[0] expects a TensorFlow tensor as input, but the user mistakenly provides a NumPy array, breaking the expected execution sequence.\n\nLevel 3 (Hybrid Patterns): F (Eventually Required Condition), F (Eventually Required Condition)\nThe computational graph fails because the provided input is not part of TensorFlow�s symbolic execution, which is necessary for gradient computation.\n\nLeaf Contract Category: F (Eventually Required Condition)\nThe API expects input_img to be a valid tensor, but it isn't, violating the eventual requirement for differentiability.\n\nRoot Cause: Missing Required State-specific Method Order\nThe user did not ensure that input_img is properly incorporated into the TensorFlow computation graph before using it in K.gradients.\n\nEffect: Crash\nThe function returns None instead of gradients, causing the program to fail when the returned value is used later.\n\nML Library: Keras\nThe issue specifically arises from the Keras backend functions (K.gradients, K.function).\n\nContract Violation Location: Model Evaluation\nThe error occurs while attempting to evaluate model gradients during CNN filter visualization.\n\nDetection Technique: Static\nThe issue can be identified by inspecting how K.gradients operates and ensuring that all inputs are TensorFlow tensors rather than NumPy arrays."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/34716454",
    "title": "",
    "question": "213\n\nIf I want to use the BatchNormalization function in Keras, then do I need to call it once only at the beginning?\n\nI read this documentation for it: http://keras.io/layers/normalization/\n\nI don't see where I'm supposed to call it. Below is my code attempting to use it:\n\nmodel = Sequential()\nkeras.layers.normalization.BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)\nmodel.add(Dense(64, input_dim=14, init='uniform'))\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, init='uniform'))\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2, init='uniform'))\nmodel.add(Activation('softmax'))\n\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='binary_crossentropy', optimizer=sgd)\nmodel.fit(X_train, y_train, nb_epoch=20, batch_size=16, show_accuracy=True, validation_split=0.2, verbose = 2)\nI ask because if I run the code with the second line including the batch normalization and if I run the code without the second line I get similar outputs. So either I'm not calling the function in the right place, or I guess it doesn't make that much of a difference.",
    "answer": "270\n\nAs Pavel said, Batch Normalization is just another layer, so you can use it as such to create your desired network architecture.\n\nThe general use case is to use BN between the linear and non-linear layers in your network, because it normalizes the input to your activation function, so that you're centered in the linear section of the activation function (such as Sigmoid). There's a small discussion of it here\n\nIn your case above, this might look like:\n\n# import BatchNormalization\nfrom keras.layers.normalization import BatchNormalization\n\n# instantiate model\nmodel = Sequential()\n\n# we can think of this chunk as the input layer\nmodel.add(Dense(64, input_dim=14, init='uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\n\n# we can think of this chunk as the hidden layer    \nmodel.add(Dense(64, init='uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\n\n# we can think of this chunk as the output layer\nmodel.add(Dense(2, init='uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('softmax'))\n\n# setting up the optimization of our weights \nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='binary_crossentropy', optimizer=sgd)\n\n# running the fitting\nmodel.fit(X_train, y_train, nb_epoch=20, batch_size=16, show_accuracy=True, validation_split=0.2, verbose = 2)\nShare",
    "mlApiName": "keras.layers.Activation, keras.layers.BatchNormalization, keras.layers.Dense",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "F",
      "level3": "F",
      "leafContractCategory": "F",
      "rootCause": "Missing Required State-specific Method Order",
      "effect": "BP",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model construction",
      "detectionTechnique": "Runtime Checking",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): AMO (API Method Order)\nThe issue stems from incorrect ordering of method calls�BatchNormalization is not properly placed in the model's layer structure.\n\nLevel 2: F (Eventually Required Condition)\nBatchNormalization must be positioned between Dense and Activation layers to function correctly.\n\nLevel 3 (Hybrid Patterns): F (Eventually Required Condition), F (Eventually Required Condition)\nThe normalization step needs to be applied at the correct location, ensuring proper input scaling before activation functions.\n\nLeaf Contract Category: F (Eventually Required Condition)\nThe issue arises because the layer was not placed where it is needed for effective normalization.\n\nRoot Cause: Missing Required State-specific Method Order\nThe BatchNormalization layer was not inserted in the right sequence, leading to no meaningful change in training behavior.\n\nEffect: BP (Bad Prediction)\nThe model trains, but predictions remain unaffected, indicating ineffective normalization.\n\nML Library: Keras\nThe issue specifically relates to Keras' model construction and layer ordering.\n\nContract Violation Location: Model Construction\nThe problem occurs when building the model structure before training.\n\nDetection Technique: Runtime Checking\nThe issue is detected at runtime, as the user notices no significant difference in model performance despite using BatchNormalization incorrectly.\n\n\n"
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/48846332",
    "title": "",
    "question": "10\n\nI train a model A and try to use the output of the intermediate layer with the name=\"layer_x\" as an additional input for model B.\n\nI tried to use the output of the intermediate layer like on the Keras doc https://keras.io/getting-started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer.\n\nModel A:\n\ninputs = Input(shape=(100,))\ndnn = Dense(1024, activation='relu')(inputs)\ndnn = Dense(128, activation='relu', name=\"layer_x\")(dnn)\ndnn = Dense(1024, activation='relu')(dnn)\noutput = Dense(10, activation='softmax')(dnn)\nModel B:\n\ninput_1 = Input(shape=(200,))\ninput_2 = Input(shape=(100,)) # input for model A\n\n# loading model A\nmodel_a = keras.models.load_model(path_to_saved_model_a)\n\nintermediate_layer_model = Model(inputs=model_a.input, \n                                 outputs=model_a.get_layer(\"layer_x\").output)\n\nintermediate_output = intermediate_layer_model.predict(data)\n\nmerge_layer = concatenate([input_1, intermediate_output])\ndnn_layer = Dense(512, activation=\"relu\")(merge_layer)\noutput = Dense(5, activation=\"sigmoid\")(dnn_layer)\nmodel = keras.models.Model(inputs=[input_1, input_2], outputs=output)\nWhen I debug I get an error on this line:\n\nintermediate_layer_model = Model(inputs=model_a.input, \n                                 outputs=model_a.get_layer(\"layer_x\").output)\n\nFile \"..\", line 89, in set_model\n  outputs=self.neural_net_asc.model.get_layer(\"layer_x\").output)\nFile \"C:\\WinPython\\python-3.5.3.amd64\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 87, in wrapper\n  return func(*args, **kwargs)\nFile \"C:\\WinPython\\python-3.5.3.amd64\\lib\\site-packages\\keras\\engine\\topology.py\", line 1592, in __init__\n  mask = node.output_masks[tensor_index]\nAttributeError: 'Node' object has no attribute 'output_masks'\nI can access the tensor with get_layer(\"layer_x\").output and the output_mask is None. Do I have to set manually an output mask and how do I set up this output mask if needed?",
    "answer": "There are two things that you seem to be doing wrong :\n\nintermediate_output = intermediate_layer_model.predict(data)\nwhen you do .predict(), you are actually passing data through the graph and asking what will be the result. When you do that, intermediate_output will be a numpy array and not a layer as you would like it to be.\n\nSecondly, you don't need to recreate a new intermediate model. You can directly use the part of model_a that interest you.\n\nHere is a code that \"compiles\" for me :\n\nfrom keras.layers import Input, Dense, concatenate\nfrom keras.models import Model\n\ninputs = Input(shape=(100,))\ndnn = Dense(1024, activation='relu')(inputs)\ndnn = Dense(128, activation='relu', name=\"layer_x\")(dnn)\ndnn = Dense(1024, activation='relu')(dnn)\noutput = Dense(10, activation='softmax')(dnn)\n\nmodel_a = Model(inputs=inputs, outputs=output)\n\n# You don't need to recreate an input for the model_a, \n# it already has one and you can reuse it\ninput_b = Input(shape=(200,))\n\n# Here you get the layer that interests you from model_a, \n# it is still linked to its input layer, you just need to remember it for later\nintermediate_from_a = model_a.get_layer(\"layer_x\").output\n\n# Since intermediate_from_a is a layer, you can concatenate it with the other input\nmerge_layer = concatenate([input_b, intermediate_from_a])\ndnn_layer = Dense(512, activation=\"relu\")(merge_layer)\noutput_b = Dense(5, activation=\"sigmoid\")(dnn_layer)\n# Here you remember that one input is input_b and the other one is from model_a\nmodel_b = Model(inputs=[input_b, model_a.input], outputs=output_b)\nI hope this is what you wanted to do.\n\nPlease tell me if something isn't clear :-)",
    "mlApiName": "keras.models.Model, keras.models.model.predict",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "F",
      "level3": "F",
      "leafContractCategory": "AMO(Level-2)",
      "rootCause": "Missing Options",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Prediction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): Hybrid\nThe issue involves combining multiple Keras models (Model A and Model B) and incorrectly handling intermediate layer outputs, leading to a hybrid contract violation.\n\nLevel 2: F (Eventually Required Condition)\nThe intermediate layer must remain part of the TensorFlow computation graph, but calling predict() prematurely converts it into a NumPy array, breaking this requirement.\n\nLevel 3 (Hybrid Patterns): F (Eventually Required Condition), IC-1 (Intra-argument Contract)\nThe function expects a tensor but receives an incorrect argument type, violating both expected execution flow and argument structure.\n\nLeaf Contract Category: AMO (Level-2)\nThe violation stems from incorrect method order�predict() is used instead of passing the tensor output directly.\n\nRoot Cause: Missing Options\nThe user did not properly extract the intermediate output while maintaining its graph dependency.\n\nEffect: Crash\nThe incorrect API usage results in an AttributeError, leading to program failure.\n\nML Library: Keras\nThe issue is specific to Keras' functional API and model composition.\n\nContract Violation Location: Prediction\nThe error occurs when attempting to use an intermediate layer output as input for another model.\n\nDetection Technique: Static\nThe mistake can be detected by verifying that intermediate layers are properly referenced within the functional API instead of being converted to NumPy arrays."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/51100508",
    "title": "",
    "question": "9\n\nI need some help with keras loss function. I have been implementing custom loss function on keras with Tensorflow backend.\n\nI have implemented the custom loss function in numpy but it would be great if it could be translated into keras loss function. The loss function takes dataframe and series of user id. The Euclidean distance for same user_id are positive and negative if the user_id are different. The function returns summed up scalar distance of the dataframe.\n\ndef custom_loss_numpy (encodings, user_id):\n# user_id: a pandas series of users\n# encodings: a pandas dataframe of encodings\n\n    batch_dist = 0\n\n    for i in range(len(user_id)):\n         first_row = encodings.iloc[i,:].values\n         first_user = user_id[i]\n\n         for j in range(i+1, len(user_id)):\n              second_user = user_id[j]\n              second_row = encodings.iloc[j,:].values\n\n        # compute distance: if the users are same then Euclidean distance is positive otherwise negative.\n            if first_user == second_user:\n                tmp_dist = np.linalg.norm(first_row - second_row)\n            else:\n                tmp_dist = -np.linalg.norm(first_row - second_row)\n\n            batch_dist += tmp_dist\n\n    return batch_dist\nI have tried to implement into keras loss function. I extracted numpy array from y_true and y_pred tensor objects.\n\ndef custom_loss_keras(y_true, y_pred):\n    # session of my program\n    sess = tf_session.TF_Session().get()\n\n    with sess.as_default():\n        array_pred = y_pred.eval()\n        print(array_pred)\nBut I get the following error.\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'dense_1_input' with dtype float and shape [?,102]\n [[Node: dense_1_input = Placeholder[dtype=DT_FLOAT, shape=[?,102], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nAny kind of help would be really appreciated.",
    "answer": "First of all, it is not possible to \"extract numpy array from y_true and y_pred\" in Keras loss functions. You have to operate the tensors with Keras backend functions (or TF functions) to calculate the loss.\n\nIn other words, it would be better to think about a \"vectorized\" way to calculate the loss, without using if-else and loops.\n\nYour loss function can be computed in the following steps:\n\nGenerate a matrix of pairwise Euclidean distances, between all pairs of vectors in encodings.\nGenerate a matrix I whose element I_ij is 1 if user_i == user_j, and -1 if user_i != user_j.\nElement-wise multiply the two matrices, and sum up the elements to get the final loss.\nHere's an implementation:\n\ndef custom_loss_keras(user_id, encodings):\n    # calculate pairwise Euclidean distance matrix\n    pairwise_diff = K.expand_dims(encodings, 0) - K.expand_dims(encodings, 1)\n    pairwise_squared_distance = K.sum(K.square(pairwise_diff), axis=-1)\n\n    # add a small number before taking K.sqrt for numerical safety\n    # (K.sqrt(0) sometimes becomes nan)\n    pairwise_distance = K.sqrt(pairwise_squared_distance + K.epsilon())\n\n    # this will be a pairwise matrix of True and False, with shape (batch_size, batch_size)\n    pairwise_equal = K.equal(K.expand_dims(user_id, 0), K.expand_dims(user_id, 1))\n\n    # convert True and False to 1 and -1\n    pos_neg = K.cast(pairwise_equal, K.floatx()) * 2 - 1\n\n    # divide by 2 to match the output of `custom_loss_numpy`, but it's not really necessary\n    return K.sum(pairwise_distance * pos_neg, axis=-1) / 2\nI've assumed that user_id are integers in the code above. The trick here is to use K.expand_dims for implementing pairwise operations. It's probably a bit difficult to understand at a first glance, but it's quite useful.\n\nIt should give about the same loss value as custom_loss_numpy (there will be a little bit difference because of K.epsilon()):\n\nencodings = np.random.rand(32, 10)\nuser_id = np.random.randint(10, size=32)\n\nprint(K.eval(custom_loss_keras(K.variable(user_id), K.variable(encodings))).sum())\n-478.4245\n\nprint(custom_loss_numpy(pd.DataFrame(encodings), pd.Series(user_id)))\n-478.42953553795815\nI've made a mistake in the loss function.\n\nWhen this function is used in training, since Keras automatically changes y_true to be at least 2D, the argument user_id is no longer a 1D tensor. The shape of it will be (batch_size, 1).\n\nIn order to use this function, the extra axis must be removed:\n\ndef custom_loss_keras(user_id, encodings):\n    pairwise_diff = K.expand_dims(encodings, 0) - K.expand_dims(encodings, 1)\n    pairwise_squared_distance = K.sum(K.square(pairwise_diff), axis=-1)\n    pairwise_distance = K.sqrt(pairwise_squared_distance + K.epsilon())\n\n    user_id = K.squeeze(user_id, axis=1)  # remove the axis added by Keras\n    pairwise_equal = K.equal(K.expand_dims(user_id, 0), K.expand_dims(user_id, 1))\n\n    pos_neg = K.cast(pairwise_equal, K.floatx()) * 2 - 1\n    return K.sum(pairwise_distance * pos_neg, axis=-",
    "mlApiName": "keras.backend.sqrt, keras.backend.expand_dims",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "F, IC-1",
      "leafContractCategory": "Comb. of SAM(Level 3) and AMO(Level 2)",
      "rootCause": "Missing Options",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): Hybrid\nThe issue involves multiple Keras API functions (K.sqrt, K.expand_dims) in a custom loss function, making it a hybrid contract violation.\n\nLevel 2: SL (Selection Issue)\nThe user incorrectly selects NumPy-style operations instead of TensorFlow/Keras backend functions for tensor calculations.\n\nLevel 3 (Hybrid Patterns): F (Eventually Required Condition), IC-1 (Intra-argument Contract)\nThe function fails because it does not properly handle tensor-based operations, which Keras loss functions require.\n\nLeaf Contract Category: Combination of SAM(Level 3) and AMO(Level 2)\nThe issue stems from both single API method misuse (K.sqrt, K.expand_dims) and method-order dependencies (ensuring proper tensor operations before evaluation).\n\nRoot Cause: Missing Options\nThe user attempts to extract NumPy arrays from Keras tensors, which is not possible within a loss function.\n\nEffect: Crash\nThe program fails with an InvalidArgumentError due to improper use of Keras backend functions in loss computation.\n\nML Library: Keras\nThe issue is specific to Keras� backend operations in defining a custom loss function.\n\nContract Violation Location: Model Construction\nThe error occurs while constructing the model with an incorrectly implemented loss function.\n\nDetection Technique: Static\nThe mistake can be identified through static analysis by ensuring that loss functions use valid Keras/TensorFlow operations instead of NumPy-based calculations.\n\n\n"
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/41378461",
    "title": "",
    "question": "21\n\nI want to get pretrained VGG16 model in Keras, remove its output layer, and then put a new output layer with the number of classes suited for my problem, and then to fit it on new data. For this reason, I am trying to use the model here: https://keras.io/applications/#vgg16, but since it is not Sequential, I cannot just model.pop(). Popping from layers and adding it also does not work, because in the predictions it still expects the old shape. How would I do that? Is there a way to convert this type of model to Sequential?",
    "answer": "56\n\nYou can use pop() on model.layers and then use model.layers[-1].output to create new layers.\n\nExample:\n\nfrom keras.models import Model\nfrom keras.layers import Dense,Flatten\nfrom keras.applications import vgg16\nfrom keras import backend as K\n\nmodel = vgg16.VGG16(weights='imagenet', include_top=True)\n\nmodel.input\n\nmodel.summary(line_length=150)\n\nmodel.layers.pop()\nmodel.layers.pop()\n\nmodel.summary(line_length=150)\n\nnew_layer = Dense(10, activation='softmax', name='my_dense')\n\ninp = model.input\nout = new_layer(model.layers[-1].output)\n\nmodel2 = Model(inp, out)\nmodel2.summary(line_length=150)\nAlternatively, you can use include_top=False option of these models. In this case if you need to use flatten the layer then you need to pass the input_shape also.\n\nmodel3 = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nmodel3.summary(line_length=150)\n\nflatten = Flatten()\nnew_layer2 = Dense(10, activation='softmax', name='my_dense_2')\n\ninp2 = model3.input\nout2 = new_layer2(flatten(model3.output))\n\nmodel4 = Model(inp2, out2)\nmodel4.summary(line_length=150)",
    "mlApiName": "keras.models.pop, keras.applications.vgg16.VGG16, keras.layers, keras.models",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "F, F, IC-1",
      "leafContractCategory": "Comb. of SAM(Level 3) and AMO(Level 2)",
      "rootCause": "Missing Options",
      "effect": "IF",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): Hybrid\nThe issue involves multiple Keras API methods (VGG16, pop, layers, models), leading to a hybrid contract violation.\n\nLevel 2: SL (Selection Issue)\nThe user incorrectly selects pop() to remove layers, which does not work for functional API models like VGG16.\n\nLevel 3 (Hybrid Patterns): F (Eventually Required Condition), F (Eventually Required Condition), IC-1 (Intra-argument Contract)\nThe model modification requires specific API calls to ensure proper structure, which was not followed.\n\nLeaf Contract Category: Combination of SAM(Level 3) and AMO(Level 2)\nThe violation arises due to a combination of single API misuse (pop()) and incorrect method ordering.\n\nRoot Cause: Missing Options\nThe user did not use the include_top=False argument when loading VGG16, which would allow proper customization.\n\nEffect: IF (Incorrect Functionality)\nThe model still expects the original output shape, leading to incorrect behavior.\n\nML Library: Keras\nThe issue is specific to modifying pre-trained Keras models.\n\nContract Violation Location: Model Construction\nThe error occurs during the modification of the model architecture.\n\nDetection Technique: Static\nThe incorrect use of pop() with functional API models can be identified through static analysis by verifying if layer modifications are properly reflected in the model structure."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/41651628",
    "title": "",
    "question": "66\n\nI'm using Keras with Tensorflow as backend , here is my code:\n\nimport numpy as np\nnp.random.seed(1373) \nimport tensorflow as tf\ntf.python.control_flow_ops = tf\n\nimport os\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D\nfrom keras.utils import np_utils\n\nbatch_size = 128\nnb_classes = 10\nnb_epoch = 12\n\nimg_rows, img_cols = 28, 28\n\nnb_filters = 32\n\nnb_pool = 2\n\nnb_conv = 3\n\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n\nprint(X_train.shape[0])\n\nX_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\nX_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\nX_train /= 255\nX_test /= 255\n\nprint('X_train shape:', X_train.shape)\nprint(X_train.shape[0], 'train samples')\nprint(X_test.shape[0], 'test samples')\n\nY_train = np_utils.to_categorical(y_train, nb_classes)\nY_test = np_utils.to_categorical(y_test, nb_classes)\n\nmodel = Sequential()\n\nmodel.add(Convolution2D(nb_filters, nb_conv, nb_conv,\nborder_mode='valid',\ninput_shape=(1, img_rows, img_cols)))\nmodel.add(Activation('relu'))\nmodel.add(Convolution2D(nb_filters, nb_conv, nb_conv))\nmodel.add(Activation('relu'))\n\nmodel.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(128))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(nb_classes)) \nmodel.add(Activation('softmax')) \n\nmodel.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=[\"accuracy\"])\n\nmodel.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\nverbose=1, validation_data=(X_test, Y_test))\n\nscore = model.evaluate(X_test, Y_test, verbose=0)\n\nprint('Test score:', score[0])\nprint('Test accuracy:', score[1])\nand Trackback error:\n\nUsing TensorFlow backend.\n60000\n('X_train shape:', (60000, 1, 28, 28))\n(60000, 'train samples')\n(10000, 'test samples')\nTraceback (most recent call last):\n  File \"mnist.py\", line 154, in \n    input_shape=(1, img_rows, img_cols)))\n  File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 276, in add\n    layer.create_input_layer(batch_input_shape, input_dtype)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py\", line 370, in create_input_layer\n    self(x)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py\", line 514, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py\", line 572, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py\", line 149, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/usr/local/lib/python2.7/dist-packages/keras/layers/convolutional.py\", line 466, in call\n    filter_shape=self.W_shape)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py\", line 1579, in conv2d\n    x = tf.nn.conv2d(x, kernel, strides, padding=padding)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 396, in conv2d\n    data_format=data_format, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2242, in create_op\n    set_shapes_for_outputs(ret)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1617, in set_shapes_for_outputs\n    shapes = shape_func(op)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1568, in call_with_requiring\n    return call_cpp_shape_fn(op, require_shape_fn=True)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py\", line 610, in call_cpp_shape_fn\n    debug_python_shape_fn, require_shape_fn)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py\", line 675, in _call_cpp_shape_fn_impl\n    raise ValueError(err.message)\nValueError: Negative dimension size caused by subtracting 3 from 1 for 'Conv2D' (op: 'Conv2D') with input shapes: [?,1,28,28], [3,3,28,32].\nFirst I saw some answers that problem is with Tensorflow version so I upgrade Tensorflow to 0.12.0, but still exist , is that problem with network or I missing something, what should input_shape looks like?\n\nUpdate Here is ./keras/keras.json:\n\n{\n    \"image_dim_ordering\": \"tf\", \n    \"epsilon\": 1e-07, \n    \"floatx\": \"float32\", \n    \"backend\": \"tensorflow\"\n}",
    "answer": "95\n\n+50\nYour issue comes from the image_ordering_dim in keras.json.\n\nFrom Keras Image Processing doc:\n\ndim_ordering: One of {\"th\", \"tf\"}. \"tf\" mode means that the images should have shape (samples, height, width, channels), \"th\" mode means that the images should have shape (samples, channels, height, width). It defaults to the image_dim_ordering value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"tf\".\n\nKeras maps the convolution operation to the chosen backend (theano or tensorflow). However, both backends have made different choices for the ordering of the dimensions. If your image batch is of N images of HxW size with C channels, theano uses the NCHW ordering while tensorflow uses the NHWC ordering.\n\nKeras allows you to choose which ordering you prefer and will do the conversion to map to the backends behind. But if you choose image_ordering_dim=\"th\" it expects Theano-style ordering (NCHW, the one you have in your code) and if image_ordering_dim=\"tf\" it expects tensorflow-style ordering (NHWC).\n\nSince your image_ordering_dim is set to \"tf\", if you reshape your data to the tensorflow style it should work:\n\nX_train = X_train.reshape(X_train.shape[0], img_cols, img_rows, 1)\nX_test = X_test.reshape(X_test.shape[0], img_cols, img_rows, 1)\nand\n\ninput_shape=(img_cols, img_rows, 1)",
    "mlApiName": "keras.json.set_image_dim_ordering, keras.models.fit",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "F, IC-2",
      "leafContractCategory": "Comb. of SAM(Level 3) and AMO(Level 2)",
      "rootCause": "Missing Options",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Train",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): Hybrid\nThe issue arises from multiple interacting API methods (set_image_dim_ordering, model.fit), leading to a hybrid contract violation.\n\nLevel 2: SL (Selection Issue)\nThe error is due to an incorrect selection of image dimension ordering, causing the input shape to be mismatched.\n\nLevel 3 (Hybrid Patterns): F (Eventually Required Condition), IC-2 (Inter-argument Contract)\nThe problem involves both missing a required configuration (image_dim_ordering) and incorrect dependencies between function arguments (input_shape mismatch).\n\nLeaf Contract Category: Combination of SAM (Level 3) and AMO (Level 2)\nThe issue arises from improper configuration (SAM) and incorrect method order dependencies (AMO) when setting up the model.\n\nRoot Cause: Missing Options\nThe user did not correctly configure the input shape based on the backend's expected image ordering.\n\nEffect: Crash\nThe model fails at runtime due to a negative dimension size caused by incorrect reshaping.\n\nML Library: Keras\nThe issue is specific to Keras' image processing and model setup.\n\nContract Violation Location: Train\nThe error occurs during the training phase when attempting to fit data to the model.\n\nDetection Technique: Static\nThe issue can be identified through static analysis by verifying that the input shape correctly follows the backend�s expected format (NHWC for TensorFlow, NCHW for Theano).\n\n\n"
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/47599436",
    "title": "",
    "question": "12\n\nI am trying to make a simple proof-of-concept where I can see the probabilities of different classes for a given prediction.\n\nHowever, everything I try seems to only output the predicted class, even though I am using a softmax activation. I am new to machine learning, so I'm not sure if I am making a simple mistake or if this is a feature not available in Keras.\n\nI'm using Keras + TensorFlow. I have adapted one of the basic examples given by Keras for classifying the MNIST dataset.\n\nMy code below is exactly the same as the example, except for a few (commented) extra lines that exports the model to a local file.\n\n'''Trains a simple deep NN on the MNIST dataset.\nGets to 98.40% test accuracy after 20 epochs\n(there is *a lot* of margin for parameter tuning).\n2 seconds per epoch on a K520 GPU.\n'''\n\nfrom __future__ import print_function\n\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.optimizers import RMSprop\n\nimport h5py # added import because it is required for model.save\nmodel_filepath = 'test_model.h5' # added filepath config\n\nbatch_size = 128\nnum_classes = 10\nepochs = 20\n\n# the data, shuffled and split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.reshape(60000, 784)\nx_test = x_test.reshape(10000, 784)\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\nmodel = Sequential()\nmodel.add(Dense(512, activation='relu', input_shape=(784,)))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.summary()\n\nmodel.compile(loss='categorical_crossentropy',\n          optimizer=RMSprop(),\n          metrics=['accuracy'])\n\nhistory = model.fit(x_train, y_train,\n                batch_size=batch_size,\n                epochs=epochs,\n                verbose=1,\n                validation_data=(x_test, y_test))\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n\nmodel.save(model_filepath) # added saving model\nprint('Model saved') # added log\nThen the second part of this is a simple script that should import the model, predict the class for some given data, and print out the probabilities for each class. (I am using the same mnist class included with the Keras codebase to make an example as simple as possible).\n\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nimport keras.backend as K\n\nimport numpy\n\n# loading model saved locally in test_model.h5\nmodel_filepath = 'test_model.h5'\nprev_model = keras.models.load_model(model_filepath)\n\n# these lines are copied from the example for loading MNIST data\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train = x_train.reshape(60000, 784)\n\n# for this example, I am only taking the first 10 images\nx_slice = x_train[slice(1, 11, 1)]\n\n# making the prediction\nprediction = prev_model.predict(x_slice)\n\n# logging each on a separate line\nfor single_prediction in prediction:\n    print(single_prediction)\nIf I run the first script to export the model, then the second script to classify some examples, I get the following output:\n\n[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\nThis is great for seeing which class each is predicted to be, but what if I want to see the relative probabilities of each class for each example? I am looking for something more like this:\n\n[ 0.94 0.01 0.02 0. 0. 0.01 0. 0.01 0.01 0.]\n[ 0. 0. 0. 0. 0.51 0. 0. 0. 0.49 0.]\n...\nIn other words, I need to know how sure each prediction is, not just the prediction itself. I thought seeing the relative probabilities was a part of using a softmax activation in the model, but I can't seem to find anything in the Keras documentation that would give me probabilities instead of the predicted answer. Am I making some kind of silly mistake, or is this feature not available?",
    "answer": "12\n\nSo it turns out that the problem was I was not fully normalizing the data in the prediction script.\n\nMy prediction script should have had the following lines:\n\n# these lines are copied from the example for loading MNIST data\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train = x_train.reshape(60000, 784)\nx_train = x_train.astype('float32') # this line was missing\nx_train /= 255 # this line was missing too\nBecause the data was not cast to float, and divided by 255 (so it would be between 0 and 1), it was just showing up as 1s and 0s.",
    "mlApiName": "keras.models.fit",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Train",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): SAM (Single API Method)\nThe issue is related to incorrect usage of the model.fit() function, making it a single API method violation.\n\nLevel 2: BET (Behavioral Expectation Type)\nThe user expects softmax probabilities to be returned, but due to improper data preprocessing, the model behaves unexpectedly.\n\nLevel 3 (Hybrid Patterns): IC-1 (Intra-argument Contract)\nThe issue arises due to an internal argument inconsistency�the input data is not properly normalized, leading to incorrect softmax outputs.\n\nLeaf Contract Category: IC-1 (Intra-argument Contract)\nThe incorrect normalization affects internal consistency within the model, violating expected input constraints.\n\nRoot Cause: Unacceptable Input Value\nThe training data was not normalized (missing x_train = x_train.astype('float32') and x_train /= 255), leading to incorrect outputs.\n\nEffect: Crash\nThe model fails to return probability distributions as expected, instead outputting one-hot vectors.\n\nML Library: Keras\nThe issue specifically relates to Keras' model training process.\n\nContract Violation Location: Train\nThe problem occurs during the training phase when the dataset is improperly preprocessed.\n\nDetection Technique: Static\nThe issue can be detected by verifying the data preprocessing steps before training, ensuring normalization is correctly applied."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/49834380",
    "title": "",
    "question": "I have CNN models trained using Keras with Tensorflow backend. And I want to visualize my CNN filters with this tutorial: https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html\n\nfrom keras import backend as K\nfrom keras.models import load_model\nimport numpy as np\n\nmodel = load_model('my_cnn_model.h5')\ninput_img = np.load('my_picture.npy')\n\n# get the symbolic outputs of each \"key\" layer (we gave them unique names).\nlayer_dict = dict([(layer.name, layer) for layer in model.layers])\n\nlayer_name = 'block5_conv3'\nfilter_index = 0  # can be any integer from 0 to 511, as there are 512 filters in that layer\n\n# build a loss function that maximizes the activation\n# of the nth filter of the layer considered\nlayer_output = layer_dict[layer_name].output\nloss = K.mean(layer_output[:, :, :, filter_index])\n\n# compute the gradient of the input picture wrt this loss\ngrads = K.gradients(loss, input_img)[0]\n\n# normalization trick: we normalize the gradient\ngrads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n\n# this function returns the loss and grads given the input picture\niterate = K.function([input_img], [loss, grads])\nHowever, when the code execute to this line:\ngrads = K.gradients(loss, input_img)[0]\nI found it returns nothing but None object, so the program fail to progress after that.\n\nI search for some solution. Some people say theinput_img should be tensorflow's Tensor type: https://github.com/keras-team/keras/issues/5455\n\nBut when I tried to convert the img to Tensor, the problem is still exist.\nI tried the solution in the link above, but still fail.\n\nThere is also someone say that this problem exists because your CNN model is not differentiable. https://github.com/keras-team/keras/issues/8478\n\nBut my model use only the activate function of ReLU and Sigmoid(at output layer). Is this problem really caused by nondifferentiable problem?\n\nCan anyone help me? Thank you very much!",
    "answer": "12\n\nIf you have a Model instance, then to take the gradient of the loss with respect to the input, you should do:\n\ngrads = K.gradients(loss, model.input)[0]\nmodel.input contains the symbolic tensor that represents the input to the model. Using a plain numpy array makes no sense because TensorFlow then has no idea how this connects to the computational graph, and returns None as the gradient.\n\nThen you should also rewrite the iterate function as:\n\niterate = K.function([model.input], [loss, grads])",
    "mlApiName": "keras.backend.function, keras.backend.gradients",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "F",
      "level3": "F",
      "leafContractCategory": "F",
      "rootCause": "Missing Required State-specific Method Order",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Evaluation",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): AMO (API Method Order)\nThe issue occurs due to an incorrect sequence of method calls�using K.gradients with an invalid input type.\n\nLevel 2: F (Eventually Required Condition)\nThe computation graph requires that input_img be a TensorFlow tensor, but the user provides a NumPy array, breaking the required condition.\n\nLevel 3 (Hybrid Patterns): F (Eventually Required Condition), F (Eventually Required Condition)\nThe issue arises because K.gradients expects an input that is part of the computational graph, which wasn�t ensured.\n\nLeaf Contract Category: F (Eventually Required Condition)\nThe function relies on the input being properly set up in the computation graph, which wasn�t done.\n\nRoot Cause: Missing Required State-specific Method Order\nThe user did not pass a valid tensor to K.gradients, leading to an incorrect execution order.\n\nEffect: Crash\nThe function returns None, causing the program to fail when it tries to use the gradient.\n\nML Library: Keras\nThe issue is specific to Keras backend operations for computing gradients.\n\nContract Violation Location: Model Evaluation\nThe error occurs when attempting to compute gradients for CNN filter visualization.\n\nDetection Technique: Static\nThe issue can be detected through static analysis by checking whether all function arguments are valid TensorFlow tensors before calling K.gradients()."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/34716454",
    "title": "",
    "question": "213\n\nIf I want to use the BatchNormalization function in Keras, then do I need to call it once only at the beginning?\n\nI read this documentation for it: http://keras.io/layers/normalization/\n\nI don't see where I'm supposed to call it. Below is my code attempting to use it:\n\nmodel = Sequential()\nkeras.layers.normalization.BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)\nmodel.add(Dense(64, input_dim=14, init='uniform'))\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, init='uniform'))\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2, init='uniform'))\nmodel.add(Activation('softmax'))\n\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='binary_crossentropy', optimizer=sgd)\nmodel.fit(X_train, y_train, nb_epoch=20, batch_size=16, show_accuracy=True, validation_split=0.2, verbose = 2)\nI ask because if I run the code with the second line including the batch normalization and if I run the code without the second line I get similar outputs. So either I'm not calling the function in the right place, or I guess it doesn't make that much of a difference.",
    "answer": "270\n\nAs Pavel said, Batch Normalization is just another layer, so you can use it as such to create your desired network architecture.\n\nThe general use case is to use BN between the linear and non-linear layers in your network, because it normalizes the input to your activation function, so that you're centered in the linear section of the activation function (such as Sigmoid). There's a small discussion of it here\n\nIn your case above, this might look like:\n\n# import BatchNormalization\nfrom keras.layers.normalization import BatchNormalization\n\n# instantiate model\nmodel = Sequential()\n\n# we can think of this chunk as the input layer\nmodel.add(Dense(64, input_dim=14, init='uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\n\n# we can think of this chunk as the hidden layer    \nmodel.add(Dense(64, init='uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\n\n# we can think of this chunk as the output layer\nmodel.add(Dense(2, init='uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('softmax'))\n\n# setting up the optimization of our weights \nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='binary_crossentropy', optimizer=sgd)\n\n# running the fitting\nmodel.fit(X_train, y_train, nb_epoch=20, batch_size=1",
    "mlApiName": "keras.layers.Activation, keras.layers.BatchNormalization, keras.layers.Dense",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "F",
      "level3": "F",
      "leafContractCategory": "F",
      "rootCause": "Missing Required State-specific Method Order",
      "effect": "BP",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model construction",
      "detectionTechnique": "Runtime Checking",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): AMO (API Method Order)\nThe issue arises due to incorrect ordering of API calls�BatchNormalization is not properly placed within the model's architecture.\n\nLevel 2: F (Eventually Required Condition)\nBatchNormalization should be positioned correctly between layers (before activation) for optimal functionality.\n\nLevel 3 (Hybrid Patterns): F (Eventually Required Condition), F (Eventually Required Condition)\nThe normalization step is not properly applied in the layer sequence, preventing it from functioning as expected.\n\nLeaf Contract Category: F (Eventually Required Condition)\nThe user�s incorrect ordering of layers violates the eventual requirement for proper feature scaling.\n\nRoot Cause: Missing Required State-specific Method Order\nThe user added BatchNormalization incorrectly, expecting it to work without integrating it properly into the computational graph.\n\nEffect: BP (Bad Prediction)\nThe model trains, but predictions remain unaffected, meaning BatchNormalization isn't applied where needed.\n\nML Library: Keras\nThe issue relates specifically to Keras model construction and layer ordering.\n\nContract Violation Location: Model Construction\nThe problem occurs at model setup, where layers are incorrectly arranged.\n\nDetection Technique: Runtime Checking\nThe issue becomes evident at runtime when the model does not behave as expected despite the presence of BatchNormalization."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/48846332",
    "title": "",
    "question": "10\n\nI train a model A and try to use the output of the intermediate layer with the name=\"layer_x\" as an additional input for model B.\n\nI tried to use the output of the intermediate layer like on the Keras doc https://keras.io/getting-started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer.\n\nModel A:\n\ninputs = Input(shape=(100,))\ndnn = Dense(1024, activation='relu')(inputs)\ndnn = Dense(128, activation='relu', name=\"layer_x\")(dnn)\ndnn = Dense(1024, activation='relu')(dnn)\noutput = Dense(10, activation='softmax')(dnn)\nModel B:\n\ninput_1 = Input(shape=(200,))\ninput_2 = Input(shape=(100,)) # input for model A\n\n# loading model A\nmodel_a = keras.models.load_model(path_to_saved_model_a)\n\nintermediate_layer_model = Model(inputs=model_a.input, \n                                 outputs=model_a.get_layer(\"layer_x\").output)\n\nintermediate_output = intermediate_layer_model.predict(data)\n\nmerge_layer = concatenate([input_1, intermediate_output])\ndnn_layer = Dense(512, activation=\"relu\")(merge_layer)\noutput = Dense(5, activation=\"sigmoid\")(dnn_layer)\nmodel = keras.models.Model(inputs=[input_1, input_2], outputs=output)\nWhen I debug I get an error on this line:\n\nintermediate_layer_model = Model(inputs=model_a.input, \n                                 outputs=model_a.get_layer(\"layer_x\").output)\n\nFile \"..\", line 89, in set_model\n  outputs=self.neural_net_asc.model.get_layer(\"layer_x\").output)\nFile \"C:\\WinPython\\python-3.5.3.amd64\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 87, in wrapper\n  return func(*args, **kwargs)\nFile \"C:\\WinPython\\python-3.5.3.amd64\\lib\\site-packages\\keras\\engine\\topology.py\", line 1592, in __init__\n  mask = node.output_masks[tensor_index]\nAttributeError: 'Node' object has no attribute 'output_masks'\nI can access the tensor with get_layer(\"layer_x\").output and the output_mask is None. Do I have to set manually an output mask and how do I set up this output mask if needed?\n\npython",
    "answer": "There are two things that you seem to be doing wrong :\n\nintermediate_output = intermediate_layer_model.predict(data)\nwhen you do .predict(), you are actually passing data through the graph and asking what will be the result. When you do that, intermediate_output will be a numpy array and not a layer as you would like it to be.\n\nSecondly, you don't need to recreate a new intermediate model. You can directly use the part of model_a that interest you.\n\nHere is a code that \"compiles\" for me :\n\nfrom keras.layers import Input, Dense, concatenate\nfrom keras.models import Model\n\ninputs = Input(shape=(100,))\ndnn = Dense(1024, activation='relu')(inputs)\ndnn = Dense(128, activation='relu', name=\"layer_x\")(dnn)\ndnn = Dense(1024, activation='relu')(dnn)\noutput = Dense(10, activation='softmax')(dnn)\n\nmodel_a = Model(inputs=inputs, outputs=output)\n\n# You don't need to recreate an input for the model_a, \n# it already has one and you can reuse it\ninput_b = Input(shape=(200,))\n\n# Here you get the layer that interests you from model_a, \n# it is still linked to its input layer, you just need to remember it for later\nintermediate_from_a = model_a.get_layer(\"layer_x\").output\n\n# Since intermediate_from_a is a layer, you can concatenate it with the other input\nmerge_layer = concatenate([input_b, intermediate_from_a])\ndnn_layer = Dense(512, activation=\"relu\")(merge_layer)\noutput_b = Dense(5, activation=\"sigmoid\")(dnn_layer)\n# Here you remember that one input is input_b and the other one is from model_a\nmodel_b = Model(inputs=[input_b, model_a.input], outputs=output_b)\nI hope this is what you wanted to do.\n\nPlease tell me if something isn't clear :-)",
    "mlApiName": "keras.models.Model, keras.models.model.predict",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "F",
      "level3": "F",
      "leafContractCategory": "AMO(Level-2)",
      "rootCause": "Missing Options",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Prediction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): Hybrid\nThe issue involves multiple Keras models (Model A and Model B) and the incorrect handling of intermediate layer outputs, leading to a hybrid contract violation.\n\nLevel 2: F (Eventually Required Condition)\nThe intermediate layer output must remain part of the computation graph, but calling predict() prematurely converts it into a NumPy array, breaking this requirement.\n\nLevel 3 (Hybrid Patterns): F (Eventually Required Condition), IC-2 (Inter-argument Contract)\nThe issue arises from an improper method call sequence that disrupts the computational graph and an inter-argument contract violation due to mismatched data formats.\n\nLeaf Contract Category: AMO (Level-2)\nThe violation stems from incorrect method ordering�using predict() instead of correctly extracting the layer output.\n\nRoot Cause: Missing Options\nThe user failed to maintain the intermediate layer as a valid tensor in the computational graph, leading to incorrect execution.\n\nEffect: Crash\nThe incorrect API usage results in an AttributeError, causing a runtime failure.\n\nML Library: Keras\nThe issue is specific to Keras' functional API and model composition.\n\nContract Violation Location: Prediction\nThe error occurs while attempting to use an intermediate layer output as input for another model.\n\nDetection Technique: Static\nThe mistake can be detected by verifying that intermediate layers are properly referenced within the functional API instead of being converted to NumPy arrays."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/51100508",
    "title": "",
    "question": "9\n\nI need some help with keras loss function. I have been implementing custom loss function on keras with Tensorflow backend.\n\nI have implemented the custom loss function in numpy but it would be great if it could be translated into keras loss function. The loss function takes dataframe and series of user id. The Euclidean distance for same user_id are positive and negative if the user_id are different. The function returns summed up scalar distance of the dataframe.\n\ndef custom_loss_numpy (encodings, user_id):\n# user_id: a pandas series of users\n# encodings: a pandas dataframe of encodings\n\n    batch_dist = 0\n\n    for i in range(len(user_id)):\n         first_row = encodings.iloc[i,:].values\n         first_user = user_id[i]\n\n         for j in range(i+1, len(user_id)):\n              second_user = user_id[j]\n              second_row = encodings.iloc[j,:].values\n\n        # compute distance: if the users are same then Euclidean distance is positive otherwise negative.\n            if first_user == second_user:\n                tmp_dist = np.linalg.norm(first_row - second_row)\n            else:\n                tmp_dist = -np.linalg.norm(first_row - second_row)\n\n            batch_dist += tmp_dist\n\n    return batch_dist\nI have tried to implement into keras loss function. I extracted numpy array from y_true and y_pred tensor objects.\n\ndef custom_loss_keras(y_true, y_pred):\n    # session of my program\n    sess = tf_session.TF_Session().get()\n\n    with sess.as_default():\n        array_pred = y_pred.eval()\n        print(array_pred)\nBut I get the following error.\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'dense_1_input' with dtype float and shape [?,102]\n [[Node: dense_1_input = Placeholder[dtype=DT_FLOAT, shape=[?,102], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nAny kind of help would be really appreciated.",
    "answer": "12\n\nFirst of all, it is not possible to \"extract numpy array from y_true and y_pred\" in Keras loss functions. You have to operate the tensors with Keras backend functions (or TF functions) to calculate the loss.\n\nIn other words, it would be better to think about a \"vectorized\" way to calculate the loss, without using if-else and loops.\n\nYour loss function can be computed in the following steps:\n\nGenerate a matrix of pairwise Euclidean distances, between all pairs of vectors in encodings.\nGenerate a matrix I whose element I_ij is 1 if user_i == user_j, and -1 if user_i != user_j.\nElement-wise multiply the two matrices, and sum up the elements to get the final loss.\nHere's an implementation:\n\ndef custom_loss_keras(user_id, encodings):\n    # calculate pairwise Euclidean distance matrix\n    pairwise_diff = K.expand_dims(encodings, 0) - K.expand_dims(encodings, 1)\n    pairwise_squared_distance = K.sum(K.square(pairwise_diff), axis=-1)\n\n    # add a small number before taking K.sqrt for numerical safety\n    # (K.sqrt(0) sometimes becomes nan)\n    pairwise_distance = K.sqrt(pairwise_squared_distance + K.epsilon())\n\n    # this will be a pairwise matrix of True and False, with shape (batch_size, batch_size)\n    pairwise_equal = K.equal(K.expand_dims(user_id, 0), K.expand_dims(user_id, 1))\n\n    # convert True and False to 1 and -1\n    pos_neg = K.cast(pairwise_equal, K.floatx()) * 2 - 1\n\n    # divide by 2 to match the output of `custom_loss_numpy`, but it's not really necessary\n    return K.sum(pairwise_distance * pos_neg, axis=-1) / 2\nI've assumed that user_id are integers in the code above. The trick here is to use K.expand_dims for implementing pairwise operations. It's probably a bit difficult to understand at a first glance, but it's quite useful.\n\nIt should give about the same loss value as custom_loss_numpy (there will be a little bit difference because of K.epsilon()):\n\nencodings = np.random.rand(32, 10)\nuser_id = np.random.randint(10, size=32)\n\nprint(K.eval(custom_loss_keras(K.variable(user_id), K.variable(encodings))).sum())\n-478.4245\n\nprint(custom_loss_numpy(pd.DataFrame(encodings), pd.Series(user_id)))\n-478.42953553795815\nI've made a mistake in the loss function.\n\nWhen this function is used in training, since Keras automatically changes y_true to be at least 2D, the argument user_id is no longer a 1D tensor. The shape of it will be (batch_size, 1).\n\nIn order to use this function, the extra axis must be removed:\n\ndef custom_loss_keras(user_id, encodings):\n    pairwise_diff = K.expand_dims(encodings, 0) - K.expand_dims(encodings, 1)\n    pairwise_squared_distance = K.sum(K.square(pairwise_diff), axis=-1)\n    pairwise_distance = K.sqrt(pairwise_squared_distance + K.epsilon())\n\n    user_id = K.squeeze(user_id, axis=1)  # remove the axis added by Keras\n    pairwise_equal = K.equal(K.expand_dims(user_id, 0), K.expand_dims(user_id, 1))\n\n    pos_neg = K.cast(pairwise_equal, K.floatx()) * 2 - 1\n    return K.sum(pairwise_distance * pos_neg, axis=-",
    "mlApiName": "keras.backend.sqrt, keras.backend.expand_dims",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "F, IC-1",
      "leafContractCategory": "Comb. of SAM(Level 3) and AMO(Level 2)",
      "rootCause": "Missing Options",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): Hybrid\nThe issue involves multiple Keras backend functions (K.sqrt, K.expand_dims) in a custom loss function, leading to a hybrid contract violation.\n\nLevel 2: SL (Selection Issue)\nThe user incorrectly selects NumPy-style operations instead of using proper Keras/TensorFlow tensor operations for loss computation.\n\nLevel 3 (Hybrid Patterns): F (Eventually Required Condition), IC-1 (Intra-argument Contract)\nThe function fails because it does not properly handle tensor-based operations, leading to incorrect computational graph execution.\n\nLeaf Contract Category: Combination of SAM (Level 3) and AMO (Level 2)\nThe issue involves both improper use of individual API methods (K.sqrt, K.expand_dims) and incorrect method ordering.\n\nRoot Cause: Missing Options\nThe user attempts to extract NumPy arrays from Keras tensors within a loss function, which is not allowed.\n\nEffect: Crash\nThe program fails with an InvalidArgumentError due to improper use of Keras backend functions in the loss calculation.\n\nML Library: Keras\nThe issue occurs in Keras� backend operations when defining a custom loss function.\n\nContract Violation Location: Model Construction\nThe error occurs while constructing the model with an incorrectly implemented loss function.\n\nDetection Technique: Static\nThe issue can be detected through static analysis by verifying that all loss function operations are performed using valid Keras/TensorFlow backend functions instead of NumPy operations.\n\n\n"
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/41378461",
    "title": "",
    "question": "21\n\nI want to get pretrained VGG16 model in Keras, remove its output layer, and then put a new output layer with the number of classes suited for my problem, and then to fit it on new data. For this reason, I am trying to use the model here: https://keras.io/applications/#vgg16, but since it is not Sequential, I cannot just model.pop(). Popping from layers and adding it also does not work, because in the predictions it still expects the old shape. How would I do that? Is there a way to convert this type of model to Sequential?",
    "answer": "56\n\nYou can use pop() on model.layers and then use model.layers[-1].output to create new layers.\n\nExample:\n\nfrom keras.models import Model\nfrom keras.layers import Dense,Flatten\nfrom keras.applications import vgg16\nfrom keras import backend as K\n\nmodel = vgg16.VGG16(weights='imagenet', include_top=True)\n\nmodel.input\n\nmodel.summary(line_length=150)\n\nmodel.layers.pop()\nmodel.layers.pop()\n\nmodel.summary(line_length=150)\n\nnew_layer = Dense(10, activation='softmax', name='my_dense')\n\ninp = model.input\nout = new_layer(model.layers[-1].output)\n\nmodel2 = Model(inp, out)\nmodel2.summary(line_length=150)\nAlternatively, you can use include_top=False option of these models. In this case if you need to use flatten the layer then you need to pass the input_shape also.\n\nmodel3 = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nmodel3.summary(line_length=150)\n\nflatten = Flatten()\nnew_layer2 = Dense(10, activation='softmax', name='my_dense_2')\n\ninp2 = model3.input\nout2 = new_layer2(flatten(model3.output))\n\nmodel4 = Model(inp2, out2)\nmodel4.summary(line_length=150)",
    "mlApiName": "keras.models.pop, keras.applications.vgg16.VGG16, keras.layers, keras.models",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "F, F, IC-1",
      "leafContractCategory": "Comb. of SAM(Level 3) and AMO(Level 2)",
      "rootCause": "Missing Options",
      "effect": "IF",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): Hybrid\nThe issue involves modifying a pre-trained VGG16 model by interacting with multiple Keras API methods (pop(), Model, layers), leading to a hybrid contract violation.\n\nLevel 2: SL (Selection Issue)\nThe user incorrectly selects pop() for removing layers from a functional model (VGG16), which does not work as expected.\n\nLevel 3 (Hybrid Patterns): F (Eventually Required Condition), F (Eventually Required Condition), IC-1 (Intra-argument Contract)\nThe functional model structure requires explicit modifications using include_top=False instead of pop(), and inter-argument dependencies must be preserved.\n\nLeaf Contract Category: Combination of SAM (Level 3) and AMO (Level 2)\nThe violation arises due to single API misuse (pop()) and incorrect method dependencies (include_top should be set properly).\n\nRoot Cause: Missing Options\nThe user failed to use the include_top=False argument, which is required to modify the pre-trained model correctly.\n\nEffect: IF (Incorrect Functionality)\nThe model still expects the original output shape, leading to incorrect behavior when trying to modify layers.\n\nML Library: Keras\nThe issue is specific to modifying pre-trained Keras models.\n\nContract Violation Location: Model Construction\nThe error occurs while modifying the model architecture.\n\nDetection Technique: Static\nThe incorrect use of pop() with functional API models can be identified through static analysis by verifying that layer modifications properly reflect in the model structure."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/41651628",
    "title": "",
    "question": "66\n\nI'm using Keras with Tensorflow as backend , here is my code:\n\nimport numpy as np\nnp.random.seed(1373) \nimport tensorflow as tf\ntf.python.control_flow_ops = tf\n\nimport os\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D\nfrom keras.utils import np_utils\n\nbatch_size = 128\nnb_classes = 10\nnb_epoch = 12\n\nimg_rows, img_cols = 28, 28\n\nnb_filters = 32\n\nnb_pool = 2\n\nnb_conv = 3\n\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n\nprint(X_train.shape[0])\n\nX_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\nX_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\nX_train /= 255\nX_test /= 255\n\nprint('X_train shape:', X_train.shape)\nprint(X_train.shape[0], 'train samples')\nprint(X_test.shape[0], 'test samples')\n\nY_train = np_utils.to_categorical(y_train, nb_classes)\nY_test = np_utils.to_categorical(y_test, nb_classes)\n\nmodel = Sequential()\n\nmodel.add(Convolution2D(nb_filters, nb_conv, nb_conv,\nborder_mode='valid',\ninput_shape=(1, img_rows, img_cols)))\nmodel.add(Activation('relu'))\nmodel.add(Convolution2D(nb_filters, nb_conv, nb_conv))\nmodel.add(Activation('relu'))\n\nmodel.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(128))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(nb_classes)) \nmodel.add(Activation('softmax')) \n\nmodel.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=[\"accuracy\"])\n\nmodel.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\nverbose=1, validation_data=(X_test, Y_test))\n\nscore = model.evaluate(X_test, Y_test, verbose=0)\n\nprint('Test score:', score[0])\nprint('Test accuracy:', score[1])\nand Trackback error:\n\nUsing TensorFlow backend.\n60000\n('X_train shape:', (60000, 1, 28, 28))\n(60000, 'train samples')\n(10000, 'test samples')\nTraceback (most recent call last):\n  File \"mnist.py\", line 154, in \n    input_shape=(1, img_rows, img_cols)))\n  File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 276, in add\n    layer.create_input_layer(batch_input_shape, input_dtype)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py\", line 370, in create_input_layer\n    self(x)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py\", line 514, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py\", line 572, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py\", line 149, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/usr/local/lib/python2.7/dist-packages/keras/layers/convolutional.py\", line 466, in call\n    filter_shape=self.W_shape)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py\", line 1579, in conv2d\n    x = tf.nn.conv2d(x, kernel, strides, padding=padding)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 396, in conv2d\n    data_format=data_format, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2242, in create_op\n    set_shapes_for_outputs(ret)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1617, in set_shapes_for_outputs\n    shapes = shape_func(op)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1568, in call_with_requiring\n    return call_cpp_shape_fn(op, require_shape_fn=True)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py\", line 610, in call_cpp_shape_fn\n    debug_python_shape_fn, require_shape_fn)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py\", line 675, in _call_cpp_shape_fn_impl\n    raise ValueError(err.message)\nValueError: Negative dimension size caused by subtracting 3 from 1 for 'Conv2D' (op: 'Conv2D') with input shapes: [?,1,28,28], [3,3,28,32].\nFirst I saw some answers that problem is with Tensorflow version so I upgrade Tensorflow to 0.12.0, but still exist , is that problem with network or I missing something, what should input_shape looks like?\n\nUpdate Here is ./keras/keras.json:\n\n{\n    \"image_dim_ordering\": \"tf\", \n    \"epsilon\": 1e-07, \n    \"floatx\": \"float32\", \n    \"backend\": \"tensorflow\"\n}",
    "answer": "Your issue comes from the image_ordering_dim in keras.json.\n\nFrom Keras Image Processing doc:\n\ndim_ordering: One of {\"th\", \"tf\"}. \"tf\" mode means that the images should have shape (samples, height, width, channels), \"th\" mode means that the images should have shape (samples, channels, height, width). It defaults to the image_dim_ordering value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"tf\".\n\nKeras maps the convolution operation to the chosen backend (theano or tensorflow). However, both backends have made different choices for the ordering of the dimensions. If your image batch is of N images of HxW size with C channels, theano uses the NCHW ordering while tensorflow uses the NHWC ordering.\n\nKeras allows you to choose which ordering you prefer and will do the conversion to map to the backends behind. But if you choose image_ordering_dim=\"th\" it expects Theano-style ordering (NCHW, the one you have in your code) and if image_ordering_dim=\"tf\" it expects tensorflow-style ordering (NHWC).\n\nSince your image_ordering_dim is set to \"tf\", if you reshape your data to the tensorflow style it should work:\n\nX_train = X_train.reshape(X_train.shape[0], img_cols, img_rows, 1)\nX_test = X_test.reshape(X_test.shape[0], img_cols, img_rows, 1)\nand\n\ninput_shape=(img_cols, img_rows, 1)",
    "mlApiName": "keras.json.set_image_dim_ordering, keras.models.fit",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "F, IC-2",
      "leafContractCategory": "Comb. of SAM(Level 3) and AMO(Level 2)",
      "rootCause": "Missing Options",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Train",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "NA",
      "reasonsForLabeling": "Level 1 (Central Contract Category): Hybrid\nThe issue involves multiple interacting API methods (set_image_dim_ordering, model.fit), leading to a hybrid contract violation.\n\nLevel 2: SL (Selection Issue)\nThe error is due to incorrect selection of image dimension ordering, causing the input shape to be mismatched.\n\nLevel 3 (Hybrid Patterns): F (Eventually Required Condition), IC-2 (Inter-argument Contract)\nThe problem involves both missing a required configuration (image_dim_ordering) and incorrect dependencies between function arguments (input_shape mismatch).\n\nLeaf Contract Category: Combination of SAM (Level 3) and AMO (Level 2)\nThe issue arises from improper configuration (SAM) and incorrect method order dependencies (AMO) when setting up the model.\n\nRoot Cause: Missing Options\nThe user did not correctly configure the input shape based on the backend's expected image ordering.\n\nEffect: Crash\nThe model fails at runtime due to a negative dimension size caused by incorrect reshaping.\n\nML Library: Keras\nThe issue is specific to Keras' image processing and model setup.\n\nContract Violation Location: Train\nThe error occurs during the training phase when attempting to fit data to the model.\n\nDetection Technique: Static\nThe issue can be identified through static analysis by verifying that the input shape correctly follows the backend�s expected format (NHWC for TensorFlow, NCHW for Theano)."
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/44627977",
    "title": "",
    "question": "\"I'm trying to build a model as ilustrated in below diagram. The idea is to take more than one categorical features (one-hot vectors) and embed them separately, then combine those embedded vectors with a 3D tensor for a LSTM.\n\nWith following code in Keras2.0.2, when creating the Model() object with multiple inputs, it raises an AttributeError: 'NoneType' object has no attribute 'inbound_nodes' similar to this question. Can anyone help me to figure out what's the problem?\n\nModel:\n\nCode:\n\nfrom keras.layers import Dense, LSTM, Input\nfrom keras.layers.merge import concatenate\nfrom keras import backend as K\nfrom keras.models import Model\n\ncat_feats_dims = [315, 14] # Dimensions of the cat_feats\nemd_inputs = [Input(shape=(in_size,)) for in_size in cat_feats_dims]\nemd_out = concatenate([Dense(20, use_bias=False)(inp) for inp in emd_inputs])\nemd_out_3d = K.repeat(emd_out, 10)\n\nlstm_input = Input(shape=(10,5))\n\nmerged = concatenate([emd_out_3d,lstm_input])\n\nlstm_output = LSTM(32)(merged)\ndense_output = Dense(1, activation='linear')(lstm_output)\n\nmodel = Model(inputs=emd_inputs+[lstm_input], outputs=[dense_output])\n\n#ERROR MESSAGE\nTraceback (most recent call last):\n  File \"\"C:\\Program Files\\Anaconda2\\envs\\mle-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"\"\"\", line 14, in \n    model = Model(inputs=emd_inputs+[lstm_input], outputs=[dense_output])\n  File \"\"C:\\Program Files\\Anaconda2\\envs\\mle-env\\lib\\site-packages\\keras\\legacy\\interfaces.py\"\", line 88, in wrapper\n    return func(*args, **kwargs)\n  File \"\"C:\\Program Files\\Anaconda2\\envs\\mle-env\\lib\\site-packages\\keras\\engine\\topology.py\"\", line 1648, in __init__\n    build_map_of_graph(x, seen_nodes, depth=0)\n  File \"\"C:\\Program Files\\Anaconda2\\envs\\mle-env\\lib\\site-packages\\keras\\engine\\topology.py\"\", line 1644, in build_map_of_graph\n    layer, node_index, tensor_index)\n  File \"\"C:\\Program Files\\Anaconda2\\envs\\mle-env\\lib\\site-packages\\keras\\engine\\topology.py\"\", line 1644, in build_map_of_graph\n    layer, node_index, tensor_index)\n  File \"\"C:\\Program Files\\Anaconda2\\envs\\mle-env\\lib\\site-packages\\keras\\engine\\topology.py\"\", line 1639, in build_map_of_graph\n    next_node = layer.inbound_nodes[node_index]\nAttributeError: 'NoneType' object has no attribute 'inbound_nodes'\"",
    "answer": "\"keras.backend.repeat is a function, not a layer. Try using keras.layers.core.RepeatVector instead. It has the same functionality as the function.\n\nemd_out_3d = RepeatVector(10)(emd_out)\"",
    "mlApiName": "keras.layers.RepeatVector",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Evaluation",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/51632716",
    "title": "",
    "question": "\"I just recently started playing around with Keras and got into making custom layers. However, I am rather confused by the many different types of layers with slightly different names but with the same functionality. \n\nFor example, there are 3 different forms of the concatenate function from https://keras.io/layers/merge/ and https://www.tensorflow.org/api_docs/python/tf/keras/backend/concatenate\n\nkeras.layers.Concatenate(axis=-1)\nkeras.layers.concatenate(inputs, axis=-1)\ntf.keras.backend.concatenate()\n\nI know the 2nd one is used for functional API but what is the difference between the 3? The documentation seems a bit unclear on this.\n\nAlso, for the 3rd one, I have seen a code that does this below. Why must there be the line ._keras_shape after the concatenation?\n\n# Concatenate the summed atom and bond features\natoms_bonds_features = K.concatenate([atoms, summed_bond_features], axis=-1)\n\n# Compute fingerprint\natoms_bonds_features._keras_shape = (None, max_atoms, num_atom_features + num_bond_features)\n\nLastly, under keras.layers, there always seems to be 2 duplicates. For example, Add() and add(), and so on.\"",
    "answer": "\"First, the backend: tf.keras.backend.concatenate()\nBackend functions are supposed to be used \"\"inside\"\" layers. You'd only use this in Lambda layers, custom layers, custom loss functions, custom metrics, etc.\nIt works directly on \"\"tensors\"\".\nIt's not the choice if you're not going deep on customizing. (And it was a bad choice in your example code -- See details at the end).\nIf you dive deep into keras code, you will notice that the Concatenate layer uses this function internally:\nimport keras.backend as K\nclass Concatenate(_Merge):  \n    #blablabla   \n    def _merge_function(self, inputs):\n        return K.concatenate(inputs, axis=self.axis)\n    #blablabla\n\nThen, the Layer: keras.layers.Concatenate(axis=-1)\nAs any other keras layers, you instantiate and call it on tensors.\nPretty straighforward:\n#in a functional API model:\ninputTensor1 = Input(shape) #or some tensor coming out of any other layer   \ninputTensor2 = Input(shape2) #or some tensor coming out of any other layer\n\n#first parentheses are creating an instance of the layer\n#second parentheses are \"\"calling\"\" the layer on the input tensors\noutputTensor = keras.layers.Concatenate(axis=someAxis)([inputTensor1, inputTensor2])\n\nThis is not suited for sequential models, unless the previous layer outputs a list (this is possible but not common).\n\nFinally, the concatenate function from the layers module: keras.layers.concatenate(inputs, axis=-1)\nThis is not a layer. This is a function that will return the tensor produced by an internal Concatenate layer.\nThe code is simple:\ndef concatenate(inputs, axis=-1, **kwargs):\n   #blablabla\n   return Concatenate(axis=axis, **kwargs)(inputs)\n\nOlder functions\nIn Keras 1, people had functions that were meant to receive \"\"layers\"\" as input and return an output \"\"layer\"\". Their names were related to the merge word.\nBut since Keras 2 doesn't mention or document these, I'd probably avoid using them, and if old code is found, I'd probably update it to a proper Keras 2 code.\n\nWhy the _keras_shape word?\nThis backend function was not supposed to be used in high level codes. The coder should have used a Concatenate layer.\natoms_bonds_features = Concatenate(axis=-1)([atoms, summed_bond_features])   \n#just this line is perfect\n\nKeras layers add the _keras_shape property to all their output tensors, and Keras uses this property for infering the shapes of the entire model.\nIf you use any backend function \"\"outside\"\" a layer or loss/metric, your output tensor will lack this property and an error will appear telling _keras_shape doesn't exist.\nThe coder is creating a bad workaround by adding the property manually, when it should have been added by a proper keras layer. (This may work now, but in case of keras updates this code will break while proper codes will remain ok)\"",
    "mlApiName": "keras.layers.Concatenate,tf.keras.backend.concatenate",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "F",
      "level3": "F",
      "leafContractCategory": "F",
      "rootCause": "Missing Required State-specific Method Order",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/51421885",
    "title": "",
    "question": "\"I am getting the following error while calling the model.predict function when running a text classification model in keras. I searched the everywhere but it isn't working for me.\n\nValueError: Error when checking input: expected dense_1_input to have shape (100,) but got array with shape (1,)\n\nMy data has 5 classes and has a total of 15 examples only. Below is the dataset\n\n             query        tags\n0               hi       intro\n1      how are you       wellb\n2            hello       intro\n3        what's up       wellb\n4       how's life       wellb\n5              bye          gb\n6    see you later          gb\n7         good bye          gb\n8           thanks   gratitude\n9        thank you   gratitude\n10  that's helpful   gratitude\n11      I am great  revertfine\n12            fine  revertfine\n13       I am fine  revertfine\n14            good  revertfine\n\nThis is the code of my model\n\nfrom keras.preprocessing.text import Tokenizer\nfrom sklearn.preprocessing import LabelBinarizer\nfrom keras.models import Sequential\nimport pandas as pd\nfrom keras.layers import Dense, Activation\n\ndata = pd.read_csv('text_class.csv')\ntrain_text = data['query']\ntrain_labels = data['tags']\n\ntokenize = Tokenizer(num_words=100)\ntokenize.fit_on_texts(train_text)\n\nx_data = tokenize.texts_to_matrix(train_text)\n\nencoder = LabelBinarizer()\nencoder.fit(train_labels)\ny_data = encoder.transform(train_labels)\n\nmodel = Sequential()\nmodel.add(Dense(512, input_shape=(100,)))\nmodel.add(Activation('relu'))\nmodel.add(Dense(5))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\nmodel.fit(x_data, y_data, batch_size=8, epochs=10)\n\npredictions = model.predict(x_data[0])\ntag_labels = encoder.classes_\npredicted_tags = tag_labels[np.argmax(predictions)]\nprint (predicted_tags)\n\nI am not able to figure out where the problem lies and how to fix it.\"",
    "answer": "\"x_data is 2-dimensional array with shape (15, 100)\n\n  print(x_data.shape) \n\nbut x_data[0] is 1-dimensional array with shape (100, )\n\n  print(x_data[0].shape) \n\nand it makes problem.\n\nUse slicing x_data[0:1] to get it as 2-dimensional array with shape (1, 100) \n\n print(x_data[0:1].shape) \n\nand it will work\n\n predictions = model.predict(x_data[0:1])\"",
    "mlApiName": "keras.models.predict",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Prediction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/43178668",
    "title": "",
    "question": "\"I want to compare the computation time between different models.\nDuring the fit the computation time per epoch is printed to the console.\n\nEpoch 5/5\n160000/160000 [==============================] - **10s** ......\n\nI'm looking for a way to store these times in a similar way to the model metrics that are saved in each epoch and avaliable through the history object.\"",
    "answer": "\"Try the following callback:\n\nclass TimeHistory(keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.times = []\n\n    def on_epoch_begin(self, batch, logs={}):\n        self.epoch_time_start = time.time()\n\n    def on_epoch_end(self, batch, logs={}):\n        self.times.append(time.time() - self.epoch_time_start)\n\nThen:\n\ntime_callback = TimeHistory()\nmodel.fit(..., callbacks=[..., time_callback],...)\ntimes = time_callback.times\n\nIn this case times should store the epoch computation times.\"",
    "mlApiName": "keras.models.fit",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "Unknown",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Train",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/49195189",
    "title": "",
    "question": "\"I have trained a keras sequential model in a linux 64 machine and saved to a .h5 file.\n\nIt this PC I can load the model and do predictions without problems.\n\nNow I'm implementing the prediction in a Raspberry Pi 3 that have installed keras, tensorflow, h5py and python3.\n\nwhen I load the model\n\nfrom keras.models import load_model\nmodel = load_model('model-0.6358.h5')\n\n, I'm getting: \n\nusr/lib/python3.4/importlib/_bootstrap.py:321: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\nreturn f(*args, **kwds)\n\n/usr/local/lib/python3.4/dist-packages/keras/models.py:291: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\nwarnings.warn('Error in loading the saved optimizer '\n\nBut... it looks like it predicts right.\n\nHow can I avoid that warning message?\"",
    "answer": "\"load_model first builds the saved model architecture with its saved weights and then tries to build the saved optimizer with its saved weights. \n\nHowever, you get an error message because there is a mismatch between the shape of the saved optimizer weights and the shape of the weights that the optimizer is expecting based on the architecture of the loaded model. \n\nI ran into this issue using Keras 2.1.4 when I tried to save and re-load a model that had inner submodels that were set to trainable=False. This information seems not to be preserved when you save the model, so after re-instatiating the inner submodel is set to trainable=True and the optimizer would expect more saved weights than were actually saved. If this might be the problem in your case, I described a workaround in this bug-report:\n\nSet the trainability of all the inner model layers explicitly\nRight before saving, the trainability flags of all the layers have to be set to the state that they had at model compile time\n\nIf you want to get rid of the warning and you do not need the optimizer after saving anyway, you can also save your model without the optimizer: use model.save(filename, include_optimizer=False)\"",
    "mlApiName": "keras.models.add,keras.models.save",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SAI",
      "level3": "F,IC-1",
      "leafContractCategory": "SAM (Level 3) ? AMO(Level 2)",
      "rootCause": "Missing Input value-Method order Dependency",
      "effect": "IF",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Load",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/42475381",
    "title": "",
    "question": "\"In keras.applications, there is a VGG16 model pre-trained on imagenet.\n\nfrom keras.applications import VGG16\nmodel = VGG16(weights='imagenet')\n\nThis model has the following structure.\n\nLayer (type)                     Output Shape          Param #     Connected to                     \n====================================================================================================\ninput_1 (InputLayer)             (None, 3, 224, 224)   0                                            \n____________________________________________________________________________________________________\nblock1_conv1 (Convolution2D)     (None, 64, 224, 224)  1792        input_1[0][0]                    \n____________________________________________________________________________________________________\nblock1_conv2 (Convolution2D)     (None, 64, 224, 224)  36928       block1_conv1[0][0]               \n____________________________________________________________________________________________________\nblock1_pool (MaxPooling2D)       (None, 64, 112, 112)  0           block1_conv2[0][0]               \n____________________________________________________________________________________________________\nblock2_conv1 (Convolution2D)     (None, 128, 112, 112) 73856       block1_pool[0][0]                \n____________________________________________________________________________________________________\nblock2_conv2 (Convolution2D)     (None, 128, 112, 112) 147584      block2_conv1[0][0]               \n____________________________________________________________________________________________________\nblock2_pool (MaxPooling2D)       (None, 128, 56, 56)   0           block2_conv2[0][0]               \n____________________________________________________________________________________________________\nblock3_conv1 (Convolution2D)     (None, 256, 56, 56)   295168      block2_pool[0][0]                \n____________________________________________________________________________________________________\nblock3_conv2 (Convolution2D)     (None, 256, 56, 56)   590080      block3_conv1[0][0]               \n____________________________________________________________________________________________________\nblock3_conv3 (Convolution2D)     (None, 256, 56, 56)   590080      block3_conv2[0][0]               \n____________________________________________________________________________________________________\nblock3_pool (MaxPooling2D)       (None, 256, 28, 28)   0           block3_conv3[0][0]               \n____________________________________________________________________________________________________\nblock4_conv1 (Convolution2D)     (None, 512, 28, 28)   1180160     block3_pool[0][0]                \n____________________________________________________________________________________________________\nblock4_conv2 (Convolution2D)     (None, 512, 28, 28)   2359808     block4_conv1[0][0]               \n____________________________________________________________________________________________________\nblock4_conv3 (Convolution2D)     (None, 512, 28, 28)   2359808     block4_conv2[0][0]               \n____________________________________________________________________________________________________\nblock4_pool (MaxPooling2D)       (None, 512, 14, 14)   0           block4_conv3[0][0]               \n____________________________________________________________________________________________________\nblock5_conv1 (Convolution2D)     (None, 512, 14, 14)   2359808     block4_pool[0][0]                \n____________________________________________________________________________________________________\nblock5_conv2 (Convolution2D)     (None, 512, 14, 14)   2359808     block5_conv1[0][0]               \n____________________________________________________________________________________________________\nblock5_conv3 (Convolution2D)     (None, 512, 14, 14)   2359808     block5_conv2[0][0]               \n____________________________________________________________________________________________________\nblock5_pool (MaxPooling2D)       (None, 512, 7, 7)     0           block5_conv3[0][0]               \n____________________________________________________________________________________________________\nflatten (Flatten)                (None, 25088)         0           block5_pool[0][0]                \n____________________________________________________________________________________________________\nfc1 (Dense)                      (None, 4096)          102764544   flatten[0][0]                    \n____________________________________________________________________________________________________\nfc2 (Dense)                      (None, 4096)          16781312    fc1[0][0]                        \n____________________________________________________________________________________________________\npredictions (Dense)              (None, 1000)          4097000     fc2[0][0]                        \n====================================================================================================\nTotal params: 138,357,544\nTrainable params: 138,357,544\nNon-trainable params: 0\n____________________________________________________________________________________________________\n\nI would like to fine-tune this model with dropout layers between the dense layers (fc1, fc2 and predictions), while keeping all the pre-trained weights of the model intact. I know it's possible to access each layer individually with model.layers, but I haven't found anywhere how to add new layers between the existing layers.\n\nWhat's the best practice of doing this?\"",
    "answer": "\"I found an answer myself by using Keras functional API\n\nfrom keras.applications import VGG16\nfrom keras.layers import Dropout\nfrom keras.models import Model\n\nmodel = VGG16(weights='imagenet')\n\n# Store the fully connected layers\nfc1 = model.layers[-3]\nfc2 = model.layers[-2]\npredictions = model.layers[-1]\n\n# Create the dropout layers\ndropout1 = Dropout(0.85)\ndropout2 = Dropout(0.85)\n\n# Reconnect the layers\nx = dropout1(fc1.output)\nx = fc2(x)\nx = dropout2(x)\npredictors = predictions(x)\n\n# Create a new model\nmodel2 = Model(input=model.input, output=predictors)\n\nmodel2 has the dropout layers as I wanted\n\n____________________________________________________________________________________________________\nLayer (type)                     Output Shape          Param #     Connected to                     \n====================================================================================================\ninput_1 (InputLayer)             (None, 3, 224, 224)   0                                            \n____________________________________________________________________________________________________\nblock1_conv1 (Convolution2D)     (None, 64, 224, 224)  1792        input_1[0][0]                    \n____________________________________________________________________________________________________\nblock1_conv2 (Convolution2D)     (None, 64, 224, 224)  36928       block1_conv1[0][0]               \n____________________________________________________________________________________________________\nblock1_pool (MaxPooling2D)       (None, 64, 112, 112)  0           block1_conv2[0][0]               \n____________________________________________________________________________________________________\nblock2_conv1 (Convolution2D)     (None, 128, 112, 112) 73856       block1_pool[0][0]                \n____________________________________________________________________________________________________\nblock2_conv2 (Convolution2D)     (None, 128, 112, 112) 147584      block2_conv1[0][0]               \n____________________________________________________________________________________________________\nblock2_pool (MaxPooling2D)       (None, 128, 56, 56)   0           block2_conv2[0][0]               \n____________________________________________________________________________________________________\nblock3_conv1 (Convolution2D)     (None, 256, 56, 56)   295168      block2_pool[0][0]                \n____________________________________________________________________________________________________\nblock3_conv2 (Convolution2D)     (None, 256, 56, 56)   590080      block3_conv1[0][0]               \n____________________________________________________________________________________________________\nblock3_conv3 (Convolution2D)     (None, 256, 56, 56)   590080      block3_conv2[0][0]               \n____________________________________________________________________________________________________\nblock3_pool (MaxPooling2D)       (None, 256, 28, 28)   0           block3_conv3[0][0]               \n____________________________________________________________________________________________________\nblock4_conv1 (Convolution2D)     (None, 512, 28, 28)   1180160     block3_pool[0][0]                \n____________________________________________________________________________________________________\nblock4_conv2 (Convolution2D)     (None, 512, 28, 28)   2359808     block4_conv1[0][0]               \n____________________________________________________________________________________________________\nblock4_conv3 (Convolution2D)     (None, 512, 28, 28)   2359808     block4_conv2[0][0]               \n____________________________________________________________________________________________________\nblock4_pool (MaxPooling2D)       (None, 512, 14, 14)   0           block4_conv3[0][0]               \n____________________________________________________________________________________________________\nblock5_conv1 (Convolution2D)     (None, 512, 14, 14)   2359808     block4_pool[0][0]                \n____________________________________________________________________________________________________\nblock5_conv2 (Convolution2D)     (None, 512, 14, 14)   2359808     block5_conv1[0][0]               \n____________________________________________________________________________________________________\nblock5_conv3 (Convolution2D)     (None, 512, 14, 14)   2359808     block5_conv2[0][0]               \n____________________________________________________________________________________________________\nblock5_pool (MaxPooling2D)       (None, 512, 7, 7)     0           block5_conv3[0][0]               \n____________________________________________________________________________________________________\nflatten (Flatten)                (None, 25088)         0           block5_pool[0][0]                \n____________________________________________________________________________________________________\nfc1 (Dense)                      (None, 4096)          102764544   flatten[0][0]                    \n____________________________________________________________________________________________________\ndropout_1 (Dropout)              (None, 4096)          0           fc1[0][0]                        \n____________________________________________________________________________________________________\nfc2 (Dense)                      (None, 4096)          16781312    dropout_1[0][0]                  \n____________________________________________________________________________________________________\ndropout_2 (Dropout)              (None, 4096)          0           fc2[1][0]                        \n____________________________________________________________________________________________________\npredictions (Dense)              (None, 1000)          4097000     dropout_2[0][0]                  \n====================================================================================================\nTotal params: 138,357,544\nTrainable params: 138,357,544\nNon-trainable params: 0\n____________________________________________________________________________________________________\"",
    "mlApiName": "keras.models,keras.applications.vgg16.VGG16,keras.layers.Dropout",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "F",
      "level3": "F",
      "leafContractCategory": "F",
      "rootCause": "Missing Required State-specific Method Order",
      "effect": "Unknown",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/43855162",
    "title": "",
    "question": "\"I try to participate in my first Kaggle competition where RMSLE is given as the required loss function. For I have found nothing how to implement this loss function I tried to settle for RMSE. I know this was part of Keras in the past, is there any way to use it in the latest version, maybe with a customized function via backend?\n\nThis is the NN I designed:\n\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense , Dropout\nfrom keras import regularizers\n\nmodel = Sequential()\nmodel.add(Dense(units = 128, kernel_initializer = \"\"uniform\"\", activation = \"\"relu\"\", input_dim = 28,activity_regularizer = regularizers.l2(0.01)))\nmodel.add(Dropout(rate = 0.2))\nmodel.add(Dense(units = 128, kernel_initializer = \"\"uniform\"\", activation = \"\"relu\"\"))\nmodel.add(Dropout(rate = 0.2))\nmodel.add(Dense(units = 1, kernel_initializer = \"\"uniform\"\", activation = \"\"relu\"\"))\nmodel.compile(optimizer = \"\"rmsprop\"\", loss = \"\"root_mean_squared_error\"\")#, metrics =[\"\"accuracy\"\"])\n\nmodel.fit(train_set, label_log, batch_size = 32, epochs = 50, validation_split = 0.15)\n\nI tried a customized root_mean_squared_error function I found on GitHub but for all I know the syntax is not what is required. I think the y_true and the y_pred would have to be defined before passed to the return but I have no idea how exactly, I just started with programming in python and I am really not that good in math...\n\nfrom keras import backend as K\n\ndef root_mean_squared_error(y_true, y_pred):\n        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n\nI receive the following error with this function: \n\nValueError: ('Unknown loss function', ':root_mean_squared_error')\n\nThanks for your ideas, I appreciate every help!\"",
    "answer": "\"When you use a custom loss, you need to put it without quotes, as you pass the function object, not a string:\n\ndef root_mean_squared_error(y_true, y_pred):\n        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n\nmodel.compile(optimizer = \"\"rmsprop\"\", loss = root_mean_squared_error, \n              metrics =[\"\"accuracy\"\"])\"",
    "mlApiName": "keras.models.compile",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/53153790",
    "title": "",
    "question": "\"I am fine-tuning a MobileNet with 14 new classes. When I add new layers by:\n\nx=mobile.layers[-6].output\nx=Flatten(x)\npredictions = Dense(14, activation='softmax')(x)\nmodel = Model(inputs=mobile.input, outputs=predictions)\n\nI get the error:\n\n'Tensor' object has no attribute 'lower'\n\nAlso using:\n\nmodel.compile(Adam(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.fit_generator(train_batches, steps_per_epoch=18,\n                validation_data=valid_batches, validation_steps=3, epochs=60, verbose=2)\n\nI get the error:\n\nError when checking target: expected dense_1 to have 4 dimensions, but got array with shape (10, 14)\n\nWhat does lower mean? I saw other fine-tuning scripts and there were no other arguments other than the name of the model which is x in this case.\"",
    "answer": "\"The tensor must be passed to the layer when you are calling it, and not as an argument. Therefore it must be like this:\n\nx = Flatten()(x)  # first the layer is constructed and then it is called on x\n\nTo make it more clear, it is equivalent to this:\n\nflatten_layer = Flatten()  # instantiate the layer\nx = flatten_layer(x)       # call it on the given tensor\"",
    "mlApiName": "keras.layers.Flatten",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "DT",
      "level3": "MT",
      "leafContractCategory": "MT",
      "rootCause": "Unacceptable Input Type",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/42264649",
    "title": "",
    "question": "\"I'm following this tutorial (section 6: Tying it All Together), with my own dataset. I can get the example in the tutorial working, no problem, with the sample dataset provided.\nI'm getting a binary cross-entropy error that is negative, and no improvements as epochs progress. I'm pretty sure binary cross-entropy should always be positive, and I should see some improvement in the loss. I've truncated the sample output (and code call) below to 5 epochs. Others seem to run into similar problems sometimes when training CNNs, but I didn't see a clear solution in my case. Does anyone know why this is happening?\nSample output:\nCreating TensorFlow device (/gpu:2) -> (device: 2, name: GeForce GTX TITAN Black, pci bus id: 0000:84:00.0)\n10240/10240 [==============================] - 2s - loss: -5.5378 - acc: 0.5000 - val_loss: -7.9712 - val_acc: 0.5000\nEpoch 2/5\n10240/10240 [==============================] - 0s - loss: -7.9712 - acc: 0.5000 - val_loss: -7.9712 - val_acc: 0.5000\nEpoch 3/5\n10240/10240 [==============================] - 0s - loss: -7.9712 - acc: 0.5000 - val_loss: -7.9712 - val_acc: 0.5000\nEpoch 4/5\n10240/10240 [==============================] - 0s - loss: -7.9712 - acc: 0.5000 - val_loss: -7.9712 - val_acc: 0.5000\nEpoch 5/5\n10240/10240 [==============================] - 0s - loss: -7.9712 - acc: 0.5000 - val_loss: -7.9712 - val_acc: 0.5000\n\nMy code:\nimport numpy as np\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndataset = np.loadtxt('train_rows.csv', delimiter=\"\",\"\")\ntestset = np.loadtxt('test_rows.csv', delimiter=\"\",\"\")\n\n# split into input (X) and output (Y) variables\nX = dataset[:, :62]\nY = dataset[:, 62]\n\nX_test = testset[:, :62]\nY_test = testset[:, 62]\n\n### create model\nmodel = Sequential()\nmodel.add(Dense(100, input_dim=(62,), activation='relu'))\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n## Fit the model\nmodel.fit(X, Y, validation_data=(X_test, Y_test), epochs=5, batch_size=128)\"",
    "answer": "I should have printed out my response variable. The categories were labelled as 1 and 2 instead of 0 and 1, which confused the classifier.",
    "mlApiName": "keras.models.fit",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "IF",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Train",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/47183159",
    "title": "",
    "question": "\"I am having trouble with the Keras backend functions for setting values.  I am trying to convert a model from PyTorch to Keras and am trying to set the weights of the Keras model, but the weights do not appear to be getting set.  Note: I am not actually setting with np.ones just using that for an example.\n\nI have tried...\n\nLoading an existing model\n\nimport keras\nfrom keras.models import load_model, Model\nmodel = load_model(model_dir+file_name)\nkeras_layer = [layer for layer in model.layers if layer.name=='conv2d_1'][0]\n\nCreating a simple model\n\nimg_input = keras.layers.Input(shape=(3,3,3))\nx = keras.layers.Conv2D(1, kernel_size=1, strides=1, padding=\"\"valid\"\", \nuse_bias=False, name='conv1')(img_input)\nmodel = Model(img_input, x)\nkeras_layer = [layer for layer in model.layers if layer.name=='conv1'][0]\n\nThen using set_weights or set_value\n\nkeras_layer.set_weights([np.ones((1, 1, 3, 1))])\n\nor...\n\nK.batch_set_value([(weight,np.ones((1, 1, 3, 1))) for weight in keras_layer.weights])\n\nafterwards I call either one of the following:\n\nK.batch_get_value([weight for weight in keras_layer.weights])\nkeras_layer.get_weights()\n\nAnd None of the weights appear to have been set.  The same values as before are returned.\n\n[array([[[[  1.61547325e-06],\n      [  2.97779252e-06],\n      [  1.50160542e-06]]]], dtype=float32)]\n\nHow do I set the weights of a layer in Keras with a numpy array of values?\"",
    "answer": "\"What is keras_layer in your code?\n\nYou can set weights these ways:\n\nmodel.layers[i].set_weights(listOfNumpyArrays)    \nmodel.get_layer(layerName).set_weights(...)\nmodel.set_weights(listOfNumpyArrays)\n\nWhere model is an instance of an existing model. \nYou can see the expected length of the list and its array shapes using the method get_weights() from the same instances above.\"",
    "mlApiName": "keras.models,keras.models.layers,keras.models.load_model",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "F",
      "leafContractCategory": "AMO(Level-2)",
      "rootCause": "Missing Options",
      "effect": "IF",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Load",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/43196636",
    "title": "",
    "question": "\"I have an example of a neural network with two layers. The first layer takes two arguments and has one output. The second should take one argument as result of the first layer and one additional argument. It should looks like this:\n\nx1  x2  x3\n \\  /   /\n  y1   /\n   \\  /\n    y2\n\nSo, I'd created a model with two layers and tried to merge them but it returns an error: The first layer in a Sequential model must get an \"\"input_shape\"\" or \"\"batch_input_shape\"\" argument. on the line result.add(merged).\n\nModel:\n\nfirst = Sequential()\nfirst.add(Dense(1, input_shape=(2,), activation='sigmoid'))\n\nsecond = Sequential()\nsecond.add(Dense(1, input_shape=(1,), activation='sigmoid'))\n\nresult = Sequential()\nmerged = Concatenate([first, second])\nada_grad = Adagrad(lr=0.1, epsilon=1e-08, decay=0.0)\nresult.add(merged)\nresult.compile(optimizer=ada_grad, loss=_loss_tensor, metrics=['accuracy'])\"",
    "answer": "\"You're getting the error because result defined as Sequential() is just a container for the model and you have not defined an input for it.\n\nGiven what you're trying to build set result to take the third input x3.\nfirst = Sequential()\nfirst.add(Dense(1, input_shape=(2,), activation='sigmoid'))\n\nsecond = Sequential()\nsecond.add(Dense(1, input_shape=(1,), activation='sigmoid'))\n\nthird = Sequential()\n# of course you must provide the input to result which will be your x3\nthird.add(Dense(1, input_shape=(1,), activation='sigmoid'))\n\n# lets say you add a few more layers to first and second.\n# concatenate them\nmerged = Concatenate([first, second])\n\n# then concatenate the two outputs\n\nresult = Concatenate([merged,  third])\n\nada_grad = Adagrad(lr=0.1, epsilon=1e-08, decay=0.0)\n\nresult.compile(optimizer=ada_grad, loss='binary_crossentropy',\n               metrics=['accuracy'])\n\nHowever, my preferred way of building a model that has this type of input structure would be to use the functional api.\nHere is an implementation of your requirements to get you started:\nfrom keras.models import Model\nfrom keras.layers import Concatenate, Dense, LSTM, Input, concatenate\nfrom keras.optimizers import Adagrad\n\nfirst_input = Input(shape=(2, ))\nfirst_dense = Dense(1, )(first_input)\n\nsecond_input = Input(shape=(2, ))\nsecond_dense = Dense(1, )(second_input)\n\nmerge_one = concatenate([first_dense, second_dense])\n\nthird_input = Input(shape=(1, ))\nmerge_two = concatenate([merge_one, third_input])\n\nmodel = Model(inputs=[first_input, second_input, third_input], outputs=merge_two)\nada_grad = Adagrad(lr=0.1, epsilon=1e-08, decay=0.0)\nmodel.compile(optimizer=ada_grad, loss='binary_crossentropy',\n               metrics=['accuracy'])\n\nTo answer the question in the comments:\n\nHow are result and merged connected? Assuming you mean how are they concatenated.\n\nConcatenation works like this:\n  a        b         c\na b c   g h i    a b c g h i\nd e f   j k l    d e f j k l\n\ni.e rows are just joined.\n\nNow, x1 is input to first, x2 is input into second and x3 input into third.\"",
    "mlApiName": "keras.layers.Concatenate,keras.models.Model",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "F",
      "level3": "F",
      "leafContractCategory": "F",
      "rootCause": "Missing Required State-specific Method Order",
      "effect": "Unknown",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/42606207",
    "title": "",
    "question": "\"I'm doing a binary classification using Keras (with Tensorflow backend) and I've got about 76% precision and 70% recall. Now I want to try to play with decision threshold. As far as I know Keras uses decision threshold 0.5. Is there a way in Keras to use custom threshold for decision precision and recall?\n\nThank you for your time!\"",
    "answer": "\"create custom metrics like this :\n\nEdited thanks to @Marcin : Create functions that returns the desired metrics with threshold_value as argument\n\ndef precision_threshold(threshold=0.5):\n    def precision(y_true, y_pred):\n        \"\"\"\"\"\"Precision metric.\n        Computes the precision over the whole batch using threshold_value.\n        \"\"\"\"\"\"\n        threshold_value = threshold\n        # Adaptation of the \"\"round()\"\" used before to get the predictions. Clipping to make sure that the predicted raw values are between 0 and 1.\n        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n        # Compute the number of true positives. Rounding in prevention to make sure we have an integer.\n        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n        # count the predicted positives\n        predicted_positives = K.sum(y_pred)\n        # Get the precision ratio\n        precision_ratio = true_positives / (predicted_positives + K.epsilon())\n        return precision_ratio\n    return precision\n\ndef recall_threshold(threshold = 0.5):\n    def recall(y_true, y_pred):\n        \"\"\"\"\"\"Recall metric.\n        Computes the recall over the whole batch using threshold_value.\n        \"\"\"\"\"\"\n        threshold_value = threshold\n        # Adaptation of the \"\"round()\"\" used before to get the predictions. Clipping to make sure that the predicted raw values are between 0 and 1.\n        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n        # Compute the number of true positives. Rounding in prevention to make sure we have an integer.\n        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n        # Compute the number of positive targets.\n        possible_positives = K.sum(K.clip(y_true, 0, 1))\n        recall_ratio = true_positives / (possible_positives + K.epsilon())\n        return recall_ratio\n    return recall\n\nnow you can use them in\n\nmodel.compile(..., metrics = [precision_threshold(0.1), precision_threshold(0.2),precision_threshold(0.8), recall_threshold(0.2,...)])\n\nI hope this helps :)\"",
    "mlApiName": "keras.models.compile",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "Unknown",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/45979848",
    "title": "",
    "question": "\"I a trying to merge 2 sequential models in keras. Here is the code:\n\nmodel1 = Sequential(layers=[\n    # input layers and convolutional layers\n    Conv1D(128, kernel_size=12, strides=4, padding='valid', activation='relu', input_shape=input_shape),\n    MaxPooling1D(pool_size=6),\n    Conv1D(256, kernel_size=12, strides=4, padding='valid', activation='relu'),\n    MaxPooling1D(pool_size=6),\n    Dropout(.5),\n\n])\n\nmodel2 = Sequential(layers=[\n    # input layers and convolutional layers\n    Conv1D(128, kernel_size=20, strides=5, padding='valid', activation='relu', input_shape=input_shape),\n    MaxPooling1D(pool_size=5),\n    Conv1D(256, kernel_size=20, strides=5, padding='valid', activation='relu'),\n    MaxPooling1D(pool_size=5),\n    Dropout(.5),\n\n])\n\nmodel = merge([model1, model2], mode = 'sum')\nFlatten(),\nDense(256, activation='relu'),\nDropout(.5),\nDense(128, activation='relu'),\nDropout(.35),\n# output layer\nDense(5, activation='softmax')\nreturn model\n\nHere is the error log:\n\n  File\n  \"\"/nics/d/home/dsawant/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\"\",\n  line 392, in is_keras_tensor\n      raise ValueError('Unexpectedly found an instance of type ' + str(type(x)) + '. ' ValueError: Unexpectedly found an instance of\n  type . Expected a symbolic tensor\n  instance.\n\nSome more log:\n\n  ValueError: Layer merge_1 was called with an input that isn't a\n  symbolic tensor. Received type: class 'keras.models.Sequential'.\n  Full input: [keras.models.Sequential object at 0x2b32d518a780,\n  keras.models.Sequential object at 0x2b32d521ee80]. All inputs to the\n  layer should be tensors.\n\nHow can I merge these 2 Sequential models that use different window sizes and apply functions like 'max', 'sum' etc to them?\"",
    "answer": "\"Using the functional API brings you all possibilities. \n\nWhen using the functional API, you need to keep track of inputs and outputs, instead of just defining layers. \n\nYou define a layer, then you call the layer with an input tensor to get the output tensor. Models and layers can be called exactly the same way.\n\nFor the merge layer, I prefer using other merge layers that are more intuitive, such as Add(), Multiply() and Concatenate() for instance. \n\nfrom keras.layers import *\n\nmergedOut = Add()([model1.output,model2.output])\n    #Add() -> creates a merge layer that sums the inputs\n    #The second parentheses \"\"calls\"\" the layer with the output tensors of the two models\n    #it will demand that both model1 and model2 have the same output shape\n\nThis same idea apply to all the following layers. We keep updating the output tensor giving it to each layer and getting a new output (if we were interested in creating branches, we would use a different var for each output of interest to keep track of them):\n\nmergedOut = Flatten()(mergedOut)    \nmergedOut = Dense(256, activation='relu')(mergedOut)\nmergedOut = Dropout(.5)(mergedOut)\nmergedOut = Dense(128, activation='relu')(mergedOut)\nmergedOut = Dropout(.35)(mergedOut)\n\n# output layer\nmergedOut = Dense(5, activation='softmax')(mergedOut)\n\nNow that we created the \"\"path\"\", it's time to create the Model. Creating the model is just like telling at which input tensors it starts and where it ends:\n\nfrom keras.models import Model\n\nnewModel = Model([model1.input,model2.input], mergedOut)\n    #use lists if you want more than one input or output    \n\nNotice that since this model has two inputs, you have to train it with two different X_training vars in a list:\n\nnewModel.fit([X_train_1, X_train_2], Y_train, ....)    \n\nNow, suppose you wanted only one input, and both model1 and model2 would take the same input. \n\nThe functional API allows that quite easily by creating an input tensor and feeding it to the models (we call the models as if they were layers):   \n\ncommonInput = Input(input_shape)\n\nout1 = model1(commonInput)    \nout2 = model2(commonInput)    \n\nmergedOut = Add()([out1,out2])\n\nIn this case, the Model would consider this input:\n\noneInputModel = Model(commonInput,mergedOut)\"",
    "mlApiName": "keras.models.Model,keras.models.add",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "F",
      "leafContractCategory": "AMO(Level-2)",
      "rootCause": "Missing Options",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/42492824",
    "title": "",
    "question": "\"I want the classifier to run faster and stop early if the patience reaches the number I set. In the following code it does 10 iterations of fitting the model.\n\nimport numpy\nimport pandas\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.constraints import maxnorm\nfrom keras.optimizers import SGD\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n# fix random seed for reproducibility\nseed = 7\nnumpy.random.seed(seed)\n# load dataset\ndataframe = pandas.read_csv(\"\"sonar.csv\"\", header=None)\ndataset = dataframe.values\n# split into input (X) and output (Y) variables\nX = dataset[:,0:60].astype(float)\nY = dataset[:,60]\n# encode class values as integers\nencoder = LabelEncoder()\nencoder.fit(Y)\nencoded_Y = encoder.transform(Y)\n\ncalls=[EarlyStopping(monitor='acc', patience=10), ModelCheckpoint('C:/Users/Nick/Data Science/model', monitor='acc', save_best_only=True, mode='auto', period=1)]\n\ndef create_baseline(): \n    # create model\n    model = Sequential()\n    model.add(Dropout(0.2, input_shape=(33,)))\n    model.add(Dense(33, init='normal', activation='relu', W_constraint=maxnorm(3)))\n    model.add(Dense(16, init='normal', activation='relu', W_constraint=maxnorm(3)))\n    model.add(Dense(122, init='normal', activation='softmax'))\n    # Compile model\n    sgd = SGD(lr=0.1, momentum=0.8, decay=0.0, nesterov=False)\n    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n    return model\n\nnumpy.random.seed(seed)\nestimators = []\nestimators.append(('standardize', StandardScaler()))\nestimators.append(('mlp', KerasClassifier(build_fn=create_baseline, nb_epoch=300, batch_size=16, verbose=0, callbacks=calls)))\npipeline = Pipeline(estimators)\nkfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\nresults = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\nprint(\"\"Baseline: %.2f%% (%.2f%%)\"\" % (results.mean()*100, results.std()*100))\n\nHere is the resulting error-\n\nRuntimeError: Cannot clone object , as the constructor does not seem to set parameter callbacks\n\nI changed the cross_val_score in the following-\n\nnumpy.random.seed(seed)\nestimators = []\nestimators.append(('standardize', StandardScaler()))\nestimators.append(('mlp', KerasClassifier(build_fn=create_baseline, nb_epoch=300, batch_size=16, verbose=0, callbacks=calls)))\npipeline = Pipeline(estimators)\nkfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\nresults = cross_val_score(pipeline, X, encoded_Y, cv=kfold, fit_params={'callbacks':calls})\nprint(\"\"Baseline: %.2f%% (%.2f%%)\"\" % (results.mean()*100, results.std()*100))\n\nand now I get this error-\n\nValueError: need more than 1 value to unpack\n\nThis code came from here. The code is by far the most accurate I've used so far. The problem is that there is no defined model.fit() anywhere in the code. It also takes forever to fit. The fit() operation occurs at the results = cross_val_score(...) and there's no parameters to throw a callback in there.\n\nHow do I go about doing this?\nAlso, how do I run the model trained on a test set?\n\nI need to be able to save the trained model for later use...\"",
    "answer": "\"Reading from here, which is the source code of KerasClassifier, you can pass it the arguments of fit and they should be used.\nI don't have your dataset so I cannot test it, but you can tell me if this works and if not I will try and adapt the solution. Change this line :\n\nestimators.append(('mlp', KerasClassifier(build_fn=create_baseline, nb_epoch=300, batch_size=16, verbose=0, callbacks=[...your_callbacks...])))\n\nA small explaination of what's happening : KerasClassifier is taking all the possibles arguments for fit, predict, score and uses them accordingly when each method is called. They made a function that filters the arguments that should go to each of the above functions that can be called in the pipeline. \nI guess there are several fit and predict calls inside the StratifiedKFold step to train on different splits everytime. \n\nThe reason why it takes forever to fit and it fits 10 times is because one fit is doing 300 epochs, as you asked. So the KFold is repeating this step over the different folds :\n\ncalls fit with all the parameters given to KerasClassifier (300 epochs and batch size = 16). It's training on 9/10 of your data and using 1/10 as validation. \n\nEDIT :\n\nOk, so I took the time to download the dataset and try your code... First of all you need to correct a \"\"few\"\" things in your network : \n\nyour input have a 60 features. You clearly show it in your data prep :\n\nX = dataset[:,:60].astype(float)\n\nso why would you have this :\n\nmodel.add(Dropout(0.2, input_shape=(33,)))\n\nplease change to : \n\nmodel.add(Dropout(0.2, input_shape=(60,)))\n\nAbout your targets/labels. You changed the objective from the original code (binary_crossentropy) to categorical_crossentropy. But you didn't change your Y array. So either do this in your data preparation :\n\nfrom keras.utils.np_utils import to_categorical\nencoded_Y = to_categorical(encoder.transform(Y))\n\nor change your objective back to binary_crossentropy.\nNow the network's output size : 122 on the last dense layer? your dataset obviously has 2 categories so why are you trying to output 122 classes? it won't match the target. Please change back your last layer to :\n\nmodel.add(Dense(2, init='normal', activation='softmax'))\n\nif you choose to use categorical_crossentropy, or \n\nmodel.add(Dense(1, init='normal', activation='sigmoid'))\n\nif you go back to binary_crossentropy.\n\nSo now that your network compiles, I could start to troubleshout.\n\nhere is your solution\n\nSo now I could get the real error message. It turns out that when you feed fit_params=whatever in the cross_val_score() function, you are feeding those parameters to a pipeline. In order to know to which part of the pipeline you want to send those parameters you have to specify it like this :\n\nfit_params={'mlp__callbacks':calls}\n\nYour error was saying that the process couldn't unpack 'callbacks'.split('__', 1) into 2 values. It was actually looking for the name of the pipeline's step to apply this to.\n\nIt should be working now :)\n\nresults = cross_val_score(pipeline, X, encoded_Y, cv=kfold, fit_params={'mlp__callbacks':calls})\n\nBUT, you should be aware of what's happening here... the cross validation actually calls the create_baseline() function to recreate the model from scratch 10 times an trains it 10 times on different parts of the dataset. So it's not doing epochs as you were saying, it's doing 300 epochs 10 times. \nWhat is also happening as a consequence of using this tool : since the models are always differents, it means the fit() method is applied 10 times on different models, therefore, the callbacks are also applied 10 different times and the files saved by ModelCheckpoint() get overriden and you find yourself only with the best model of the last run.\n\nThis is intrinsec to the tools you use, I don't see any way around this. This comes as consequence to using different general tools that weren't especially thought to be used together with all the possible configurations.\"",
    "mlApiName": "keras.models.compile,keras.utils.np_utils.to_categorical,sklearn.model_selection.cross_val_score",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SAI",
      "level3": "F,IC-1",
      "leafContractCategory": "SAM (Level 3) ? AMO(Level 2)",
      "rootCause": "Missing Input value-Method order Dependency",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Evaluation",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/47523841",
    "title": "",
    "question": "\"I am trying to use keras to store a model and then load it to retrain. My question is how do I set the learning rate to a new value when loading a model?\n\nHere are my code:  \n\n# Save a model\nmodel = Sequential()\nmodel.add(Dense(64, kernel_initializer='uniform', input_shape=(10,)))\nmodel.add(Activation('tanh'))\nmodel.add(Activation('softmax'))\n# learning rate is 0.001\nsgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='mean_squared_error', optimizer=sgd)\nmodel.fit_generator(...)\nmodel.save()\n\nThen load the model,  \n\nmodel = load_model(model)\n# Change the model's parameters here. Set the learning rate to 0.01.\nmodel.fit_generator(...)\n\nThank you.\"",
    "answer": "\"I think I find the answer:\n\nfrom keras import backend as K\n# To get learning rate\nprint(K.get_value(model.optimizer.lr))\n# To set learning rate\nK.set_value(model.optimizer.lr, 0.001)\nkeras.__version__ # 2.0.2\"",
    "mlApiName": "keras.backend.set_value,keras.models.load_model",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "F",
      "level3": "F",
      "leafContractCategory": "F",
      "rootCause": "Missing Required State-specific Method Order",
      "effect": "Unknown",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Load",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/42284873",
    "title": "",
    "question": "\"I'm using the ImageDataGenerator inside Keras to read a directory of images. I'd like to save the result inside a numpy array, so I can do further manipulations and save it to disk in one file.\n\nflow_from_directory() returns an iterator, which is why I tried the following\n\nitr = gen.flow_from_directory('data/train/', batch_size=1, target_size=(32,32))\nimgs = np.concatenate([itr.next() for i in range(itr.nb_sample)])\n\nbut that produced\n\nValueError: could not broadcast input array from shape (32,32,3) into shape (1)\n\nI think I'm misusing the concatenate() function, but I can't figure out where I fail.\"",
    "answer": "\"I had the same problem and solved it the following way:\nitr.next returns the next batch of images as two numpy.ndarray objects: batch_x, batch_y. (Source: keras/preprocessing/image.py)\nSo what you can do is set the batch_size for flow_from_directory to the size of your whole train dataset.\nExample, my whole training set consists of 1481 images:\ntrain_datagen = ImageDataGenerator(rescale=1. / 255)\nitr = train_datagen.flow_from_directory(\ntrain_data_dir,\ntarget_size=(img_width, img_height),\nbatch_size=1481,\nclass_mode='categorical')\n\nX, y = itr.next()\"",
    "mlApiName": "keras.preprocessing.image.ImageDataGenerator.flow_from_directory",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Load",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/47843265",
    "title": "",
    "question": "\"I have saved a keras model as a h5py file and now want to load it from disk.\nWhen training the model I use:\nfrom keras.models import Sequential\n\nmodel = Sequential()\nH = model.fit(....)\n\nWhen the model is trained, I want to load it from disk with\nmodel = load_model()\n\nHow can I get H from the model variable? It unfortunately does not have a history parameter that I can just call. Is it because the save_model function doesn't save history?\"",
    "answer": "\"Unfortunately it seems that Keras hasn't implemented the possibility of loading the history directly from a loaded model. Instead you have to set it up in advance. This is how I solved it using CSVLogger (it's actually very convenient storing the entire training history in a separate file. This way you can always come back later and plot whatever history you want instead of being dependent on a variable you can easily lose stored in the RAM):\nFirst we have to set up the logger before initiating the training.\nfrom keras.callbacks import CSVLogger\n\ncsv_logger = CSVLogger('training.log', separator=',', append=False)\nmodel.fit(X_train, Y_train, callbacks=[csv_logger])\n\nThe entire log history will now be stored in the file 'training.log' (the same information you would get, by in your case, calling H.history). When the training is finished, the next step would simply be to load the data stored in this file. You can do that with pandas read_csv:\nimport pandas as pd\nlog_data = pd.read_csv('training.log', sep=',', engine='python')\n\nFrom here on you can treat the data stored in log_data just as you would by loading it from K.history.\nMore information in Keras callbacks docs.\"",
    "mlApiName": "keras.callbacks.CSVLogger,keras.models.fit",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SAI",
      "level3": "F,IC-1",
      "leafContractCategory": "SAM (Level 3) ? AMO(Level 2)",
      "rootCause": "Missing Input value-Method order Dependency",
      "effect": "Unknown",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Load",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/45755022",
    "title": "",
    "question": "\"I have a saved a model using model.save(). I'm trying to reload the model and add a few layers and tune some hyper-parameters, however, it throws the AttributeError.\n\nModel is loaded using load_model().\n\nI guess I'm missing understanding how to add layers to saved layers. If someone can guide me here, it will be great. I'm a novice to deep learning and using keras, so probably my request would be silly.\n\nSnippet:\n\nprev_model = load_model('final_model.h5') # loading the previously saved model.\n\nprev_model.add(Dense(256,activation='relu'))\nprev_model.add(Dropout(0.5))\nprev_model.add(Dense(1,activation='sigmoid'))\n\nmodel = Model(inputs=prev_model.input, outputs=prev_model(prev_model.output))\n\nAnd the error it throws:\n\nTraceback (most recent call last):\n  File \"\"image_classifier_3.py\"\", line 39, in \n    prev_model.add(Dense(256,activation='relu'))\nAttributeError: 'Model' object has no attribute 'add'\n\nI know adding layers works on new Sequential() model, but how do we add to existing saved models?\"",
    "answer": "\"The add method is present only in sequential models (Sequential class), which is a simpler interface to the more powerful but complicated functional model (Model class). load_model will always return a Model instance, which is the most generic class.\n\nYou can look at the example to see how you can compose different models, but the idea is that, in the end, a Model behaves pretty much like any other layer. So you should be able to do:\n\nprev_model = load_model('final_model.h5') # loading the previously saved model.\n\nnew_model = Sequential()\nnew_model.add(prev_model)\nnew_model.add(Dense(256,activation='relu'))\nnew_model.add(Dropout(0.5))\nnew_model.add(Dense(1,activation='sigmoid'))\n\nnew_model.compile(...)\"",
    "mlApiName": "keras.models.add,keras.models.load_model",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "G",
      "level3": "G",
      "leafContractCategory": "G",
      "rootCause": "Missing Required Method Order",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Load",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/49785536",
    "title": "",
    "question": "\"I cannot seem to get the value of learning rate. What I get is below. \n\nI've tried the model for 200 epochs and want to see/change the learning rate. Is this not the correct way?\n\n>>> print(ig_cnn_model.optimizer.lr)\n\"",
    "answer": "\"Use eval() from keras.backend:\n\nimport keras.backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\nmodel = Sequential()\nmodel.add(Dense(1, input_shape=(1,)))\nmodel.add(Dense(1))\nmodel.compile(loss='mse', optimizer='adam')\n\nprint(K.eval(model.optimizer.lr))\n\nOutput:\n\n0.001\"",
    "mlApiName": "keras.backend",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "0",
      "mlLibrary": "Keras",
      "contractViolationLocation": "0",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/47266383",
    "title": "",
    "question": "\"Im trying to save and load weights from the model i have trained.\n\nthe code im using to save the model is.\n\nTensorBoard(log_dir='/output')\nmodel.fit_generator(image_a_b_gen(batch_size), steps_per_epoch=1, epochs=1)\nmodel.save_weights('model.hdf5')\nmodel.save_weights('myModel.h5')\n\nLet me know if this an incorrect way to do it,or if there is a better way to do it.\n\nbut when i try to load them,using this,\n\nfrom keras.models import load_model\nmodel = load_model('myModel.h5')\n\nbut i get this error:\n\nValueError                                Traceback (most recent call \nlast)\n in ()\n      1 from keras.models import load_model\n----> 2 model = load_model('myModel.h5')\n\n/home/decentmakeover2/anaconda3/lib/python3.5/site-\npackages/keras/models.py in load_model(filepath, custom_objects, compile)\n    235         model_config = f.attrs.get('model_config')\n    236         if model_config is None:\n--> 237             raise ValueError('No model found in config file.')\n    238         model_config = json.loads(model_config.decode('utf-8'))\n    239         model = model_from_config(model_config, \ncustom_objects=custom_objects)\n\nValueError: No model found in config file.\n\nAny suggestions on what i may be doing wrong?\nThank you in advance.\"",
    "answer": "\"Here is a YouTube video that explains exactly what you're wanting to do: Save and load a Keras model\n\nThere are three different saving methods that Keras makes available. These are described in the video link above (with examples), as well as below. \n\nFirst, the reason you're receiving the error is because you're calling load_model incorrectly.\n\nTo save and load the weights of the model, you would first use \n\nmodel.save_weights('my_model_weights.h5')\n\nto save the weights, as you've displayed. To load the weights, you would first need to build your model, and then call load_weights on the model, as in\n\nmodel.load_weights('my_model_weights.h5')\n\nAnother saving technique is model.save(filepath). This save function saves:\n\nThe architecture of the model, allowing to re-create the model.\nThe weights of the model.\nThe training configuration (loss, optimizer).\nThe state of the optimizer, allowing to resume training exactly where you left off.\n\nTo load this saved model, you would use the following:\n\nfrom keras.models import load_model\nnew_model = load_model(filepath)'\n\nLastly, model.to_json(), saves only the architecture of the model. To load the architecture, you would use \n\nfrom keras.models import model_from_json\nmodel = model_from_json(json_string)\"",
    "mlApiName": "keras.models.load_model,keras.models.save_weights",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "G",
      "level3": "G",
      "leafContractCategory": "G",
      "rootCause": "Missing Required Method Order",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Load",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/51806852",
    "title": "",
    "question": "\"Inspired by tf.keras.Model subclassing I created custom model.\n\nI can train it and get successfull results, but I can't save it.\n\nI use python3.6 with tensorflow v1.10 (or v1.9)  \n\nMinimal complete code example here:\n\nimport tensorflow as tf\nfrom tensorflow.keras.datasets import mnist\n\nclass Classifier(tf.keras.Model):\n    def __init__(self):\n        super().__init__(name=\"\"custom_model\"\")\n\n        self.batch_norm1 = tf.layers.BatchNormalization()\n        self.conv1 = tf.layers.Conv2D(32, (7, 7))\n        self.pool1 = tf.layers.MaxPooling2D((2, 2), (2, 2))\n\n        self.batch_norm2 = tf.layers.BatchNormalization()\n        self.conv2 = tf.layers.Conv2D(64, (5, 5))\n        self.pool2 = tf.layers.MaxPooling2D((2, 2), (2, 2))\n\n    def call(self, inputs, training=None, mask=None):\n        x = self.batch_norm1(inputs)\n        x = self.conv1(x)\n        x = tf.nn.relu(x)\n        x = self.pool1(x)\n\n        x = self.batch_norm2(x)\n        x = self.conv2(x)\n        x = tf.nn.relu(x)\n        x = self.pool2(x)\n\n        return x\n\nif __name__ == '__main__':\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n    x_train = x_train.reshape(*x_train.shape, 1)[:1000]\n    y_train = y_train.reshape(*y_train.shape, 1)[:1000]\n\n    x_test = x_test.reshape(*x_test.shape, 1)\n    y_test = y_test.reshape(*y_test.shape, 1)\n\n    y_train = tf.keras.utils.to_categorical(y_train)\n    y_test = tf.keras.utils.to_categorical(y_test)\n\n    model = Classifier()\n\n    inputs = tf.keras.Input((28, 28, 1))\n\n    x = model(inputs)\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dense(10, activation=\"\"sigmoid\"\")(x)\n\n    model = tf.keras.Model(inputs=inputs, outputs=x)\n    model.compile(optimizer=\"\"adam\"\", loss=\"\"binary_crossentropy\"\", metrics=[\"\"accuracy\"\"])\n    model.fit(x_train, y_train, epochs=1, shuffle=True)\n\n    model.save(\"\"./my_model\"\")\n\nError message:  \n\n1000/1000 [==============================] - 1s 1ms/step - loss: 4.6037 - acc: 0.7025\nTraceback (most recent call last):\n  File \"\"/home/user/Data/test/python/mnist/mnist_run.py\"\", line 62, in \n    model.save(\"\"./my_model\"\")\n  File \"\"/home/user/miniconda3/envs/ml3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\"\", line 1278, in save\n    save_model(self, filepath, overwrite, include_optimizer)\n  File \"\"/home/user/miniconda3/envs/ml3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\"\", line 101, in save_model\n    'config': model.get_config()\n  File \"\"/home/user/miniconda3/envs/ml3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\"\", line 1049, in get_config\n    layer_config = layer.get_config()\n  File \"\"/home/user/miniconda3/envs/ml3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\"\", line 1028, in get_config\n    raise NotImplementedError\nNotImplementedError\n\nProcess finished with exit code 1\n\nI looked into the error line and found out that get_config method checks self._is_graph_network\n\nDo anybody deal with this problem?\n\nThanks!\n\nUpdate 1:\n\nOn the keras 2.2.2 (not tf.keras)\n\nFound comment (for model saving)\n\nfile: keras/engine/network.py\n\nFunction: get_config  \n\n  # Subclassed networks are not serializable\n\n  # (unless serialization is implemented by\n\n  # the author of the subclassed network).  \n\nSo, obviously it won't work...\n\nI wonder, why don't they point it out in the documentation (Like: \"\"Use subclassing without ability to save!\"\")\n\nUpdate 2:\n\nFound in keras documentation:  \n\n  In subclassed models, the model's topology is defined as Python code\n\n  (rather than as a static graph of layers). That means the model's\n\n  topology cannot be inspected or serialized. As a result, the following\n\n  methods and attributes are not available for subclassed models:  \n  \n  model.inputs        and model.outputs.\n\n  model.to_yaml()     and model.to_json()\n\n  model.get_config()  and model.save().  \n\nSo, there is no way to save model by using subclassing.\n\nIt's possible to only use Model.save_weights()\"",
    "answer": "\"TensorFlow 2.2\n\nThanks for @cal for noticing me that the new TensorFlow has supported saving the custom models!\n\n  By using model.save to save the whole model and by using load_model to restore previously stored subclassed model. The following code snippets describe how to implement them.\n\nclass ThreeLayerMLP(keras.Model):\n\n  def __init__(self, name=None):\n    super(ThreeLayerMLP, self).__init__(name=name)\n    self.dense_1 = layers.Dense(64, activation='relu', name='dense_1')\n    self.dense_2 = layers.Dense(64, activation='relu', name='dense_2')\n    self.pred_layer = layers.Dense(10, name='predictions')\n\n  def call(self, inputs):\n    x = self.dense_1(inputs)\n    x = self.dense_2(x)\n    return self.pred_layer(x)\n\ndef get_model():\n  return ThreeLayerMLP(name='3_layer_mlp')\n\nmodel = get_model()\n# Save the model\nmodel.save('path_to_my_model',save_format='tf')\n\n# Recreate the exact same model purely from the file\nnew_model = keras.models.load_model('path_to_my_model')\n\nSee: Save and serialize models with Keras - Part II: Saving and Loading of Subclassed Models\n\nTensorFlow 2.0\n\nTL;DR:\n\ndo not use model.save() for custom subclass keras model;\nuse save_weights() and load_weights() instead.\n\nWith the help of the Tensorflow Team, it turns out the best practice of saving a Custom Sub-Class Keras Model is to save its weights and load it back when needed.\n\nThe reason that we can not simply save a Keras custom subclass model is that it contains custom codes, which can not be serialized safely. However, the weights can be saved/loaded when we have the same model structure and custom codes without any problem.\n\nThere has a great tutorial written by Francois Chollet who is the author of Keras, for how to save/load Sequential/Functional/Keras/Custom Sub-Class Models in Tensorflow 2.0 in Colab at here. In Saving Subclassed Models section, it said that:\n\n  Sequential models and Functional models are datastructures that represent a DAG of layers. As such, they can be safely serialized and deserialized.\n  \n  A subclassed model differs in that it's not a datastructure, it's a\n  piece of code. The architecture of the model is defined via the body\n  of the call method. This means that the architecture of the model\n  cannot be safely serialized. To load a model, you'll need to have\n  access to the code that created it (the code of the model subclass).\n  Alternatively, you could be serializing this code as bytecode (e.g.\n  via pickling), but that's unsafe and generally not portable.\"",
    "mlApiName": "keras.models.save_weights,keras.models.save",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "F",
      "level3": "F",
      "leafContractCategory": "F",
      "rootCause": "Missing Required State-specific Method Order",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/43452441",
    "title": "",
    "question": "\"I combine two VGG net in keras together to make classification task. When I run the program, it shows an error:\n\n  RuntimeError: The name \"\"predictions\"\" is used 2 times in the model. All layer names should be unique.\n\nI was confused because I only use prediction layer once in my code:\n\nfrom keras.layers import Dense\nimport keras\nfrom keras.models import  Model\nmodel1 = keras.applications.vgg16.VGG16(include_top=True, weights='imagenet',\n                                input_tensor=None, input_shape=None,\n                                pooling=None,\n                                classes=1000)\nmodel1.layers.pop()\n\nmodel2 =  keras.applications.vgg16.VGG16(include_top=True, weights='imagenet',\n                                input_tensor=None, input_shape=None,\n                                pooling=None,\n                                classes=1000)\nmodel2.layers.pop()\nfor layer in model2.layers:\n    layer.name = layer.name + str(\"\"two\"\")\nmodel1.summary()\nmodel2.summary()\nfeatureLayer1 = model1.output\nfeatureLayer2 = model2.output\ncombineFeatureLayer = keras.layers.concatenate([featureLayer1, featureLayer2])\nprediction = Dense(1, activation='sigmoid', name='main_output')(combineFeatureLayer)\n\nmodel = Model(inputs=[model1.input, model2.input], outputs= prediction)\nmodel.summary()\n\nThanks for @putonspectacles help, I follow his instruction and find some interesting part. If you use model2.layers.pop() and combine the last layer of two models using \"\"model.layers.keras.layers.concatenate([model1.output, model2.output])\"\", you will find that the last layer information is still showed using the model.summary(). But actually they do not exist in the structure. So instead, you can use model.layers.keras.layers.concatenate([model1.layers[-1].output, model2.layers[-1].output]). It looks tricky but it works.. I think it is a problem about synchronization of the log and structure.\"",
    "answer": "\"First, based on the code you posted you have no layers with a name attribute 'predictions', so this error has nothing to do with your layer \n Dense layer prediction: i.e:\n\nprediction = Dense(1, activation='sigmoid', \n             name='main_output')(combineFeatureLayer)\n\nThe VGG16 model has a Dense layer with name predictions. In particular this line:\n\nx = Dense(classes, activation='softmax', name='predictions')(x)\n\nAnd since you're using two of these models you have layers with duplicate names.\n\nWhat you could do is rename the layer in the second model to something other than predictions, maybe predictions_1, like so:\n\nmodel2 =  keras.applications.vgg16.VGG16(include_top=True, weights='imagenet',\n                                input_tensor=None, input_shape=None,\n                                pooling=None,\n                                classes=1000)\n\n# now change the name of the layer inplace.\nmodel2.get_layer(name='predictions').name='predictions_1'\"",
    "mlApiName": "keras.applications.vgg16.VGG16",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SAI",
      "level3": "F,IC-2",
      "leafContractCategory": "SAM (Level 3) ? AMO(Level 2)",
      "rootCause": "Missing Input value-Method order Dependency",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/42699956",
    "title": "",
    "question": "\"I'm having a problem feeding a 3D CNN using Keras and Python to classify 3D shapes. I have a folder with some models in JSON format. I read those models into a Numpy Array. The models are 25*25*25 and represent the occupancy grid of the voxelized model (each position represents if the voxel in position (i,j,k) has points in it or no), so I only have 1 channel of input, like grayscale images in 2D images. The code that I have is the following:\n\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Convolution3D, MaxPooling3D\nfrom keras.optimizers import SGD\nfrom keras.utils import np_utils\nfrom keras import backend as K\n\n# Number of Classes and Epochs of Training\nnb_classes = 3 # cube, cone or sphere\nnb_epoch = 100\nbatch_size = 2\n\n# Input Image Dimensions\nimg_rows, img_cols, img_depth = 25, 25, 25\n\n# Number of Convolutional Filters to use\nnb_filters = 32\n\n# Convolution Kernel Size\nkernel_size = [5,5,5]\n\nX_train, Y_train = [], []\n\n# Read from File\nimport os\nimport json\n\ni=0\nfor filename in os.listdir(os.path.join(os.getcwd(), 'models')):\n    with open(os.path.join(os.getcwd(), 'models', filename)) as f:\n        file = f.readlines()\n        json_file = '\\n'.join(file)\n        content = json.loads(json_file)\n        occupancy = content['model']['occupancy']\n        form = []\n        for value in occupancy:\n            form.append(int(value))\n        final_model = [ [ [ 0 for i in range(img_rows) ]\n                              for j in range(img_cols) ]\n                              for k in range(img_depth) ]\n        a = 0\n        for i in range(img_rows):\n            for j in range(img_cols):\n                for k in range(img_depth):\n                    final_model[i][j][k] = form[a]\n                    a = a + 1\n        X_train.append(final_model)\n        Y_train.append(content['model']['label'])\n\nX_train = np.array(X_train)\nY_train = np.array(Y_train)\n\n# (1 channel, 25 rows, 25 cols, 25 of depth)\ninput_shape = (1, img_rows, img_cols, img_depth)\n\n# Init\nmodel = Sequential()\n\n# 3D Convolution layer\nmodel.add(Convolution3D(nb_filters, kernel_size[0], kernel_size[1], kernel_size[2],\n                        input_shape=input_shape,\n                        activation='relu'))\n\n# Fully Connected layer\nmodel.add(Flatten())\nmodel.add(Dense(128,\n          init='normal',\n          activation='relu'))\nmodel.add(Dropout(0.5))\n\n# Softmax Layer\nmodel.add(Dense(nb_classes,\n                init='normal'))\nmodel.add(Activation('softmax'))\n\n# Compile\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=SGD())\n\n# Fit network\nmodel.fit(X_train, Y_train, nb_epoch=nb_epoch,\n         verbose=1)\n\nAfter this, I get the following error\n\n  Using TensorFlow backend. Traceback (most recent call last):   File\n  \"\"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\"\",\n  line 670, in _call_cpp_shape_fn_impl\n      status)   File \"\"/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py\"\",\n  line 89, in exit\n      next(self.gen)   File \"\"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\"\",\n  line 469, in raise_exception_on_not_ok_status\n      pywrap_tensorflow.TF_GetCode(status)) tensorflow.python.framework.errors_impl.InvalidArgumentError: Negative\n  dimension size caused by subtracting 5 from 1 for 'Conv3D' (op:\n  'Conv3D') with input shapes: [?,1,25,25,25], [5,5,5,25,32].\n  \n  During handling of the above exception, another exception occurred:\n  \n  Traceback (most recent call last):   File \"\"CNN_3D.py\"\", line 76, in\n  \n      activation='relu'))   File \"\"/usr/local/lib/python3.6/site-packages/keras/models.py\"\", line 299, in\n  add\n      layer.create_input_layer(batch_input_shape, input_dtype)   File \"\"/usr/local/lib/python3.6/site-packages/keras/engine/topology.py\"\",\n  line 401, in create_input_layer\n      self(x)   File \"\"/usr/local/lib/python3.6/site-packages/keras/engine/topology.py\"\",\n  line 572, in call\n      self.add_inbound_node(inbound_layers, node_indices, tensor_indices)   File\n  \"\"/usr/local/lib/python3.6/site-packages/keras/engine/topology.py\"\",\n  line 635, in add_inbound_node\n      Node.create_node(self, inbound_layers, node_indices, tensor_indices)   File\n  \"\"/usr/local/lib/python3.6/site-packages/keras/engine/topology.py\"\",\n  line 166, in create_node\n      output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))   File\n  \"\"/usr/local/lib/python3.6/site-packages/keras/layers/convolutional.py\"\",\n  line 1234, in call\n      filter_shape=self.W_shape)   File \"\"/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\"\",\n  line 2831, in conv3d\n      x = tf.nn.conv3d(x, kernel, strides, padding)   File \"\"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\"\",\n  line 522, in conv3d\n      strides=strides, padding=padding, name=name)   File \"\"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\"\",\n  line 763, in apply_op\n      op_def=op_def)   File \"\"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\"\",\n  line 2397, in create_op\n      set_shapes_for_outputs(ret)   File \"\"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\"\",\n  line 1757, in set_shapes_for_outputs\n      shapes = shape_func(op)   File \"\"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\"\",\n  line 1707, in call_with_requiring\n      return call_cpp_shape_fn(op, require_shape_fn=True)   File \"\"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\"\",\n  line 610, in call_cpp_shape_fn\n      debug_python_shape_fn, require_shape_fn)   File \"\"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\"\",\n  line 675, in _call_cpp_shape_fn_impl\n      raise ValueError(err.message) ValueError: Negative dimension size caused by subtracting 5 from 1 for 'Conv3D' (op: 'Conv3D') with input\n  shapes: [?,1,25,25,25], [5,5,5,25,32].\n\nWhat am I doing wrong to get this error?\"",
    "answer": "\"I think that the problem is that you are setting the input shape in Theano ordering but you are using Keras with Tensorflow backend and Tensorflow img ordering. In addition the y_train array has to be converted to categorical labels.\n\nUpdated code:\n\nfrom keras.utils import np_utils\nfrom keras import backend as K\n\nif K.image_dim_ordering() == 'th':\n    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols, img_depth)\n    input_shape = (1, img_rows, img_cols, img_depth)\nelse:\n    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, img_depth, 1)\n    input_shape = (img_rows, img_cols, img_depth, 1)\n\nY_train = np_utils.to_categorical(Y_train, nb_classes)\n\nAdding this lines should fix it.\"",
    "mlApiName": "keras.backend.image_dim_ordering,keras.layers.Conv3D",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SAI",
      "level3": "F,IC-1,MT",
      "leafContractCategory": "SAM (Level 3) ? AMO(Level 2)",
      "rootCause": "Missing Input value-Method order Dependency",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/43715047",
    "title": "",
    "question": "\"I am using Windows 10, Python 3.5, and tensorflow 1.1.0. I have the following script:\n\nimport tensorflow as tf\nimport tensorflow.contrib.keras.api.keras.backend as K\nfrom tensorflow.contrib.keras.api.keras.layers import Dense\n\ntf.reset_default_graph()\ninit = tf.global_variables_initializer()\nsess =  tf.Session()\nK.set_session(sess) # Keras will use this sesssion to initialize all variables\n\ninput_x = tf.placeholder(tf.float32, [None, 10], name='input_x')    \ndense1 = Dense(10, activation='relu')(input_x)\n\nsess.run(init)\n\ndense1.get_weights()\n\nI get the error: AttributeError: 'Tensor' object has no attribute 'weights'\n\nWhat am I doing wrong, and how do I get the weights of dense1? I have look at this and this SO post, but I still can't make it work.\"",
    "answer": "\"If you want to get weights and biases of all layers, you can simply use:\n\nfor layer in model.layers: print(layer.get_config(), layer.get_weights())\n\nThis will print all information that's relevant.\n\nIf you want the weights directly returned as numpy arrays, you can use:\n\nfirst_layer_weights = model.layers[0].get_weights()[0]\nfirst_layer_biases  = model.layers[0].get_weights()[1]\nsecond_layer_weights = model.layers[1].get_weights()[0]\nsecond_layer_biases  = model.layers[1].get_weights()[1]\n\netc.\"",
    "mlApiName": "keras.layers.Dense",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/46619869",
    "title": "",
    "question": "\"I am using keras+tensorflow for the first time. I would like to specify the correlation coefficient as the loss function. It makes sense to square it so that it is a number between 0 and 1 where 0 is bad and 1 is good.\n\nMy basic code currently looks like:\n\ndef baseline_model():\n        model = Sequential()\n        model.add(Dense(4000, input_dim=n**2, kernel_initializer='normal', activation='relu'))\n        model.add(Dense(1, kernel_initializer='normal'))\n        # Compile model\n        model.compile(loss='mean_squared_error', optimizer='adam')\n        return model\n\nestimators = []\nestimators.append(('standardize', StandardScaler()))\nestimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=32, verbose=2)))\npipeline = Pipeline(estimators)\nkfold = KFold(n_splits=10, random_state=0)\nresults = cross_val_score(pipeline, X, Y, cv=kfold)\nprint(\"\"Standardized: %.2f (%.2f) MSE\"\" % (results.mean(), results.std()))\n\nHow can I change this so that it optimizes to minimize the squared correlation coefficient  instead?\n\nI tried the following:\n\ndef correlation_coefficient(y_true, y_pred):\n    pearson_r, _ = tf.contrib.metrics.streaming_pearson_correlation(y_pred, y_true)\n    return 1-pearson_r**2\n\ndef baseline_model():\n# create model\n        model = Sequential()\n        model.add(Dense(4000, input_dim=n**2, kernel_initializer='normal', activation='relu'))\n#        model.add(Dense(2000, kernel_initializer='normal', activation='relu'))\n        model.add(Dense(1, kernel_initializer='normal'))\n        # Compile model\n        model.compile(loss=correlation_coefficient, optimizer='adam')\n        return model\n\nbut this crashes with:\n\nTraceback (most recent call last):\n  File \"\"deeplearning-det.py\"\", line 67, in \n    results = cross_val_score(pipeline, X, Y, cv=kfold)\n  File \"\"/home/user/.local/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\"\", line 321, in cross_val_score\n    pre_dispatch=pre_dispatch)\n  File \"\"/home/user/.local/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\"\", line 195, in cross_validate\n    for train, test in cv.split(X, y, groups))\n  File \"\"/home/user/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\"\", line 779, in __call__\n    while self.dispatch_one_batch(iterator):\n  File \"\"/home/user/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\"\", line 625, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"\"/home/user/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\"\", line 588, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"\"/home/user/.local/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\"\", line 111, in apply_async\n    result = ImmediateResult(func)\n  File \"\"/home/user/.local/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\"\", line 332, in __init__\n    self.results = batch()\n  File \"\"/home/user/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\"\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"\"/home/user/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\"\", line 131, in \n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"\"/home/user/.local/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\"\", line 437, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"\"/home/user/.local/lib/python3.5/site-packages/sklearn/pipeline.py\"\", line 259, in fit\n    self._final_estimator.fit(Xt, y, **fit_params)\n  File \"\"/home/user/.local/lib/python3.5/site-packages/keras/wrappers/scikit_learn.py\"\", line 147, in fit\n    history = self.model.fit(x, y, **fit_args)\n  File \"\"/home/user/.local/lib/python3.5/site-packages/keras/models.py\"\", line 867, in fit\n    initial_epoch=initial_epoch)\n  File \"\"/home/user/.local/lib/python3.5/site-packages/keras/engine/training.py\"\", line 1575, in fit\n    self._make_train_function()\n  File \"\"/home/user/.local/lib/python3.5/site-packages/keras/engine/training.py\"\", line 960, in _make_train_function\n    loss=self.total_loss)\n  File \"\"/home/user/.local/lib/python3.5/site-packages/keras/legacy/interfaces.py\"\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"\"/home/user/.local/lib/python3.5/site-packages/keras/optimizers.py\"\", line 432, in get_updates\n    m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n  File \"\"/home/user/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\"\", line 856, in binary_op_wrapper\n    y = ops.convert_to_tensor(y, dtype=x.dtype.base_dtype, name=\"\"y\"\")\n  File \"\"/home/user/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\"\", line 611, in convert_to_tensor\n    as_ref=False)\n  File \"\"/home/user/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\"\", line 676, in internal_convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"\"/home/user/.local/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\"\", line 121, in _constant_tensor_conversion_function\n    return constant(v, dtype=dtype, name=name)\n  File \"\"/home/user/.local/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\"\", line 102, in constant\n    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n  File \"\"/home/user/.local/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\"\", line 364, in make_tensor_proto\n    raise ValueError(\"\"None values not supported.\"\")\nValueError: None values not supported.\n\nUpdate 1\n\nFollowing the answer below the code now runs. Unfortunately, the correlation_coefficient and correlation_coefficient_loss functions give different values from each other and I am not sure either of them is the same as you would get from 1- scipy.stats.pearsonr()[0]**2.  \n\n  Why are loss functions giving the wrong outputs and how can they be\n  corrected to give the same values as 1 -\n  scipy.stats.pearsonr()[0]**2 would give?\n\nHere is the completely self contained code that should just run:\n\nimport numpy as np\nimport sys\nimport math\nfrom scipy.stats import ortho_group\nfrom scipy.stats import pearsonr\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nimport tensorflow as tf\nfrom keras import backend as K\n\ndef permanent(M):\n    n = M.shape[0]\n    d = np.ones(n)\n    j = 0\n    s = 1\n    f = np.arange(n)\n    v = M.sum(axis=0)\n    p = np.prod(v)\n    while (j < n-1):\n        v -= 2*d[j]*M[j]\n        d[j] = -d[j]\n        s = -s\n        prod = np.prod(v)\n        p += s*prod\n        f[0] = 0\n        f[j] = f[j+1]\n        f[j+1] = j+1\n        j = f[0]\n    return p/2**(n-1)\n\ndef correlation_coefficient_loss(y_true, y_pred):\n    x = y_true\n    y = y_pred\n    mx = K.mean(x)\n    my = K.mean(y)\n    xm, ym = x-mx, y-my\n    r_num = K.sum(xm * ym)\n    r_den = K.sum(K.sum(K.square(xm)) * K.sum(K.square(ym)))\n    r = r_num / r_den\n    return 1 - r**2\n\ndef correlation_coefficient(y_true, y_pred):\n    pearson_r, update_op = tf.contrib.metrics.streaming_pearson_correlation(y_pred, y_true)\n    # find all variables created for this metric\n    metric_vars = [i for i in tf.local_variables() if 'correlation_coefficient' in i.name.split('/')[1]]\n\n    # Add metric variables to GLOBAL_VARIABLES collection.\n    # They will be initialized for new session.\n    for v in metric_vars:\n        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)\n\n    # force to update metric values\n    with tf.control_dependencies([update_op]):\n        pearson_r = tf.identity(pearson_r)\n        return 1-pearson_r**2\n\ndef baseline_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(4000, input_dim=no_rows**2, kernel_initializer='normal', activation='relu'))\n#    model.add(Dense(2000, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(1, kernel_initializer='normal'))\n    # Compile model\n    model.compile(loss=correlation_coefficient_loss, optimizer='adam', metrics=[correlation_coefficient])\n    return model\n\nno_rows = 8\n\nprint(\"\"Making the input data using seed 7\"\", file=sys.stderr)\nnp.random.seed(7)\nU = ortho_group.rvs(no_rows**2)\nU = U[:, :no_rows]\n# U is a random orthogonal matrix\nX = []\nY = []\nprint(U)\nfor i in range(40000):\n        I = np.random.choice(no_rows**2, size = no_rows)\n        A = U[I][np.lexsort(np.rot90(U[I]))]\n        X.append(A.ravel())\n        Y.append(-math.log(permanent(A)**2, 2))\n\nX = np.array(X)\nY = np.array(Y)\n\nestimators = []\nestimators.append(('standardize', StandardScaler()))\nestimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=32, verbose=2)))\npipeline = Pipeline(estimators)\nX_train, X_test, y_train, y_test = train_test_split(X, Y,\n                                                    train_size=0.75, test_size=0.25)\npipeline.fit(X_train, y_train)\n\nUpdate 2\n\nI have given up on the correlation_coefficient function and am now just using the correlation_coefficient_loss one as given by JulioDanielReyes below.  However, either this is still wrong or keras is dramatically overfitting.  Even when I have:\n\ndef baseline_model():\n        model = Sequential()\n        model.add(Dense(40, input_dim=no_rows**2, kernel_initializer='normal', activation='relu'))\n        model.add(Dense(1, kernel_initializer='normal'))\n        model.compile(loss=correlation_coefficient_loss, optimizer='adam', metrics=[correlation_coefficient_loss])\n        return model\n\nI get a loss of, for example, 0.6653 after 100 epochs but 0.857 when I test the trained model.\n\n  How can it be overfitting which such a tiny number of nodes in the\n  hidden layer?\"",
    "answer": "\"According to keras documentation, you should pass the squared correlation coefficient as a function instead of the string 'mean_squared_error'.\n\nThe function needs to receive 2 tensors (y_true, y_pred). You can look at keras source code for inspiration.\n\nThere is also a function tf.contrib.metrics.streaming_pearson_correlation implemented on tensorflow. Just be careful on the order of the parameters, it should be something like this:\n\nUpdate 1: initialize local variables according to this issue\n\nimport tensorflow as tf\ndef correlation_coefficient(y_true, y_pred):\n    pearson_r, update_op = tf.contrib.metrics.streaming_pearson_correlation(y_pred, y_true, name='pearson_r'\n    # find all variables created for this metric\n    metric_vars = [i for i in tf.local_variables() if 'pearson_r'  in i.name.split('/')]\n\n    # Add metric variables to GLOBAL_VARIABLES collection.\n    # They will be initialized for new session.\n    for v in metric_vars:\n        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)\n\n    # force to update metric values\n    with tf.control_dependencies([update_op]):\n        pearson_r = tf.identity(pearson_r)\n        return 1-pearson_r**2\n\n...\n\nmodel.compile(loss=correlation_coefficient, optimizer='adam')\n\nUpdate 2: even though you cannot use the scipy function directly, you can look at the implementation and port it to your code using keras backend. \n\nUpdate 3: The tensorflow function as it is may not be differentiable, your loss function needs to be something like this: (Please check the math)\n\nfrom keras import backend as K\ndef correlation_coefficient_loss(y_true, y_pred):\n    x = y_true\n    y = y_pred\n    mx = K.mean(x)\n    my = K.mean(y)\n    xm, ym = x-mx, y-my\n    r_num = K.sum(tf.multiply(xm,ym))\n    r_den = K.sqrt(tf.multiply(K.sum(K.square(xm)), K.sum(K.square(ym))))\n    r = r_num / r_den\n\n    r = K.maximum(K.minimum(r, 1.0), -1.0)\n    return 1 - K.square(r)\n\nUpdate 4: The results are different on both functions, but correlation_coefficient_loss gives the same results as scipy.stats.pearsonr:\nHere is the code to test it:\n\nimport tensorflow as tf\nfrom keras import backend as K\nimport numpy as np\nimport scipy.stats\n\ninputa = np.array([[3,1,2,3,4,5],\n                    [1,2,3,4,5,6],\n                    [1,2,3,4,5,6]])\ninputb = np.array([[3,1,2,3,4,5],\n                    [3,1,2,3,4,5],\n                    [6,5,4,3,2,1]])\n\nwith tf.Session() as sess:\n    a = tf.placeholder(tf.float32, shape=[None])\n    b = tf.placeholder(tf.float32, shape=[None])\n    f1 = correlation_coefficient(a, b)\n    f2 = correlation_coefficient_loss(a, b)\n\n    sess.run(tf.global_variables_initializer())\n\n    for i in range(inputa.shape[0]):\n\n        f1_result, f2_result = sess.run([f1, f2], feed_dict={a: inputa[i], b: inputb[i]})\n        scipy_result =1- scipy.stats.pearsonr(inputa[i], inputb[i])[0]**2\n        print(\"\"a: \"\"+ str(inputa[i]) + \"\" b: \"\" + str(inputb[i]))\n        print(\"\"correlation_coefficient: \"\" + str(f1_result))\n        print(\"\"correlation_coefficient_loss: \"\" + str(f2_result))\n        print(\"\"scipy.stats.pearsonr:\"\" + str(scipy_result))\n\nResults:\n\na: [3 1 2 3 4 5] b: [3 1 2 3 4 5]\ncorrelation_coefficient: -2.38419e-07\ncorrelation_coefficient_loss: 0.0\nscipy.stats.pearsonr:0.0\na: [1 2 3 4 5 6] b: [3 1 2 3 4 5]\ncorrelation_coefficient: 0.292036\ncorrelation_coefficient_loss: 0.428571\nscipy.stats.pearsonr:0.428571428571\na: [1 2 3 4 5 6] b: [6 5 4 3 2 1]\ncorrelation_coefficient: 0.994918\ncorrelation_coefficient_loss: 0.0\nscipy.stats.pearsonr:0.0\"",
    "mlApiName": "keras.models.compile",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "DT",
      "level3": "RT",
      "leafContractCategory": "RT",
      "rootCause": "Unacceptable Input Type",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/47671732",
    "title": "",
    "question": "\"I have read a sequence of images into a numpy array with shape (7338, 225, 1024, 3) where 7338 is the sample size, 225 are the time steps and 1024 (32x32) are flattened image pixels, in 3 channels (RGB).\n\nI have a sequential model with an LSTM layer:\n\nmodel = Sequential()\nmodel.add(LSTM(128, input_shape=(225, 1024, 3))\n\nBut this results in the error:\n\nInput 0 is incompatible with layer lstm_1: expected ndim=3, found ndim=4\n\nThe documentation mentions that the input tensor for LSTM layer should be a 3D tensor with shape (batch_size, timesteps, input_dim), but in my case my input_dim is 2D.\n\nWhat is the suggested way to input a 3 channel image into an LSTM layer  in Keras?\"",
    "answer": "\"If you want the number of images to be a sequence (like a movie with frames), you need to put pixels AND channels as features:\n\ninput_shape = (225,3072)  #a 3D input where the batch size 7338 wasn't informed\n\nIf you want more processing before throwing 3072 features into an LSTM, you can combine or interleave 2D convolutions and LSTMs for a more refined model (not necessarily better, though, each application has its particular behavior). \n\nYou can also try to use the new ConvLSTM2D, which will take the five dimensional input:\n\ninput_shape=(225,32,32,3) #a 5D input where the batch size 7338 wasn't informed\n\nI'd probably create a convolutional net with several TimeDistributed(Conv2D(...)) and TimeDistributed(MaxPooling2D(...)) before adding a TimeDistributed(Flatten()) and finally the LSTM(). This will very probably improve both your image understanding and the performance of the LSTM.\"",
    "mlApiName": "keras.layers.LSTM",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "DT",
      "level3": "MT",
      "leafContractCategory": "MT",
      "rootCause": "Unacceptable Input Type",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/45930844",
    "title": "",
    "question": "\"I am trying to create my first ensemble models in keras. I have 3 input values and a single output value in my dataset.\n\nfrom keras.optimizers import SGD,Adam\nfrom keras.layers import Dense,Merge\nfrom keras.models import Sequential\n\nmodel1 = Sequential()\nmodel1.add(Dense(3, input_dim=3, activation='relu'))\nmodel1.add(Dense(2, activation='relu'))\nmodel1.add(Dense(2, activation='tanh'))\nmodel1.compile(loss='mse', optimizer='Adam', metrics=['accuracy'])\n\nmodel2 = Sequential()\nmodel2.add(Dense(3, input_dim=3, activation='linear'))\nmodel2.add(Dense(4, activation='tanh'))\nmodel2.add(Dense(3, activation='tanh'))\nmodel2.compile(loss='mse', optimizer='SGD', metrics=['accuracy'])\n\nmodel3 = Sequential()\nmodel3.add(Merge([model1, model2], mode = 'concat'))\nmodel3.add(Dense(1, activation='sigmoid'))\nmodel3.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n\nmodel3.input_shape\n\nThe ensemble model(model3) compiles without any error but while fitting the model I have to pass the same input two times model3.fit([X,X],y). Which I think is an unnecessary step and instead of passing input twice I want to have a common input nodes for my ensemble model. How can I do it?\"",
    "answer": "\"Keras functional API seems to be a better fit for your use case, as it allows more flexibility in the computation graph. e.g.:\n\nfrom keras.layers import concatenate\nfrom keras.models import Model\nfrom keras.layers import Input, Merge\nfrom keras.layers.core import Dense\nfrom keras.layers.merge import concatenate\n\n# a single input layer\ninputs = Input(shape=(3,))\n\n# model 1\nx1 = Dense(3, activation='relu')(inputs)\nx1 = Dense(2, activation='relu')(x1)\nx1 = Dense(2, activation='tanh')(x1)\n\n# model 2 \nx2 = Dense(3, activation='linear')(inputs)\nx2 = Dense(4, activation='tanh')(x2)\nx2 = Dense(3, activation='tanh')(x2)\n\n# merging models\nx3 = concatenate([x1, x2])\n\n# output layer\npredictions = Dense(1, activation='sigmoid')(x3)\n\n# generate a model from the layers above\nmodel = Model(inputs=inputs, outputs=predictions)\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Always a good idea to verify it looks as you expect it to \n# model.summary()\n\ndata = [[1,2,3], [1,1,3], [7,8,9], [5,8,10]]\nlabels = [0,0,1,1]\n\n# The resulting model can be fit with a single input:\nmodel.fit(data, labels, epochs=50)\n\nNotes:\n\nThere might be slight differences in the API between Keras versions (pre- and post- version 2)\nThe example above specifies different optimizer and loss function for each of the models. However, since fit() is being called only once (on model3), the same settings - those of model3 - will apply to the entire model. In order to have different settings when training the sub-models, they will have to be fit() separately - \nsee comment by @Daniel.\n\nEDIT: updated notes based on comments\"",
    "mlApiName": "keras.models.Model,keras.layers.merge.concatenate",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SL",
      "level3": "F",
      "leafContractCategory": "AMO(Level-2)",
      "rootCause": "Missing Options",
      "effect": "Unknown",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/42886049",
    "title": "",
    "question": "\"I am trying to train 1000x of Sequential models in a loop. In every loop my program leaks memory until I run out and get an OOM exception.\n\nI already asked a similar question before\n(Training multiple Sequential models in a row slows down)\n\nand have seen others in similar problems (Keras: Out of memory when doing hyper parameter grid search)\n\nand the solution is always to add K.clear_session() to your code after you have finished using the model. So I did that in my previous question and I am still leaking memory\n\nHere is code to reproduce the issue.\n\nimport random\nimport time\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras import backend as K\nimport tracemalloc\n\ndef run():\n    tracemalloc.start()\n    num_input_nodes = 12\n    num_hidden_nodes = 8\n    num_output_nodes = 1\n\n    random_numbers = random.sample(range(1000), 50)\n    train_x, train_y = create_training_dataset(random_numbers, num_input_nodes)\n\n    for i in range(100):\n        snapshot = tracemalloc.take_snapshot()\n        for j in range(10):\n            start_time = time.time()\n            nn = Sequential()\n            nn.add(Dense(num_hidden_nodes, input_dim=num_input_nodes, activation='relu'))\n            nn.add(Dense(num_output_nodes))\n            nn.compile(loss='mean_squared_error', optimizer='adam')\n            nn.fit(train_x, train_y, nb_epoch=300, batch_size=2, verbose=0)\n            K.clear_session()\n            print(\"\"Iteration {iter}. Current time {t}. Took {elapsed} seconds\"\".\n                  format(iter=i*10 + j + 1, t=time.strftime('%H:%M:%S'), elapsed=int(time.time() - start_time)))\n\n        top_stats = tracemalloc.take_snapshot().compare_to(snapshot, 'lineno')\n\n        print(\"\"[ Top 5 differences ]\"\")\n        for stat in top_stats[:5]:\n            print(stat)\n\ndef create_training_dataset(dataset, input_nodes):\n    \"\"\"\"\"\"\n    Outputs a training dataset (train_x, train_y) as numpy arrays.\n    Each item in train_x has 'input_nodes' number of items while train_y items are of size 1\n    :param dataset: list of ints\n    :param input_nodes:\n    :return: (numpy array, numpy array), train_x, train_y\n    \"\"\"\"\"\"\n    data_x, data_y = [], []\n    for i in range(len(dataset) - input_nodes - 1):\n        a = dataset[i:(i + input_nodes)]\n        data_x.append(a)\n        data_y.append(dataset[i + input_nodes])\n    return numpy.array(data_x), numpy.array(data_y)\n\nrun()\n\nHere is the output I get from the first memory debug print\n\n/tensorflow/python/framework/ops.py:121: size=3485 KiB (+3485 KiB), count=42343 (+42343)\n/tensorflow/python/framework/ops.py:1400: size=998 KiB (+998 KiB), count=8413 (+8413)\n/tensorflow/python/framework/ops.py:116: size=888 KiB (+888 KiB), count=32468 (+32468)\n/tensorflow/python/framework/ops.py:1185: size=795 KiB (+795 KiB), count=3179 (+3179)\n/tensorflow/python/framework/ops.py:2354: size=599 KiB (+599 KiB), count=5886 (+5886)\n\nSystem info:\n\npython 3.5\nkeras (1.2.2)\ntensorflow(1.0.0)\"",
    "answer": "\"The memory leak stems from Keras and TensorFlow using a single \"\"default graph\"\" to store the network structure, which increases in size with each iteration of the inner for loop. \n\nCalling K.clear_session() frees some of the (backend) state associated with the default graph between iterations, but an additional call to tf.reset_default_graph() is needed to clear the Python state.\n\nNote that there might be a more efficient solution: since nn does not depend on either of the loop variables, you can define it outside the loop, and reuse the same instance inside the loop. If you do that, there is no need to clear the session or reset the default graph, and performance should increase because you benefit from caching between iterations.\"",
    "mlApiName": "keras.backend.clear_session,keras.models.fit",
    "embedding": [],
    "label": {
      "level1": "AMO",
      "level2": "G",
      "level3": "G",
      "leafContractCategory": "G",
      "rootCause": "Missing Required Method Order",
      "effect": "MOB",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Train",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/48547688",
    "title": "",
    "question": "\"Using Keras from Tensorflow 1.4.1, how does one copy weights from one model to another?\n\nAs some background, I'm trying to implement a deep-q network (DQN) for Atari games following the DQN publication by DeepMind.  My understanding is that the implementation uses two networks, Q and Q'.  The weights of Q are trained using gradient descent, and then the weights are copied periodically to Q'.\n\nHere's how I build Q and Q':\n\nACT_SIZE   = 4\nLEARN_RATE = 0.0025\nOBS_SIZE   = 128\n\ndef buildModel():\n  model = tf.keras.models.Sequential()\n\n  model.add(tf.keras.layers.Lambda(lambda x: x / 255.0, input_shape=OBS_SIZE))\n  model.add(tf.keras.layers.Dense(128, activation=\"\"relu\"\"))\n  model.add(tf.keras.layers.Dense(128, activation=\"\"relu\"\"))\n  model.add(tf.keras.layers.Dense(ACT_SIZE, activation=\"\"linear\"\"))\n  opt = tf.keras.optimizers.RMSprop(lr=LEARN_RATE)\n\n  model.compile(loss=\"\"mean_squared_error\"\", optimizer=opt)\n\n  return model\n\nI call that twice to get Q and Q'.\n\nI have an updateTargetModel method below that is my attempt at copying weights.  The code runs fine, but my overall DQN implementation is failing.  I'm really just trying to verify if this is a valid way of copying weights from one network to another.\n\ndef updateTargetModel(model, targetModel):\n  modelWeights       = model.trainable_weights\n  targetModelWeights = targetModel.trainable_weights\n\n  for i in range(len(targetModelWeights)):\n    targetModelWeights[i].assign(modelWeights[i])\n\nThere's another question here that discusses saving and loading weights to and from disk (Tensorflow Copy Weights Issue), but there's no accepted answer.  There is also a question about loading weights from individual layers (Copying weights from one Conv2D layer to another), but I'm wanting to copy the entire model's weights.\"",
    "answer": "Actually what you've done is much more than simply copying weights. You made these two models identical all the time. Every time you update one model - the second one is also updated - as both models have the same weights variables.\n\nIf you want to just copy weights - the simplest way is by this command:\n\ntarget_model.set_weights(model.get_weights())",
    "mlApiName": "0",
    "embedding": [],
    "label": {
      "level1": "0",
      "level2": "0",
      "level3": "0",
      "leafContractCategory": "0",
      "rootCause": "0",
      "effect": "0",
      "mlLibrary": "Keras",
      "contractViolationLocation": "0",
      "detectionTechnique": "0",
      "reasonsForNotLabeling": "General Clarification",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/50920908",
    "title": "",
    "question": "\"This question already has answers here:\n                                \n                            \n                    \n                \n            \n                    \n                        Multilabel-indicator is not supported for confusion matrix\n                            \n                                (4 answers)\n                            \n                    \n                Closed 5 years ago.\n        \n\n    \n\nI am building a multiclass model with Keras.\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, callbacks=[checkpoint], validation_data=(X_test, y_test))  # starts training\n\nHere is how my test data looks like (it's text data).\n\nX_test\nOut[25]: \narray([[621, 139, 549, ...,   0,   0,   0],\n       [621, 139, 543, ...,   0,   0,   0]])\n\ny_test\nOut[26]: \narray([[0, 0, 1],\n       [0, 1, 0]])\n\nAfter generating predictions...\n\npredictions = model.predict(X_test)\npredictions\nOut[27]: \narray([[ 0.29071924,  0.2483743 ,  0.46090645],\n       [ 0.29566404,  0.45295066,  0.25138539]], dtype=float32)\n\nI did the following to get the confusion matrix.\n\ny_pred = (predictions > 0.5)\n\nconfusion_matrix(y_test, y_pred)\nTraceback (most recent call last):\n\n  File \"\"\"\", line 1, in \n    confusion_matrix(y_test, y_pred)\n\n  File \"\"/Users/abrahammathew/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\"\", line 252, in confusion_matrix\n    raise ValueError(\"\"%s is not supported\"\" % y_type)\n\nValueError: multilabel-indicator is not supported\n\nHowever, I am getting the above error.\n\nHow can I get a confusion matrix when doing a multiclass neural network in Keras?\"",
    "answer": "\"Your input to confusion_matrix must be an array of int not one hot encodings.\n\nmatrix = metrics.confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\"",
    "mlApiName": "keras.models.compile.metrics.confusion_matrix",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Evaluation",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/46204569",
    "title": "",
    "question": "\"I am trying to perform the usual classification on the MNIST database but with randomly cropped digits. \nImages are cropped the following way : removed randomly first/last and/or row/column.\n\nI would like to use a Convolutional Neural Network using Keras (and Tensorflow backend) to perform convolution and then the usual classification.\n\nInputs are of variable size and i can't manage to get it to work.\n\nHere is how I cropped digits\n\nimport numpy as np\nfrom keras.utils import to_categorical\nfrom sklearn.datasets import load_digits\n\ndigits = load_digits()\n\nX = digits.images\nX = np.expand_dims(X, axis=3)\n\nX_crop = list()\nfor index in range(len(X)):\n    X_crop.append(X[index, np.random.randint(0,2):np.random.randint(7,9), np.random.randint(0,2):np.random.randint(7,9), :])\nX_crop = np.array(X_crop)\n\ny = to_categorical(digits.target)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_crop, y, train_size=0.8, test_size=0.2)\n\nAnd here is the architecture of the model I want to use\n\nfrom keras.layers import Dense, Dropout\nfrom keras.layers.convolutional import Conv2D\nfrom keras.models import Sequential\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=10, \n                 kernel_size=(3,3), \n                 input_shape=(None, None, 1), \n                 data_format='channels_last'))\n\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n\nmodel.summary()\n\nmodel.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test))\n\nDoes someone have an idea on how to handle variable sized input in my neural network? \nAnd how to perform classification?\"",
    "answer": "\"TL/DR - go to point 4\n\nSo - before we get to the point - let's fix some problems with your network:\n\nYour network will not work because of activation: with categorical_crossentropy you need to have a softmax activation:\n\nmodel.add(Dense(10, activation='softmax'))\n\nVectorize spatial tensors: as Daniel mentioned - you need to, at some stage, switch your vectors from spatial (images) to vectorized (vectors). Currently - applying Dense to output from a Conv2D is equivalent to (1, 1) convolution. So basically - output from your network is spatial - not vectorized what causes dimensionality mismatch (you can check that by running your network or checking the model.summary(). In order to change that you need to use either GlobalMaxPooling2D or GlobalAveragePooling2D. E.g.:\n\nmodel.add(Conv2D(filters=10, \n             kernel_size=(3, 3), \n             input_shape=(None, None, 1),\n             padding=\"\"same\"\",\n             data_format='channels_last'))\nmodel.add(GlobalMaxPooling2D())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(10, activation='softmax'))\n\nConcatenated numpy arrays need to have the same shape: if you check the shape of X_crop you'll see that it's not a spatial matrix. It's because you concatenated matrices with different shapes. Sadly - it's impossible to overcome this issue as numpy.array need to have a fixed shape.\nHow to make your network train on examples of different shape: The most important thing in doing this is to understand two things. First - is that in a single batch every image should have the same size. Second - is that calling fit multiple times is a bad idea - as you reset inner model states. So here is what needs to be done:\n\na. Write a function which crops a single batch - e.g. a get_cropped_batches_generator which given a matrix cuts a batch out of it and crops it randomly.\n\nb. Use train_on_batch method. Here is an example code:\n\nfrom six import next\n\nbatches_generator = get_cropped_batches_generator(X, batch_size=16)\nlosses = list()\nfor epoch_nb in range(nb_of_epochs):\n    epoch_losses = list()\n    for batch_nb in range(nb_of_batches):\n        # cropped_x has a different shape for different batches (in general)\n        cropped_x, cropped_y = next(batches_generator) \n        current_loss = model.train_on_batch(cropped_x, cropped_y)\n        epoch_losses.append(current_loss)\n    losses.append(epoch_losses.sum() / (1.0 * len(epoch_losses))\nfinal_loss = losses.sum() / (1.0 * len(losses))\n\nSo - a few comments to code above: First, train_on_batch doesn't use nice keras progress bar. It returns a single loss value (for a given batch) - that's why I added logic to compute loss. You could use Progbar callback for that also. Second - you need to implement get_cropped_batches_generator - I haven't written a code to keep my answer a little bit more clear. You could ask another question on how to implement it. Last thing - I use six to keep compatibility between Python 2 and Python 3.\"",
    "mlApiName": "keras.layers.Dense,keras.models.compile",
    "embedding": [],
    "label": {
      "level1": "Hybrid",
      "level2": "SAI",
      "level3": "IC-2,F",
      "leafContractCategory": "SAM (Level 3) ? AMO(Level 2)",
      "rootCause": "Missing Input value-Method order Dependency",
      "effect": "Unknown",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/47167630",
    "title": "",
    "question": "\"Lets say I have a simple neural network with an input layer and a single convolution layer programmed in tensorflow:\n\n  # Input Layer\n  input_layer = tf.reshape(features[\"\"x\"\"], [-1, 28, 28, 1])\n\n  # Convolutional Layer #1\n  conv1 = tf.layers.conv2d(\n      inputs=input_layer,\n      filters=32,\n      kernel_size=[5, 5],\n      padding=\"\"same\"\",\n      activation=tf.nn.relu)\n\nI leave out any further parts of the network definitions for the features.\n\nIf I wanted to add an LSTM Layer after this convolution layer, I would have to make the convolution layer TimeDistributed (in the language of keras) and then put the output of the TimeDistributed layer into the LSTM. \n\nTensorflow offers access to the keras layers in tf.keras.layers. Can I use the keras layers directly in the tensorflow code? If so, how? Could I also use the tf.keras.layers.lstm for the implementation of the LSTM Layer?\n\nSo in general: Is a mixture of pure tensorflow code and keras code possible and can I use the tf.keras.layers?\"",
    "answer": "\"Yes, this is possible.\n\nImport both TensorFlow and Keras and link your Keras session to the TF one:\n\nimport tensorflow as tf\nimport keras\nfrom keras import backend as K\n\ntf_sess = tf.Session()\nK.set_session(tf_sess)\n\nNow, in your model definition, you can mix TF and Keras layers like so:\n\n# Input Layer\ninput_layer = tf.reshape(features[\"\"x\"\"], [-1, 28, 28, 1])\n\n# Convolutional Layer #1\nconv1 = tf.layers.conv2d(\n    inputs=input_layer,\n    filters=32,\n    kernel_size=[5, 5],\n    padding=\"\"same\"\",\n    activation=tf.nn.relu)\n\n# Flatten conv output\nflat = tf.contrib.layers.flatten(conv1)\n\n# Fully-connected Keras layer\nlayer2_dense = keras.layers.Dense(128, activation='relu')(flat)\n\n# Fully-connected TF layer (output)\noutput_preds = tf.layers.dense(layer2_dense, units=10)\n\nThis answer is adopted from a Keras blog post by Francois Chollet.\"",
    "mlApiName": "keras.backend.set_session",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "Unknown",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Initialization",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/48493755",
    "title": "",
    "question": "\"I'm running a Keras neural network model in Jupyter Notebook (Python 3.6)\n\nI get the following error\n\n  AttributeError: 'list' object has no attribute 'ndim'\n\nafter calling the .fit() method from Keras.model\n\nmodel  = Sequential()\nmodel.add(Dense(5, input_dim=len(X_data[0]), activation='sigmoid' ))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\nmodel.fit(X_data, y_data, epochs=20, batch_size=10)\n\nI checked the requirements.txt file for Keras (in Anaconda3) and the numpy, scipy, and six module versions are all up to date.\n\nWhat can explain this AttributeError?\n\nThe full error message is the following (seems to be somewhat related to Numpy):\n\n  --------------------------------------------------------------------------- AttributeError                            Traceback (most recent call\n  last)  in ()\n        3 model.add(Dense(1, activation = 'sigmoid'))\n        4 model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n  ----> 5 model.fit(X_data, y_data, epochs=20, batch_size=10)\n  \n  ~\\Anaconda3\\lib\\site-packages\\keras\\models.py in fit(self, x, y,\n  batch_size, epochs, verbose, callbacks, validation_split,\n  validation_data, shuffle, class_weight, sample_weight, initial_epoch,\n  steps_per_epoch, validation_steps, **kwargs)\n      963                               initial_epoch=initial_epoch,\n      964                               steps_per_epoch=steps_per_epoch,\n  --> 965                               validation_steps=validation_steps)\n      966 \n      967     def evaluate(self, x=None, y=None,\n  \n  ~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py in fit(self, x,\n  y, batch_size, epochs, verbose, callbacks, validation_split,\n  validation_data, shuffle, class_weight, sample_weight, initial_epoch,\n  steps_per_epoch, validation_steps, **kwargs)    1591\n\n  class_weight=class_weight,    1592             check_batch_axis=False,\n  -> 1593             batch_size=batch_size)    1594         # Prepare validation data.    1595         do_validation = False\n  \n  ~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py in\n  _standardize_user_data(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)    1424\n\n  self._feed_input_shapes,    1425\n\n  check_batch_axis=False,\n  -> 1426                                     exception_prefix='input')    1427         y = _standardize_input_data(y, self._feed_output_names,\n\n  1428                                     output_shapes,\n  \n  ~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py in\n  _standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)\n       68     elif isinstance(data, list):\n       69         data = [x.values if x.class.name == 'DataFrame' else x for x in data]\n  ---> 70         data = [np.expand_dims(x, 1) if x is not None and x.ndim == 1 else x for x in data]\n       71     else:\n       72         data = data.values if data.class.name == 'DataFrame' else data\n  \n  ~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py in\n  (.0)\n       68     elif isinstance(data, list):\n       69         data = [x.values if x.class.name == 'DataFrame' else x for x in data]\n  ---> 70         data = [np.expand_dims(x, 1) if x is not None and x.ndim == 1 else x for x in data]\n       71     else:\n       72         data = data.values if data.class.name == 'DataFrame' else data\n  \n  AttributeError: 'list' object has no attribute 'ndim'\"",
    "answer": "\"model.fit expects x and y to be numpy array. Seems like you pass a list, it tried to get shape of input by reading ndim attribute of numpy array and failed. \n\nYou can simply transform it using np.array:\n\nimport numpy as np\n...\nmodel.fit(np.array(train_X),np.array(train_Y), epochs=20, batch_size=10)\"",
    "mlApiName": "keras.models.fit",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "DT",
      "level3": "MT",
      "leafContractCategory": "MT",
      "rootCause": "Unacceptable Input Type",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Train",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/46464549",
    "title": "",
    "question": "\"In Keras (with Tensorflow backend), is the current input pattern available to my custom loss function?\n\nThe current input pattern is defined as the input vector used to produce the prediction. For example, consider the following: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False). Then the current input pattern is the current X_train vector associated with the y_train (which is termed y_true in the loss function).\n\nWhen designing a custom loss function, I intend to optimize/minimize a value that requires access to the current input pattern, not just the current prediction.\n\nI've taken a look through https://github.com/fchollet/keras/blob/master/keras/losses.py\n\nI've also looked through \"\"Cost function that isn't just y_pred, y_true?\"\"\n\nI am also familiar with previous examples to produce a customized loss function:\n\nimport keras.backend as K\n\ndef customLoss(y_true,y_pred):\n    return K.sum(K.log(y_true) - K.log(y_pred))\n\nPresumably (y_true,y_pred) are defined elsewhere. I've taken a look through the source code without success and I'm wondering whether I need to define the current input pattern myself or whether this is already accessible to my loss function.\"",
    "answer": "\"You can wrap the loss function as a inner function and pass your input tensor to it (as commonly done when passing additional arguments to the loss function).\n\ndef custom_loss_wrapper(input_tensor):\n    def custom_loss(y_true, y_pred):\n        return K.binary_crossentropy(y_true, y_pred) + K.mean(input_tensor)\n    return custom_loss\n\ninput_tensor = Input(shape=(10,))\nhidden = Dense(100, activation='relu')(input_tensor)\nout = Dense(1, activation='sigmoid')(hidden)\nmodel = Model(input_tensor, out)\nmodel.compile(loss=custom_loss_wrapper(input_tensor), optimizer='adam')\n\nYou can verify that input_tensor and the loss value (mostly, the K.mean(input_tensor) part) will change as different X is passed to the model.\n\nX = np.random.rand(1000, 10)\ny = np.random.randint(2, size=1000)\nmodel.test_on_batch(X, y)  # => 1.1974642\n\nX *= 1000\nmodel.test_on_batch(X, y)  # => 511.15466\"",
    "mlApiName": "keras.models.compile",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "Unknown",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/50304156",
    "title": "",
    "question": "\"Using ResNet50 pre-trained Weights I am trying to build a classifier. The code base is fully implemented in Keras high-level Tensorflow API. The complete code is posted in the below GitHub Link.\nSource Code: Classification Using RestNet50 Architecture\nThe file size of the pre-trained model is 94.7mb.\nI loaded the pre-trained file\nnew_model = Sequential()\n\nnew_model.add(ResNet50(include_top=False,\n                pooling='avg',\n                weights=resnet_weight_paths))\n\nand fit the model\ntrain_generator = data_generator.flow_from_directory(\n    'path_to_the_training_set',\n    target_size = (IMG_SIZE,IMG_SIZE),\n    batch_size = 12,\n    class_mode = 'categorical'\n    )\n\nvalidation_generator = data_generator.flow_from_directory(\n    'path_to_the_validation_set',\n    target_size = (IMG_SIZE,IMG_SIZE),\n    class_mode = 'categorical'\n    )\n\n#compile the model\n\nnew_model.fit_generator(\n    train_generator,\n    steps_per_epoch = 3,\n    validation_data = validation_generator,\n    validation_steps = 1\n)\n\nand in the Training dataset, I have two folders dog and cat, each holder almost 10,000 images. When  I compiled the script, I get the following error\n\nEpoch 1/1 2018-05-12 13:04:45.847298: W\ntensorflow/core/framework/allocator.cc:101] Allocation of 38535168\nexceeds 10% of system memory. 2018-05-12 13:04:46.845021: W\ntensorflow/core/framework/allocator.cc:101] Allocation of 37171200\nexceeds 10% of system memory. 2018-05-12 13:04:47.552176: W\ntensorflow/core/framework/allocator.cc:101] Allocation of 37171200\nexceeds 10% of system memory. 2018-05-12 13:04:48.199240: W\ntensorflow/core/framework/allocator.cc:101] Allocation of 37171200\nexceeds 10% of system memory. 2018-05-12 13:04:48.918930: W\ntensorflow/core/framework/allocator.cc:101] Allocation of 37171200\nexceeds 10% of system memory. 2018-05-12 13:04:49.274137: W\ntensorflow/core/framework/allocator.cc:101] Allocation of 19267584\nexceeds 10% of system memory. 2018-05-12 13:04:49.647061: W\ntensorflow/core/framework/allocator.cc:101] Allocation of 19267584\nexceeds 10% of system memory. 2018-05-12 13:04:50.028839: W\ntensorflow/core/framework/allocator.cc:101] Allocation of 19267584\nexceeds 10% of system memory. 2018-05-12 13:04:50.413735: W\ntensorflow/core/framework/allocator.cc:101] Allocation of 19267584\nexceeds 10% of system memory.\n\nAny ideas to optimize the way to load the pre-trained model (or) get rid of this warning message?\nThanks!\"",
    "answer": "\"Try reducing batch_size attribute to a small number(like 1,2 or 3).\nExample:\n\ntrain_generator = data_generator.flow_from_directory(\n    'path_to_the_training_set',\n    target_size = (IMG_SIZE,IMG_SIZE),\n    batch_size = 2,\n    class_mode = 'categorical'\n    )\"",
    "mlApiName": "keras.preprocessing.image.ImageDataGenerator.data_generator.flow_from_directory",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "MOB",
      "mlLibrary": "Keras",
      "contractViolationLocation": "0",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/44720822",
    "title": "",
    "question": "\"After some search here, I still can't find a solution for this. I'm new to Keras, apologies if there is a solution and I actually didn't understand how it was related to my problem.\n\nI am making a small RNN with Keras 2/Functional API, and I have trouble to make the Concatenate Layer work.\n\nHere is my structure :\n\ninputSentence = Input(shape=(30, 91))\nsentenceMatrix = LSTM(91, return_sequences=True, input_shape=(30, 91))(inputSentence)\n\ninputDeletion = Input(shape=(30, 1))\ndeletionMatrix = (LSTM(30, return_sequences=True, input_shape=(30, 1)))(inputDeletion)\n\nfusion = Concatenate([sentenceMatrix, deletionMatrix])\nfusion = Dense(122, activation='relu')(fusion)\nfusion = Dense(102, activation='relu')(fusion)\nfusion = Dense(91, activation='sigmoid')(fusion)\n\nF = Model(inputs=[inputSentence, inputDeletion], outputs=fusion)\n\nAnd here is the error:\n\nValueError: Unexpectedly found an instance of type ``. Expected a symbolic tensor instance.\n\nFull History if it helps a bit more :\n\nUsing TensorFlow backend.\n    str(inputs) + '. All inputs to the layer '\nValueError: Layer dense_1 was called with an input that isn't a symbolic tensor. Received type: . Full input: []. All inputs to the layer should be tensors.\nself.assert_input_compatibility(inputs)\n  File \"\"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\"\", line 425, in assert_input_compatibility\nfusion = Dense(122, activation='relu')(fusion)\n  File \"\"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\"\", line 552, in __call__\nTraceback (most recent call last):\n  File \"\"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\"\", line 419, in assert_input_compatibility\nK.is_keras_tensor(x)\n  File \"\"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\"\", line 392, in is_keras_tensor\nraise ValueError('Unexpectedly found an instance of type `' + str(type(x)) + '`. '\nValueError: Unexpectedly found an instance of type ``. Expected a symbolic tensor instance.\n\nI'm using Python 3.6, with Spyder 3.1.4, on Windows 7. I upgraded TensorFlow and Keras with pip this morning.\n\nThank you for any help provided !\"",
    "answer": "\"Try:\n\nfusion = concatenate([sentenceMatrix, deletionMatrix])\n\nConcatenate is used in a Sequential model, whereas concatenate is used in a Functional API.\"",
    "mlApiName": "keras.layers.concatenate",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Data Preprocessing",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/51763983",
    "title": "",
    "question": "\"I'm training a model to predict the stock price and input data is close price. I use 45 days data to predict the 46th day's close price and a economic Indicator to be second feature, here is the model:\n\nmodel = Sequential()\nmodel.add( LSTM( 512, input_shape=(45, 2), return_sequences=True))\nmodel.add( LSTM( 512, return_sequences=True))\nmodel.add( (Dense(1)))\nmodel.compile(loss='mse', optimizer='adam')\nhistory = model.fit( X_train, y_train, batch_size = batchSize, epochs=epochs, shuffle = False)\n\nWhen I run this I get the following error:\n\n  ValueError: Error when checking target: expected dense_1 to have 3\n  dimensions, but got array with shape (118, 1)\n\nHowever, I print the shape of data and they are:\n\nX_train:(118, 45, 2)\ny_train:(118, 1)\n\nI have no idea why the model is expecting a 3 dimensional output when y_train is (118, 1). Where am I wrong and what should I do?\"",
    "answer": "\"Your second LSTM layer also returns sequences and Dense layers by default apply the kernel to every timestep also producing a sequence:\n\n# (bs, 45, 2)\nmodel.add( LSTM( 512, input_shape=(45, 2), return_sequences=True))\n# (bs, 45, 512)\nmodel.add( LSTM( 512, return_sequences=True))\n# (bs, 45, 512)\nmodel.add( (Dense(1)))\n# (bs, 45, 1)\n\nSo your output is shape (bs, 45, 1). To solve the problem you need to set return_sequences=False in your second LSTM layer which will compress sequence:\n\n# (bs, 45, 2)\nmodel.add( LSTM( 512, input_shape=(45, 2), return_sequences=True))\n# (bs, 45, 512)\nmodel.add( LSTM( 512, return_sequences=False)) # SET HERE\n# (bs, 512)\nmodel.add( (Dense(1)))\n# (bs, 1)\n\nAnd you'll get the desired output. Note bs is the batch size.\"",
    "mlApiName": "keras.models.fit",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "DT",
      "level3": "BIT",
      "leafContractCategory": "BIT",
      "rootCause": "Unacceptable Input Type",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Evaluation",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/48674881",
    "title": "",
    "question": "\"I want to do multi label classification (20 distinct output labels), based on vectorized words using TfidfVectorizer. I have set of 39974 rows each one containing 2739 items (zeros or ones).\n\nI would like to classify this data using Keras model which will contain 1 hidden layer (~20 nodes with activation='relu') and output layer equal 20 possible output values (with activation='softmax' to choose best fit).\n\nHere's my code so far:\n\nmodel = Sequential()\nmodel.add(Dense(units=20, activation='relu', input_shape=tfidf_matrix.shape))\nmodel.add(Dense(units=20, activation='softmax'))\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(tfidf_matrix, train_data['cuisine_id'], epochs=10)\n\nBut got error: \n\n  ValueError: Error when checking input: expected dense_1_input to have\n  3 dimensions, but got array with shape (39774, 2739)\n\nHow can I specify this NN to fit using this matrix?\"",
    "answer": "\"The number of rows (number of training samples) is not the part of the input shape of the network because the training process feeds the network one sample per batch (or, more precisely, batch_size samples per batch).\n\nSo in your case, input shape of the network is (2739, ) and the right code should be like this:\n\nmodel = Sequential()\n# the shape of one training example is\ninput_shape = tfidf_matrix[0].shape\nmodel.add(Dense(units=20, activation='relu', input_shape=input_shape))\nmodel.add(Dense(units=20, activation='softmax'))\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', \nmetrics=['accuracy'])\nmodel.fit(tfidf_matrix, train_data['cuisine_id'], epochs=10)\"",
    "mlApiName": "keras.layers.Dense",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "DT",
      "level3": "MT",
      "leafContractCategory": "MT",
      "rootCause": "Unacceptable Input Type",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Model Construction",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  },
  {
    "postURL": "https://stackoverflow.com/questions/48373845",
    "title": "",
    "question": "\"In Keras, if you need to have a custom loss with additional parameters, we can use it like mentioned on https://datascience.stackexchange.com/questions/25029/custom-loss-function-with-additional-parameter-in-keras\n\ndef penalized_loss(noise):\n    def loss(y_true, y_pred):\n        return K.mean(K.square(y_pred - y_true) - K.square(y_true - noise), axis=-1)\n    return loss\n\nThe above method works when I am training the model. However, once the model is trained I am having difficulty in loading the model. When I try to use the custom_objects parameter in load_model like below\n\nmodel = load_model(modelFile, custom_objects={'penalized_loss': penalized_loss} )\n\nit complains ValueError: Unknown loss function:loss\n\nIs there any way to pass in the loss function as one of the custom losses in custom_objects ? From what I can gather, the inner function is not in the namespace during load_model call. Is there any easier way to load the model or use a custom loss with additional parameters\"",
    "answer": "\"Yes, there is! custom_objects expects the exact function that you used as loss function (the inner one in your case):\n\nmodel = load_model(modelFile, custom_objects={ 'loss': penalized_loss(noise) })\n\nUnfortunately keras won't store in the model the value of noise, so you need to feed it to the load_model function manually.\"",
    "mlApiName": "keras.models.load_model",
    "embedding": [],
    "label": {
      "level1": "SAM",
      "level2": "BET",
      "level3": "IC-1",
      "leafContractCategory": "IC-1",
      "rootCause": "Unacceptable Input Value",
      "effect": "Crash",
      "mlLibrary": "Keras",
      "contractViolationLocation": "Load",
      "detectionTechnique": "Static",
      "reasonsForNotLabeling": "0",
      "reasonsForLabeling": ""
    }
  }
]